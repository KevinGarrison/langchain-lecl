{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a995edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = \"/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl\"\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ea0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from docling.chunking import HybridChunker\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FILE_PATH = [\"/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf\"]\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GEN_MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "QUESTION = \"Which are the main AI models in Docling?\"\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
    ")\n",
    "TOP_K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8953672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 12:22:02,599 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-24 12:22:02,638 - INFO - Going to convert document batch...\n",
      "2025-11-24 12:22:02,639 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-11-24 12:22:02,644 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-11-24 12:22:02,644 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-24 12:22:02,646 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-24 12:22:02,649 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-11-24 12:22:02,649 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-24 12:22:02,652 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-24 12:22:03,095 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-11-24 12:22:03,099 - INFO - Accelerator device: 'mps'\n",
      "2025-11-24 12:22:03,771 - INFO - Accelerator device: 'mps'\n",
      "2025-11-24 12:22:04,043 - INFO - Processing document Bachelorarbeit_Kevin_Garrison_85826.pdf\n",
      "2025-11-24 12:22:19,968 - INFO - Finished converting document Bachelorarbeit_Kevin_Garrison_85826.pdf in 17.37 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f12b75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 103.33333305833334, 't': 802.6580558356798, 'r': 125.33333305833332, 'b': 797.3384682068138, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/1', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 11.999999324444465, 't': 742.1477465717364, 'r': 214.66666599111113, 'b': 722.199292963489, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 89.291, 't': 574.5630146484375, 'r': 256.066, 'b': 549.1620146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 41]}]}], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='STUTTGART\\nPORSCHe\\nBachelorarbeit Studiengang : Data Science'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 248.345, 't': 291.1920146484375, 'r': 346.932, 'b': 189.3030146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 33]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 277.769, 't': 175.7220146484375, 'r': 317.508, 'b': 161.97901464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/7', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 98.291, 't': 756.4200146484375, 'r': 352.429, 'b': 732.4200146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 83]}]}, {'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 98.291, 't': 715.7730146484375, 'r': 312.502, 'b': 705.3220146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 35]}]}], 'headings': ['Einsatz von Large Language Models (LLM) zur Extraktion und Strukturierung von Zolldokumenten: Ein KI-gestützter Ansatz zur automatisierten Datenverarbeitung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Einsatz von Large Language Models (LLM) zur Extraktion und Strukturierung von Zolldokumenten: Ein KI-gestützter Ansatz zur automatisierten Datenverarbeitung\\nbei Porsche AG von Kevin Garrison\\n85826\\nBetreuender Professor: Prof. Dr. Winfried Bantel Zweitprüfer : Prof. Dr. Tim Dahmen\\nEinreichungsdatum : 14. August 2025'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/10', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 641.2310146484375, 'r': 183.142, 'b': 631.2930146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 13]}]}, {'self_ref': '#/texts/11', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 195.096, 't': 641.0350146484375, 'r': 253.602, 'b': 631.4020146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/12', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 627.6820146484375, 'r': 152.651, 'b': 617.7440146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/13', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 195.096, 't': 627.4860146484375, 'r': 355.416, 'b': 577.2060146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 82]}]}, {'self_ref': '#/texts/14', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 614.1330146484376, 'r': 160.309, 'b': 604.1950146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}]}, {'self_ref': '#/texts/15', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 600.5840146484375, 'r': 149.215, 'b': 590.6460146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/16', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 559.9360146484375, 'r': 166.789, 'b': 549.9980146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 12]}]}, {'self_ref': '#/texts/17', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 195.096, 't': 559.7400146484375, 'r': 328.252, 'b': 523.0090146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 67]}]}, {'self_ref': '#/texts/18', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 546.3870146484375, 'r': 146.378, 'b': 536.4490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/19', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 98.4, 't': 532.8380146484375, 'r': 141.72, 'b': 522.9000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}], 'headings': ['Angaben zur Firma'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Angaben zur Firma\\nUnternehmen :\\nPorsche AG\\nBranche :\\nAutomobilbranche Finanzstrategie & Data Science Porscheplatz 1 D - 70435 Stuttgart\\nAbteilung :\\nAdresse :\\nBetreuerin :\\nMaike Klepsch (FOD) (+49) 0 152 3 911 0075 maike.klepsch@porsche.de\\nTelefon :\\nE-Mail :'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/21', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 88.899, 't': 642.8320146484375, 'r': 506.229, 'b': 619.3450146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 150]}]}, {'self_ref': '#/texts/22', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 88.757, 't': 606.1460146484375, 'r': 507.798, 'b': 542.3170146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 332]}]}, {'self_ref': '#/texts/24', 'parent': {'$ref': '#/groups/1'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 4, 'bbox': {'l': 164.065, 't': 485.3720146484375, 'r': 222.865, 'b': 475.7390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/25', 'parent': {'$ref': '#/groups/1'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 4, 'bbox': {'l': 300.669, 't': 485.3720146484375, 'r': 414.112, 'b': 475.7390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}], 'headings': ['Eidesstattliche Erklärung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Eidesstattliche Erklärung\\nHiermit erkläre ich, Kevin Garrison , dass ich die vorliegenden Angaben in dieser Arbeit bei Porsche AG wahrheitsgetreu und selbständig verfasst habe.\\nWeiterhin versichere ich, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt zu haben, dass alle Ausführungen, die anderen Schriften wörtlich oder sinngemäß entnommen wurden, kenntlich gemacht sind und dass die Arbeit in gleicher oder ähnlicher Fassung noch nicht Bestandteil einer Studien- oder Prüfungsleistung war.\\nOrt, Datum\\nUnterschrift (Student)'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/27', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.931, 't': 642.6360146484375, 'r': 507.798, 'b': 511.0610146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Kurzfassung\\nDie Beschaffung von Daten sowie die Abbildung komplexer Geschäftsprozesse in Unternehmen sind häufig mit erheblichem Aufwand verbunden. Insbesondere in diesen Bereichen bieten Automatisierungen durch regelbasierte oder Künstliche Intelligenz (KI)-gestützte Systeme einen erheblichen Mehrwert. Gerade Abteilungen, die sich mit der Verzollung internationaler Warenbewegungen befassen, weisen signifikante Prozessaufwände auf und können von solchen Automatisierungen deutlich profitieren. Aufgrund der häufig mangelhaften und unstrukturierten Datengrundlage ist es jedoch eine Herausforderung, manuelle Prozesse systemseitig abzubilden, ohne dabei Einbußen in Bezug auf Qualität, Nachvollziehbarkeit und Konformität der erzeugten'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/27', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.931, 't': 642.6360146484375, 'r': 507.798, 'b': 511.0610146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Kurzfassung\\nErgebnisse hinzunehmen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/28', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.899, 't': 507.1440146484375, 'r': 508.114, 'b': 199.4290146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1764]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Kurzfassung\\nIn dieser Arbeit erfolgt die Implementierung eines KI-gestützten Systems zur Extraktion und Strukturierung relevanter Inhalte aus Zolldokumenten. Der Extraktionsprozess basiert auf dem Einsatz von Large Language Models (LLMs) in Kombination mit gezieltem Prompt Engineering , um die semantische Interpretation und die kontextuelle Erfassung der Inhalte zu optimieren. Die Qualität der Ergebnisse wird anhand eines Goldstandards für Zolldaten bewertet. Darüber hinaus erfolgt ein systematischer Vergleich mit einem klassischen hybriden Ansatz, der als Referenzsystem dient und auf Optical Character Recognition (OCR)-gestützter Texterkennung sowie einer Named Entity Recognition (NER)-Komponente beruht. Dabei zeigte sich, dass OCR-bedingte Zeichenerkennungsfehler die Erkennungsleistung des'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/28', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.899, 't': 507.1440146484375, 'r': 508.114, 'b': 199.4290146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1764]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Kurzfassung\\nklassischen Systems erheblich beeinträchtigen, während der LLM-basierte Ansatz diese Schwächen durch kontextuelle Interpretation teilweise kompensieren kann. Die besten Resultate hinsichtlich der Micro-Metriken lagen bei einem Recall von 0,53 und einem F1-Score von 0,60. Diese Ergebnisse wurden bei exakter Übereinstimmung numerischer Werte und einem Levenshtein-Schwellenwert von über 90% im Zeichenkettenvergleich zu den Testdaten erzielt. Insgesamt zeigen die Ergebnisse, dass der LLM-Ansatz robuster gegenüber fehlerhaften Eingangsdaten ist und ein höheres Maß an Generalisierungsfähigkeit aufweist, zugleich jedoch auch eigene Limitationen in Bezug auf Reproduzierbarkeit und Extraktionsgenauigkeit mit sich bringt, sodass eine'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/28', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.899, 't': 507.1440146484375, 'r': 508.114, 'b': 199.4290146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1764]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Kurzfassung\\nvollständige Automatisierung bestehender Prozesse zur Inhaltsextraktion von Zolldokumenten durch das LLM-basierte System derzeit noch nicht den Anforderungen entspricht und somit nicht ohne menschliche Nachkontrolle eingesetzt werden kann.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 6, 'bbox': {'l': 87.35152435302734, 't': 644.2227783203125, 'r': 506.1298828125, 'b': 179.94110107421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\nTabellenverzeichnis, Abbildungsverzeichnis = Tabellenverzeichnis. Tabellenverzeichnis, vi = vii. Listings, Abbildungsverzeichnis = Listings. Listings, vi = ix. Abkürzungsverzeichnis, Abbildungsverzeichnis = Abkürzungsverzeichnis. Abkürzungsverzeichnis, vi = x. 1. Einleitung, Abbildungsverzeichnis = 1. Einleitung. 1. Einleitung, vi = 1. , Abbildungsverzeichnis = 1.1. Problemstellung für die automatisierte Inhaltsextraktion von Doku- menten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. , vi = 1. , Abbildungsverzeichnis = 1.2. Ziel der Arbeit . . . . . . . . . . . . . . . . . . . .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 6, 'bbox': {'l': 87.35152435302734, 't': 644.2227783203125, 'r': 506.1298828125, 'b': 179.94110107421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\n. . . . . . . . . . . .. , vi = 2. , Abbildungsverzeichnis = 1.3. Abgrenzung der Arbeit . . . . . . . . . . . . . . . . . . . . . . . . . . .. , vi = 3. 2. Grundlagen, Abbildungsverzeichnis = 2. Grundlagen. 2. Grundlagen, vi = 4. , Abbildungsverzeichnis = 2.1. Informationsextraktion aus Dokumenten . . . . . . . . . . . . . . . .. , vi = 4. , Abbildungsverzeichnis = 2.2. Optical Character Recognition (OCR) . . . . . . . . . . . . . . . . . . .. , vi = 4. , Abbildungsverzeichnis = 2.2.1. Funktionsweise von Optical Character Recognition (OCR) . .. , vi = 5. , Abbildungsverzeichnis ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 6, 'bbox': {'l': 87.35152435302734, 't': 644.2227783203125, 'r': 506.1298828125, 'b': 179.94110107421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\n2.2.2. Tesseract Optical Character Recognition (OCR) . . . . . . . .. , vi = 7. , Abbildungsverzeichnis = 2.3. Natural Language Processing (NLP) . . . . . . . . . . . . . . . . . . .. , vi = 8. , Abbildungsverzeichnis = 2.3.1. Named Entity Recognition (NER) . . . . . . . . . . . . . . . . .. , vi = 9. , Abbildungsverzeichnis = 2.3.2. Arten benannter Entitäten . . . . . . . . . . . . . . . . . . . .. , vi = 10. , Abbildungsverzeichnis = 2.3.3. spaCy: Framework für NLP in Python . . . . . . . . . . . . . .. , vi = 11. 2.4. Large Language Models (LLM), Abbildungsverzeichnis = . . . . . . . . . .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 6, 'bbox': {'l': 87.35152435302734, 't': 644.2227783203125, 'r': 506.1298828125, 'b': 179.94110107421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\n. . . . . . . . . . . .. 2.4. Large Language Models (LLM), vi = 12. , Abbildungsverzeichnis = 2.4.1. Funktionsweise eines Large Language Models . . . . . . . . .. , vi = 12. , Abbildungsverzeichnis = 2.4.2. Transformer . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. , vi = 13. , Abbildungsverzeichnis = 2.4.3. Multimodales LLM GPT-4o . . . . . . . . . . . . . . . . . . . .. , vi = 15. , Abbildungsverzeichnis = 2.4.4. Prompt Engineering . . . . . . . . . . . . . . . . . . . . . . . .. , vi = 17. 2.6. Evaluationsmetriken für die, Abbildungsverzeichnis = 2.6.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 6, 'bbox': {'l': 87.35152435302734, 't': 644.2227783203125, 'r': 506.1298828125, 'b': 179.94110107421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/31', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 7, 'bbox': {'l': 500.126, 't': 789.7760146484375, 'r': 505.984, 'b': 780.1430146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\nEvaluationsmetriken für die. 2.6. Evaluationsmetriken für die, vi = 2.6. Evaluationsmetriken für die. Bewertung des Systems . . . 3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten, Abbildungsverzeichnis = Bewertung des Systems . . . 3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten. Bewertung des Systems . . . 3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten, vi = 30. 4. Implementierung, Abbildungsverzeichnis = 4. Implementierung. 4. Implementierung, vi = 33. 5. Evaluierung des Systems, Abbildungsverzeichnis = 5. Evaluierung des Systems. 5. Evaluierung des Systems, vi = 37\\nv'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/1', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 7, 'bbox': {'l': 87.68663024902344, 't': 757.8654403686523, 'r': 506.111572265625, 'b': 579.3153686523438, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Inhaltsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Inhaltsverzeichnis\\n6. Zusammenfassung und Ausblick, 1 = 43. 6.1. Erreichte Ergebnisse . . . . . . . . . . . ., 1 = 43. 6.2. Ausblick . . . . . . . . . . . . . . . . . . ., 1 = 43. Literatur, 1 = 45. A. Anhang A, 1 = 49. A.1. Implementierung der Extraktionspipeline, 1 = 49. A.2. Prompt Design für Datenextraktion . . ., 1 = 58. A.3. Prompt Design für Schemamigration . . ., 1 = 67. B. Anhang B, 1 = 78. C. Anhang C, 1 = 82'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 8, 'bbox': {'l': 104.60250091552734, 't': 644.6215972900391, 'r': 505.8478698730469, 'b': 414.99810791015625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Abbildungsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Abbildungsverzeichnis\\n2.1., 1 = Beispiel für Named Entity Recognition mit erkannten Entitäten und zugehörigen Entitätstypen . . . . . . . . . . . . . . . . . . . . . . . . . .. 2.1., 2 = 10. 2.2., 1 = Publikationen zu NER in den letzten 30 Jahren [15] . . . . . . . . . . .. 2.2., 2 = 11. 2.3., 1 = Scaled Dot-Produkt Attention und Multi-Head Attention [18]. . . . . .. 2.3., 2 = 14. 2.4., 1 = Transformer-Modell mit Self-Attention-Mechanismus, bestehend aus Encoder, Decoder und Multi-Head Attention [18]. . . . . . . . . . . . .. 2.4., 2 = 16. 3.1., 1 = Schematische Übersicht der Datenpipeline zur Entitätsextraktion aus'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 8, 'bbox': {'l': 104.60250091552734, 't': 644.6215972900391, 'r': 505.8478698730469, 'b': 414.99810791015625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Abbildungsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Abbildungsverzeichnis\\nZolldokumenten. Die Abbildung illustriert die zentralen Verarbei- tungsschritte durch ein multimodales LLM . . . . . . . . . . . . . . . .. 3.1., 2 = 32. 5.1., 1 = Kopfdaten: Micro-Metriken in Abhängigkeit der Levenshtein-Distanz. 5.1., 2 = 42. 5.2., 1 = Einzelpositionen: Micro-Metriken in Abhängigkeit der Levenshtein- Distanz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 5.2., 2 = 42. C.1., 1 = Screenshot des LLM basierten Systems zur Zolldokumentenextraktion. C.1., 2 = 82. C.2., 1 = Screenshot des hybriden klassischen Systems zur Zolldokumentenex-'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 8, 'bbox': {'l': 104.60250091552734, 't': 644.6215972900391, 'r': 505.8478698730469, 'b': 414.99810791015625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Abbildungsverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Abbildungsverzeichnis\\ntraktion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. C.2., 2 = 83'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 9, 'bbox': {'l': 104.68489074707031, 't': 644.2362823486328, 'r': 505.898681640625, 'b': 165.0947265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Tabellenverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Tabellenverzeichnis\\n2.1., 1 = Prompt mit geringer Temperatur von 0.1 und niedrigem Token-Limit von 5: Die Ausgabe ist sehr vorhersehbar und endet nach 5 Tokens. .. 2.1., 2 = 18. 2.2., 1 = Prompt mit hoher Temperatur von 0.9 und Top-P 0.5 mit einem hohen Token-Limit von 20: Die Ausgabe ist kreativer und ausführlicher. . .. 2.2., 2 = 18. 2.3., 1 = Beispiel eines Zero-Shot Prompts mit Parametereinstellung zur Ex- traktion von Entitäten aus Zolldokumenten . . . . . . . . . . . . . . .. 2.3., 2 = 19. 2.4., 1 = In-Context Learning (ICL) mit Beispielen zur Extraktion von Entitä- ten aus Zolldokumenten . . . . . . . . . . . . . . . . . . .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 9, 'bbox': {'l': 104.68489074707031, 't': 644.2362823486328, 'r': 505.898681640625, 'b': 165.0947265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Tabellenverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Tabellenverzeichnis\\n. . . . . . .. 2.4., 2 = 20. 2.5., 1 = One-Shot/Few-Shot Prompting zur Extraktion von Entitäten aus Zoll- dokumenten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 2.5., 2 = 21. 2.6., 1 = instruktionsbasiertes Prompting mit Schrittweisen Anweisungen für Extraktion von Entitäten aus Zolldokumenten . . . . . . . . . . . . .. 2.6., 2 = 22. 2.7., 1 = Zentrale Zolldokumente mit Felder für die zu extrahierenden Entitä- ten der Kopfdaten einer Sendung und Grad des Layouts . . . . . . .. 2.7., 2 = 23. 2.8., 1 = Beschreibung der Felder der Kopfdaten . . . . . . . . . .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 9, 'bbox': {'l': 104.68489074707031, 't': 644.2362823486328, 'r': 505.898681640625, 'b': 165.0947265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Tabellenverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Tabellenverzeichnis\\n. . . . . . .. 2.8., 2 = 24. 2.9., 1 = Felder der Einzelpositionen für die Extraktion aus Zolldokumenten .. 2.9., 2 = 25. 5.1., 1 = Auswertung der aggregierten Metriken - absteigend sortiert nach Recall - für alle Dokumente Promptmethode für die Extraktion durch Gpt-4o in Teilschritt eins . . . . . . . . . . . . . . . . . . . . . . . . . .. 5.1., 2 = 38. 5.2., 1 = Auswertung der aggregierten Metriken - absteigend sortiert nach Re- call - für alle Dokumente pro Promptmethode für die Schemamigration der in Schritt eins gefundenen Entitäten durch Gpt-4o in Teilschritt zwei . . . . . . . . . . . . . . . .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 9, 'bbox': {'l': 104.68489074707031, 't': 644.2362823486328, 'r': 505.898681640625, 'b': 165.0947265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Tabellenverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Tabellenverzeichnis\\n. . . . . . . . . . . . . . . . . . . . . .. 5.2., 2 = 39. 5.3., 1 = Auswertung spaCy NER für die Extraktion Teilschritt eins . . . . . .. 5.3., 2 = 39. 5.4., 1 = Micro-basierte Metriken zur Bewertung der Kopfdatenextraktion . .. 5.4., 2 = 40. 5.5., 1 = Macro-basierte Metriken zur Bewertung der Kopfdatenextraktion .. 5.5., 2 = 40. 5.6., 1 = Micro-basierte Metriken zur Bewertung der Extraktion der Einzelpo- sitionen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 5.6., 2 = 41. 5.7., 1 = Macro-basierte Metriken zur Bewertung der'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 9, 'bbox': {'l': 104.68489074707031, 't': 644.2362823486328, 'r': 505.898681640625, 'b': 165.0947265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/tables/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 10, 'bbox': {'l': 104.72960662841797, 't': 755.7249145507812, 'r': 505.2852478027344, 'b': 730.8361892700195, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Tabellenverzeichnis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Tabellenverzeichnis\\nExtraktion der Einzelpo- sitionen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 5.7., 2 = 41. B.1., 1 = Klassenspezifische Extraktionsmetriken der Kopfdaten für 30 Sen- dungen mit der Methode Zero-Shot Prompting (erster Teil). . . . . .. B.1., 2 = 79. B.2., 1 = Klassenspezifische Extraktionsmetriken der Kopfdaten für 30 Sen- dungen mit der Methode Zero-Shot Prompting (zweiter Teil). . . . . .. B.2., 2 = 80\\nB.3., 1 = Klassenspezifische Extraktionsmetriken der Einzelpositionen für 30. , 1 = Sendungen mit der Methode Zero-Shot Prompting. . . . . . . . . . . . . 81'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'document_index', 'prov': [{'page_no': 11, 'bbox': {'l': 104.26261138916016, 't': 644.8113098144531, 'r': 505.7311096191406, 'b': 555.4896850585938, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['Listings'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listings\\n4.1., 1 = LLM als OCR-Ersatz - PDF zu Bild und Bild zu Text Extraktion . . .. 4.1., 2 = 33. 4.2., 1 = Schemamigration des extrahierten JSON-Contents aus Teilaufgabe eins. 4.2., 2 = 34. 4.3., 1 = Pydantic Modell für eine Schemaüberprüfung . . . . . . . . . . . . . .. 4.3., 2 = 35. A.1., 1 = LLM als OCR Ersatz - Umwandlung von PDF in Bild und Extraktion der Entitäten von Bild zu Text . . . . . . . . . . . . . . . . . . . . . . .. A.1., 2 = 49. A.2., 1 = LLM um Daten in vordefiniertes Schema zu migrieren . . . . . . . . .. A.2., 2 = 54'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/40', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 13, 'bbox': {'l': 88.899, 't': 585.7370146484375, 'r': 507.8, 'b': 494.80901464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 504]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nDie in Unternehmen anfallenden Datenmengen unterliegen einem stetigen, teils exponentiellen Wachstum. Dies betrifft sämtliche Phasen der datenbezogenen Wertschöpfung - von der Erfassung und Vorverarbeitung bis hin zur modellgestützten Abbildung geschäftsrelevanter Prozesse innerhalb der Hauptverarbeitung. Vor diesem Hintergrund stoßen manuelle Verfahren zur Verarbeitung und Analyse dieser Daten zunehmend an ihre Grenzen - insbesondere im Hinblick auf Effizienz, Skalierbarkeit und Fehleranfälligkeit.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/41', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 13, 'bbox': {'l': 89.291, 't': 490.8930146484375, 'r': 507.799, 'b': 413.5140146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 455]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nBesonders betroffen sind Unternehmensbereiche, die mit der internationalen Verzollung von Waren befasst sind, da hierbei eine Vielzahl komplexer und unstrukturierter Zolldokumente verarbeitet werden muss. Die Automatisierung der Inhaltsextraktion von Dokumenten aus dem Zollkontext stellt daher eine zentrale Herausforderung dar, um den gestiegenen Anforderungen an Geschwindigkeit, Genauigkeit und Nachvollziehbarkeit in der Abwicklung gerecht zu werden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/42', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 13, 'bbox': {'l': 89.291, 't': 409.5980146484375, 'r': 507.791, 'b': 291.57101464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 735]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nZolldokumente liegen häufig als zusammengeführte PDF-Dateien vor, unterscheiden sich jedoch erheblich in Layout, Struktur und Qualität (vgl. Abschnitt 2.5). Zudem enthalten sie oftmals keinen eingebetteten digitalen Text, sondern bestehen lediglich aus gescannten oder fotografierten Bildern. Diese Vielfalt macht sowohl die manuelle als auch die automatisierte Extraktion der für die Zollabwicklung relevanten Inhalte zu einem aufwändigen und fehleranfälligen Prozess. Dabei existieren einerseits standardisierte Formate wie das Zolldokument T1, die Warenverkehrsbescheinigung oder das Präferenzdokument. Andererseits gibt es zahlreiche nicht standardisierte'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/42', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 13, 'bbox': {'l': 89.291, 't': 409.5980146484375, 'r': 507.791, 'b': 291.57101464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 735]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nDokumente, deren Gestaltung und Struktur je nach Lieferant stark variieren.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/43', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 13, 'bbox': {'l': 89.291, 't': 287.6550146484375, 'r': 508.111, 'b': 169.62801464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 714]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nKlassische Verfahren zur Informationsextraktion aus Dokumenten basieren häufig auf regelbasierten Ansätzen, heuristischen Mustern oder vordefinierten Templates. Diese Methoden stoßen jedoch bei unstrukturierten oder variantenreichen Dokumenten schnell an ihre Grenzen. Sie erfordern umfangreiche manuelle Konfigurationen, sind wenig skalierbar und reagieren äußerst sensitiv auf Layout- oder Sprachänderungen [1]. Schon geringfügige Abweichungen, etwa in der Positionierung von Elementen oder der Formulierung relevanter Informationen, führen häufig zu fehlerhaften oder fehlenden Extraktionen. Zudem fehlt es regelbasierten Systemen oft an kontextuellem Verständnis, was die semantische Interpretation der Inhalte'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/46', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 505.985, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 88]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nerschwert - insbesondere bei mehrdeutigen Begriffen oder domänenspezifischen Begriffen .'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/47', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 88.866, 't': 727.3130146484375, 'r': 508.108, 'b': 527.9910146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1162]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nModerne Verfahren auf Basis großer Sprachmodelle (Large Language Models (LLMs)) versprechen hier eine deutliche Verbesserung. Aufgrund ihrer enormen Trainingsdatenbasis und generativen Fähigkeiten können sie flexibel auf unterschiedliche Layouts, Sprachvarianten und Kontexte reagieren. Insbesondere durch In Context Learning (ICL) (vgl. Tabelle 2.4) und das Einbinden geeigneter Prompts lassen sich LLMs dazu befähigen, strukturierte Informationen auch aus heterogenen Dokumenten zu extrahieren. Dennoch bestehen auch hier Herausforderungen: Die Modelle erfordern geeignete Kontextrepräsentationen und ihre Vorhersagen sind weniger deterministisch kontrollierbar, da sie auf'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/47', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 88.866, 't': 727.3130146484375, 'r': 508.108, 'b': 527.9910146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1162]}]}], 'headings': ['1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.1. Problemstellung für die automatisierte Inhaltsextraktion von Dokumenten\\nprobabilistischen Wahrscheinlichkeitsverteilungen über ein Vokabular basieren [2]. Zudem kann es zu Halluzinationen kommen, bei denen Modelle nicht vorhandene Informationen generieren oder Fakten kontextuell falsch zuordnen. Der zuverlässige Einsatz in hochregulierten Bereichen wie der Zollabwicklung erfordert daher zusätzliche Absicherungsmechanismen sowie eine gezielte Modellsteuerung, etwa durch prompt engineering, strukturierte Ausgaben oder nachgelagerte Validierungslogik [3].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/49', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 88.899, 't': 458.0010146484375, 'r': 508.111, 'b': 339.9740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 705]}]}], 'headings': ['1.2. Ziel der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.2. Ziel der Arbeit\\nDiese Arbeit untersucht, inwieweit ein automatisiertes System mithilfe eines LLMs die bestehenden Herausforderungen bei der Extraktion von Zolldaten bewältigen kann und welche neuen Schwächen und Hürden dabei möglicherweise entstehen. Angesichts der Vielzahl an Dokumentenarten und der hohen Layout-Varianz stoßen regelbasierte Systeme ohne gezielte Feinjustierung auf die jeweiligen Anwendungsfälle schnell an ihre Grenzen. Zwar sind klassische, regelbasierte Verfahren in kontrollierten Anwendungsfällen robust und effizient, zeigen jedoch eine hohe Fehleranfälligkeit bei struktureller Varianz in Dokumentenlayouts und können die Heterogenität domänenspezifischer Inhalte nur unzureichend abbilden [4].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/50', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 89.291, 't': 336.0580146484375, 'r': 508.111, 'b': 285.77701464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 255]}]}], 'headings': ['1.2. Ziel der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.2. Ziel der Arbeit\\nModerne Ansätze, insbesondere LLMs, wurden auf sehr großen und diversifizierten Datensätzen trainiert und zeigen dadurch eine hohe Generalisierungsfähigkeit. Dennoch offenbaren sie häufig Schwächen bei der Extraktion domänenspezifischer Informationen [3].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/51', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 14, 'bbox': {'l': 88.931, 't': 281.8610146484375, 'r': 507.799, 'b': 190.9330146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 511]}]}], 'headings': ['1.2. Ziel der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.2. Ziel der Arbeit\\nZur Untersuchung der jeweiligen Stärken und Schwächen erfolgt in dieser Arbeit eine vergleichende Gegenüberstellung eines hybriden, klassischen Verfahrens bestehend aus einer vorgelagerten optischen Zeichenerkennung (Optical Character Recognition (OCR)) (vgl. Abschnitt 2.2) und einer nachgelagerten Entitätserkennung mittels der benannten Entitätserkennung (Named Entity Recognition (NER)) (vgl. Unterabschnitt 2.3.1) - mit einem modernen Ansatz, der beide Teilschritte durch ein LLM-basiertes System abbildet.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/55', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 89.291, 't': 719.7690146484375, 'r': 505.985, 'b': 696.5870146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 86]}]}, {'self_ref': '#/texts/56', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 88.997, 't': 679.1220146484375, 'r': 507.794, 'b': 588.1940146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 511]}]}], 'headings': ['1.3. Abgrenzung der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.3. Abgrenzung der Arbeit\\nIm Folgenden werden die inhaltlichen und methodischen Grenzen dieser Arbeit dargelegt.\\nZunächst liegt der Schwerpunkt der Arbeit auf der Extraktion und Strukturierung relevanter Inhalte aus Zolldokumenten mithilfe eines Large Language Models. Dabei wird auf eine bestehende Optical Character Recognition-Komponente ( Tesseract 1 vgl. Unterabschnitt 2.2.2) sowie auf ein vortrainiertes Named Entity RecognitionModell von spaCy 2 (vgl. Unterabschnitt 2.3.3) zurückgegriffen, ohne diese im Detail zu optimieren. Dieser hybride Ansatz dient lediglich als Vergleichsbasis für das zu entwickelnde System.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/57', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 89.291, 't': 584.2770146484376, 'r': 507.799, 'b': 533.9970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 258]}]}, {'self_ref': '#/texts/58', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 89.291, 't': 530.0810146484375, 'r': 507.799, 'b': 493.3490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 228]}]}], 'headings': ['1.3. Abgrenzung der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.3. Abgrenzung der Arbeit\\nDes Weiteren ist die Prüfung der rechtlichen oder formalen Gültigkeit von Zolldokumenten explizit nicht Gegenstand dieser Arbeit. Ziel ist ausschließlich die technische Extraktion inhaltlich relevanter Informationen, unabhängig von rechtlichen Anforderungen.\\nZur Eingrenzung des Umfangs beschränkt sich die Arbeit auf eine Auswahl spezifischer Dokumenttypen (vgl. Abschnitt 2.5). Eine vollständige Abdeckung aller zollrelevanten Formulare im internationalen Handel wird nicht angestrebt.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/59', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 89.291, 't': 489.4330146484375, 'r': 505.985, 'b': 439.1520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 311]}]}], 'headings': ['1.3. Abgrenzung der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.3. Abgrenzung der Arbeit\\nDie Evaluation der entwickelten Extraktionspipeline basiert auf einem begrenzten Datensatz realer Zolldokumente. Aufgrund der beschränkten Datenbasis von 30 Datenpunkten, kann keine Aussage über die Generalisierbarkeit der Ergebnisse auf alle möglichen Layouts und Varianten von Zolldokumenten getroffen werden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/60', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 15, 'bbox': {'l': 89.291, 't': 435.2360146484375, 'r': 507.799, 'b': 357.85701464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 426]}]}, {'self_ref': '#/texts/61', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 15, 'bbox': {'l': 94.436, 't': 183.34901464843756, 'r': 324.704, 'b': 174.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 44]}]}, {'self_ref': '#/texts/62', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 15, 'bbox': {'l': 94.436, 't': 172.1540146484375, 'r': 205.855, 'b': 162.96801464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}], 'headings': ['1.3. Abgrenzung der Arbeit'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='1.3. Abgrenzung der Arbeit\\nDarüber hinaus wird in dieser Arbeit ausschließlich ein spezifisches Large Language Model - Generative Pre-trained Transformer 4 Omni (GPT-4o) (vgl. Unterabschnitt 2.4.3) - eingesetzt. Ein Vergleich mit anderen Modellen erfolgt nicht. Ziel ist es nicht, einen umfassenden Vergleich diverser Modelle durchzuführen, sondern das Potenzial eines exemplarischen Modells zur Extraktion aus unstrukturierten Zolldaten zu untersuchen.\\n1 https://github.com/tesseract-ocr/tesseract\\n2 https://spacy.io/api'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 16, 'bbox': {'l': 88.931, 't': 603.6900146484376, 'r': 508.113, 'b': 350.1710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['2.1. Informationsextraktion aus Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.1. Informationsextraktion aus Dokumenten\\nIn einem Zeitalter von Big Data stellt die Extraktion von wertvollem Wissen aus komplexen, unstrukturierten Daten eine immer größere Hürde dar. Automatisierte Informationsextraktion aus Dokumenten bildet hierbei einen wesentlichen Bestandteil moderner Datenverarbeitung. Diese umfasst mehrere essenzielle Schritte, die für eine präzise und verlustfreie Erfassung relevanter Inhalte berücksichtigt werden müssen. Eine zentrale Voraussetzung ist die Kenntnis über das Dokumentenlayout sowie die logische Struktur des jeweiligen Dokuments, da andernfalls kontextabhängige Informationen verloren gehen können [5]. Ein typisches Dokument besteht aus verschiedenen strukturellen Elementen wie Fließtexten, Tabellen oder'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 16, 'bbox': {'l': 88.931, 't': 603.6900146484376, 'r': 508.113, 'b': 350.1710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['2.1. Informationsextraktion aus Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.1. Informationsextraktion aus Dokumenten\\nAbbildungen. Diese Elemente werden im Rahmen einer Layoutanalyse (vgl. Unterabschnitt 2.2.1) identifiziert und klassifiziert, sodass sie im weiteren Verlauf der Verarbeitung als kontextuelle Bezugspunkte dienen können [6]. Handelt es sich um gescannte oder handgeschriebene Dokumente, müssen zunächst die enthaltenen Zeichen und Wörter erkannt und in digitale Textrepräsentationen überführt werden. Diese Aufgabe erfordert eine präzise Zeichen- und Zeilensegmentierung und gegebenenfalls eine Schräglagenkorrektur des Dokuments. In der Praxis wird dieser Verarbeitungsschritt meist durch spezialisierte Optical Character Recognition (OCR)-Systeme (vgl. Abschnitt 2.2)'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 16, 'bbox': {'l': 88.931, 't': 603.6900146484376, 'r': 508.113, 'b': 350.1710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['2.1. Informationsextraktion aus Dokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.1. Informationsextraktion aus Dokumenten\\numgesetzt, welche die visuelle Information in maschinenlesbaren Text umwandeln [7].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 16, 'bbox': {'l': 88.866, 't': 280.1890146484375, 'r': 507.8, 'b': 216.35901464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 366]}]}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 16, 'bbox': {'l': 88.986, 't': 212.4430146484375, 'r': 507.799, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 306]}]}], 'headings': ['2.2. Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2. Optical Character Recognition (OCR)\\nDie optische Zeichenerkennung (Optical Character Recognition (OCR)) bezeichnet ein Verfahren zur automatisierten Umwandlung von handschriftlichem oder gedrucktem Text in gescannten Dokumenten oder Bildern in digitalen Text. Dabei werden die einzelnen Zeichen erkannt und umgewandelt, wobei regelbasierte, statistische oder Deep-Learning-Verfahren zum Einsatz kommen.\\nDie ersten Verfahren zur optischen Zeichenerkennung entstanden in den 1950erJahren. Diese waren jedoch in ihrer Leistung stark eingeschränkt, konnten nur eine geringe Anzahl an Zeichen verarbeiten und arbeiteten zudem langsam und unpräzise [4]. Moderne Verfahren basieren auf Deep Learning und sind dadurch'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/71', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 17, 'bbox': {'l': 88.997, 't': 754.4110146484375, 'r': 507.792, 'b': 649.9340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 570]}]}], 'headings': ['2.2. Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2. Optical Character Recognition (OCR)\\ndynamischer und leistungsfähiger [7]. Moderne OCR-Systeme bieten sogenannte Ende-zu-Ende-Lösungen, bei denen sämtliche Verarbeitungsschritte - von der Vorverarbeitung über die Zeichenerkennung bis hin zur Nachverarbeitung - vollständig integriert und aufeinander abgestimmt sind. Damit entfällt die Notwendigkeit externer Module für Aufgaben wie Binarisierung, Rauschunterdrückung oder Schräglagenkorrektur (vgl. Unterabschnitt 2.2.1). Dies erleichtert die Anwendung und erhöht die Genauigkeit sowie Zuverlässigkeit der Texterkennung in verschiedensten Einsatzszenarien.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/73', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 17, 'bbox': {'l': 88.08, 't': 589.2430146484376, 'r': 508.107, 'b': 376.3720146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1216]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nEin OCR-System durchläuft dabei mehrere technische Verarbeitungsstufen. Nach der Erfassung des Dokuments durch Scannen oder Fotografie erfolgt zunächst die Vorverarbeitung, bei der Maßnahmen wie Binarisierung, Rauschunterdrückung und Schräglagenkorrektur angewendet werden, um die Bildqualität und den Informationsgehalt insgesamt zu verbessern. Die Binarisierung überführt die Bilddaten in Schwarz-Weiß-Pixel, wodurch die Trennung von Zeichen und Hintergrund anhand eines definierten Schwellenwerts erleichtert wird und eine effizientere Segmentierung möglich ist. Dieser Schritt ist besonders wichtig, da viele nachfolgende Algorithmen - etwa zur Zeichenerkennung oder Segmentierung - davon ausgehen,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/73', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 17, 'bbox': {'l': 88.08, 't': 589.2430146484376, 'r': 508.107, 'b': 376.3720146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1216]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\ndass der Text deutlich vom Hintergrund unterscheidbar ist. In der Praxis wird hierzu meist ein globaler oder adaptiver Schwellenwert verwendet. Beim globalen Ansatz wird für das gesamte Bild ein einziger Schwellenwert festgelegt, während beim adaptiven Verfahren für kleine Bildbereiche jeweils eigene Schwellenwerte berechnet werden. Dadurch können auch Dokumente mit ungleichmäßig ausgeleuchtetem Hintergrund zuverlässig in klare Schwarz-Weiß-Bilder umgewandelt werden, was die Erkennungsgenauigkeit erhöht [8].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/74', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 17, 'bbox': {'l': 87.48, 't': 372.45601464843753, 'r': 507.799, 'b': 173.13401464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1179]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nBei der Rauschunterdrückung werden unerwünschte Bildstörungen wie zufällige Punkte, Flecken oder kleine Linien entfernt, die das Erkennen von Zeichen erschweren könnten. Solche Störungen entstehen häufig durch Staub auf dem Scanner, Papierstruktur oder elektronische Bildartefakte. Die Rauschunterdrückung kann beispielsweise mit Hilfe der Faltung (Konvolution) realisiert werden, bei der ein sogenannter Glättungsfilter, wie etwa ein gleitender Mittelwerts-Filter, über das Bild gelegt wird. Dieser Filter berechnet für jeden Pixel den Durchschnitt der benachbarten Pixelwerte und ersetzt den ursprünglichen Wert durch diesen Durchschnitt. Dadurch werden plötzliche Helligkeitsänderungen und'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/74', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 17, 'bbox': {'l': 87.48, 't': 372.45601464843753, 'r': 507.799, 'b': 173.13401464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1179]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nkleine Störungen geglättet, während die grundlegenden Strukturen des Textes erhalten bleiben. Je nach Art und Ausmaß des Rauschens können unterschiedliche Filtertypen und -größen zum Einsatz kommen, um ein möglichst optimales Ergebnis für die weitere Verarbeitung zu erzielen. Die Schräglagenkorrektur sorgt dafür, dass schief gescannte oder fotografierte Dokumente ausgerichtet werden, sodass die Textzeilen wieder horizontal verlaufen und eine bessere Weiterverarbeitung gewährleistet'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 88.899, 't': 754.4110146484375, 'r': 507.8, 'b': 446.69601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1647]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nist. Bereits geringe Schräglagen können die automatische Texterkennung und die anschließende Segmentierung deutlich erschweren, da viele Algorithmen davon ausgehen, dass der Text gerade angeordnet ist. In der Praxis wird die Schräglage häufig durch Analyse der Verteilung der schwarzen Pixel in den einzelnen Bildzeilen ermittelt: Dazu werden verschiedene kleine Drehwinkel ausprobiert und jeweils überprüft, bei welchem Winkel die Zeilen im Bild am besten ausgeprägt erscheiDas Bild wird dann entsprechend gedreht, sodass die Textzeilen optimal horizontal ausgerichtet sind. Durch diese Korrektur wird die Grundlage für eine fehlerarme Texterkennung und weiterführende Verarbeitung geschaffen und es erfolgt die'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 88.899, 't': 754.4110146484375, 'r': 507.8, 'b': 446.69601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1647]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nSegDies kann entweder explizit durch geometrische Trennverfahren oder implizit durch lernbasierte Ansätze erfolgen. Zu den einfacheren expliziten Verfahren zählen die Verbundene-Komponenten-Analyse (Connected Component Analysis (CCA)) sowie die Projektionsprofil-Methode (Projection Profiles) (vgl. Unterabschnitt 2.2.1). Die CCA-Methode identifiziert zusammenhängende Pixelbereiche im Bild - sogenannte zusammenhängende Komponenten - wobei jede Komponente als potenzielles Zeichen betrachtet wird. Die Projektionsprofil-Methode nutzt vertikale Projektionen zur Trennung einzelner Zeichen innerhalb einer Zeile und horizontale Projektionen zur Abgrenzung'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 88.899, 't': 754.4110146484375, 'r': 507.8, 'b': 446.69601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1647]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nder Textzeilen. In komplexeren Dokumenten, etwa bei überlappenden Zeichen oder starkem Rauschen, stoßen diese einfachen Verfahren jedoch an ihre Grenzen, sodass auf fortgeschrittene Segmentierungsmethoden, wie zum Beispiel Clustering-Algorithmen, zurückgegriffen werden muss [4].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/78', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 88.986, 't': 442.7790146484375, 'r': 507.8, 'b': 243.45801464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 965]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nBevor die eigentliche Klassifikation der Zeichen erfolgt, wird zunächst eine Merkmalsextraktion durchgeführt. Während regelbasierte und statistische OCR-Systeme explizit definierte Merkmale aus den Zeichenbildern extrahieren, übernehmen moderne Deep-Learning-basierte Verfahren diese Aufgabe implizit: Die neuronalen Netze lernen während des Trainingsprozesses automatisch, relevante Merkmale direkt aus den Rohdaten zu identifizieren. Anschließend werden dann die erkannten Je nach System kommen hierbei einfache Heuristiken, statistische Modelle oder Deep-Learning-Architekturen wie Convolutional Neural Network (CNN) oder Long Short-Memory Network (LSTM) zum Einsatz [9]. Die'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/78', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 88.986, 't': 442.7790146484375, 'r': 507.8, 'b': 243.45801464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 965]}]}, {'self_ref': '#/texts/79', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 18, 'bbox': {'l': 89.291, 't': 673.1160146484375, 'r': 508.114, 'b': 297.6540146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 321]}]}], 'headings': ['2.2.1. Funktionsweise von Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.1. Funktionsweise von Optical Character Recognition (OCR)\\nErkennungsgenauigkeit kann Dazu zählen etwa die Kombination mehrerer Klassifikatoren in sequentieller, paralleler oder hierarchischer Struktur sowie die kontextbasierte Analyse angrenzender Zeichen oder Wörter, um zusätzliche semantische Informationen zur Validierung heranzuziehen [4].\\nnen, also der Kontrast zwischen Textzeilen und Zwischenräumen am größten ist. mentierung, bei der das Bild in Einheiten wie Zeichen oder Wörter unterteilt wird. Zeichen mittels eines Klassifikationsmodells einer bestimmten Klasse zugeordnet. nach der Klassifikation durch verschiedene Strategien weiter gesteigert werden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/83', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.899, 't': 723.8780146484376, 'r': 507.798, 'b': 592.3020146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 753]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\nEin weit verbreitetes OCR-System ist Tesseract, welches ursprünglich zwischen 1984 und 1994 von Hewlett-Packard (HP) entwickelt wurde und seit der Veröffentlichung als Open Source im Jahr 2006-2018 von Google und mittlerweile von der Community aktiv weiterentwickelt wird. Ab Version 4 basiert Tesseract auf einem hybriden Ansatz, der klassische bildanalytische Verfahren mit Deep-Learning-Methoden kombiniert. Insbesondere kommt ab dieser Version ein rekurrentes neuronales Netz auf Basis von LSTM zum Einsatz, das nicht mehr einzelne Zeichen isoliert klassifiziert, sondern ganze Textzeilen sequenziell verarbeitet. Dadurch kann das Modell den Kontext benachbarter Zeichen nutzen, was zu einer deutlich robusteren und genaueren Zeichenerkennung'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/83', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.899, 't': 723.8780146484376, 'r': 507.798, 'b': 592.3020146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 753]}]}, {'self_ref': '#/texts/84', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.866, 't': 588.3860146484375, 'r': 507.79, 'b': 511.0070146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 461]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\nführt.\\nDie Verarbeitungsarchitektur von Tesseract umfasst mehrere aufeinanderfolgende Verarbeitungsstufen. Zu Beginn erfolgt die Vorverarbeitung, wobei Tesseract ein binarisiertes Eingabebild erwartet. Anschließend übernimmt eine interne Layoutanalyse die Identifikation von Textregionen, Zeilen und Wörtern. Mittels der CCA werden zusammenhängende Pixelbereiche - sogenannte Blobs - identifiziert, die potenziell einzelnen Zeichen oder Zeichenkomponenten entsprechen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/85', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.757, 't': 507.0900146484375, 'r': 507.799, 'b': 361.9650146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 810]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\nIm nächsten Schritt werden diese Blobs zu Textzeilen und Wörtern segmentiert. Die Zeilenfindung basiert auf einer Analyse der vertikalen Struktur der Blobs und kann auch schräg gescannte Seiten bis zu einem gewissen Grad ohne explizite Schräglagenkorrektur verarbeiten. Je nach Schriftart unterscheidet Tesseract zwischen fester und proportionaler Zeichenbreite, was Einfluss auf die Segmentierung von Wörtern und Zeichen hat. Die Zeichenerkennung erfolgt im Standardmodell ab Version 4 ausschließlich durch das LSTM-basierte neuronale Netzwerk, das die gesamte Texterkennung als sequenziellen End-to-End-Prozess durchführt. Die ältere, zweiphasige Klassifikation mit statischem und adaptivem'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/85', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.757, 't': 507.0900146484375, 'r': 507.799, 'b': 361.9650146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 810]}]}, {'self_ref': '#/texts/86', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.757, 't': 358.0490146484375, 'r': 507.799, 'b': 280.6700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 429]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\nKlassifikator steht noch als Legacy-Modus zur Verfügung, wird aber in modernen Anwendungsfällen nicht mehr verwendet.\\nErgänzend zur eigentlichen Zeichenerkennung wird eine linguistische Nachverarbeitung durchgeführt. Tesseract bewertet dabei unterschiedliche Wortkandidaten anhand von Heuristiken wie Groß- und Kleinschreibung, numerischer Struktur, Wörterbuchabgleich oder Worthäufigkeit. Obwohl kein vollständiges probabilistisches Sprachmodell integriert ist, nutzt das System Distanzwerte und Ranglisten zur Auswahl der plausibelsten Wortform.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/87', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.931, 't': 276.75401464843753, 'r': 507.796, 'b': 226.47401464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 281]}]}, {'self_ref': '#/texts/88', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 88.866, 't': 222.55701464843753, 'r': 507.791, 'b': 172.27701464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 316]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\nTrotz eines vergleichsweise kleinen Trainingsdatensatzes von lediglich 60.160 Instanzen erzielt Tesseract eine hohe Erkennungsgenauigkeit. Andere publizierte Klassifikatoren, wie etwa die Systeme von Calera oder Baird, wurden hingegen auf über einer Million Datenpunkten trainiert.\\nDie Kombination aus klassischer Bildverarbeitung, leistungsstarker LSTM-basierter Erkennungs-Engine und sprachlicher Heuristik macht diese Engine besonders leistungsfähig bei maschinengedruckten Texten. In komplexeren Anwendungsfällen, wie etwa bei stark strukturierten oder verrauschten Dokumenten, stößt das System'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/91', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 505.982, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 141]}]}], 'headings': ['2.2.2. Tesseract Optical Character Recognition (OCR)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.2.2. Tesseract Optical Character Recognition (OCR)\\njedoch an seine Grenzen, was Potenzial für die Integration externer Sprachmodelle oder spezialisierter Vorverarbeitungstechniken bietet [10].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/93', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 88.931, 't': 661.2390146484375, 'r': 508.11, 'b': 570.3110146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 530]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\nDie natürliche Sprachverarbeitung (Natural Language Processing (NLP)) ist ein bedeutender Teilbereich sowohl der Künstlichen Intelligenz als auch der Linguistik. Sie ermöglicht es, automatisiert Informationen aus unstrukturierten, textbasierten Daten zu extrahieren. Erste Ansätze zur Sprachverarbeitung lassen sich bis in die 1950er-Jahre zurückverfolgen. Damals war sie noch deutlich von der klassischen Textinformationssuche abgegrenzt; in der heutigen Praxis sind beide Bereiche jedoch zunehmend miteinander verschmolzen [11].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/94', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 88.931, 't': 566.3940146484375, 'r': 507.795, 'b': 489.0150146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 403]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\nNLP lässt sich in zwei grundlegende Teilgebiete untergliedern: das Sprachverständnis (Natural Language Understanding (NLU)) und die Sprachgenerierung (Natural Language Generation (NLG)). Während NLU auf die maschinelle Analyse von Satzstruktur, Bedeutung und Kontext abzielt, beschäftigt sich NLG mit der automatisierten Erzeugung von Text, etwa im Rahmen von Textzusammenfassungen oder Textgenerierung.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/95', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 88.899, 't': 485.0990146484375, 'r': 507.792, 'b': 394.1710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 503]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\nZiel der natürlichen Sprachverarbeitung ist es, spezifische Aufgaben innerhalb algorithmischer Systeme zu übernehmen. Zahlreiche Teilbereiche finden bereits Anwendung in der Praxis - beispielsweise die automatische Textzusammenfassung, die maschinelle Übersetzung oder die Erkennung benannter Entitäten (NER), etwa von Organisationen oder Personennamen in Texten. Auch die optische Zeichenerkennung (OCR) zählt hierzu, mit der Texte auf Bildern oder in gescannten Dokumenten digitalisiert werden können.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/96', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 89.291, 't': 390.2550146484375, 'r': 507.8, 'b': 312.8760146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 440]}]}, {'self_ref': '#/texts/97', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 89.291, 't': 308.96001464843744, 'r': 507.794, 'b': 285.77701464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 144]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\nBasierend auf diesen Anwendungsfeldern lassen sich modulare Verarbeitungssysteme nach dem Prinzip der Unix-Pipeline konzipieren. Dabei wird die Ausgabe eines Subsystems als Eingabe für das nächste genutzt, wodurch sich komplexe Sprachverarbeitungssysteme aufbauen lassen. Diese Systeme können je nach Anwendungsfall sequentiell, parallel oder hierarchisch organisiert sein [11] und ermöglichen eine flexible, austauschbare Architektur [12].\\nBevor es zur Sprachverarbeitung kommt, muss der Text zuerst vorverarbeitet werden. Ohne die Vorverarbeitung sind NLP-Prozesse gar nicht möglich.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/98', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 89.291, 't': 281.8610146484375, 'r': 506.229, 'b': 231.58101464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 271]}]}, {'self_ref': '#/texts/99', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 20, 'bbox': {'l': 88.931, 't': 227.6640146484375, 'r': 507.8, 'b': 163.83501464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 395]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\nIm ersten Schritt kann der Text optional normalisiert werden, bedeutet in eine standardisierte Form gebracht werden. Dies erreicht man durch Umwandeln aller Buchstaben in Kleinbuchstaben, Entfernen von Sonderzeichen und Entfernen oder Umwandeln von Umlauten und Akzenten.\\nDann folgt die Tokenisierung, das ist die Zerlegung eines Textes in kleinere Einheiten, sogenannte Tokens [13]. Diese Tokens können Wörter, Satzzeichen oder Untereinheiten von Wörtern sein und bilden eine zentrale Grundlage für die algorithmische Verarbeitung natürlicher Sprache. Nach der Tokenisierung werden die Tokens anhand eines festgelegten Vokabulars einer ID zugeordnet und anschließend'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/102', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 88.931, 't': 754.4110146484375, 'r': 507.795, 'b': 649.9340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 605]}]}], 'headings': ['2.3. Natural Language Processing (NLP)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3. Natural Language Processing (NLP)\\njeder Token in einen hochdimensionalen Vektor transformiert, sogenannte Input Embeddings, die semantische Informationen über die Bedeutung der einzelnen Tokens enthalten. Moderne Transformer-Modelle ergänzen diese Embeddings zusätzlich um Positional Encodings, welche Informationen zur Reihenfolge der Tokens in der Eingabesequenz bereitstellen. Diese mehrstufige Aufbereitung, bestehend aus Normalisierung, Tokenisierung, Einbettung und Positionskodierung, bereitet die Eingabedaten auf, sodass mit NLP-Methoden syntaktische und semantische Zusammenhänge erkannt und weiterverarbeitet werden können [14].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/104', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 89.291, 't': 589.2430146484376, 'r': 507.8, 'b': 484.76601464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 622]}]}], 'headings': ['2.3.1. Named Entity Recognition (NER)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.1. Named Entity Recognition (NER)\\nDestillierte Informationsextraktion aus unstrukturierten Daten wie z.B. Dokumenten ist ein sehr wichtiges Teilgebiet der natürlichen Sprachverarbeitung und ist unerlässlich, um Künstliche Intelligenz (KI)-Systeme für reale Anwendungen zu implementieren. Die Named Entity Recognition (NER) ist eine Methode der natürlichen Sprachverarbeitung, die dazu dient, Entitäten aus der realen Welt automatisiert zu erkennen und sie vordefinierten semantischen Kategorien (z.B. Personen, Organisationen oder Orte) zuzuordnen. Die Umsetzung erfolgt entweder regelbasiert oder unter Einsatz von Verfahren des maschinellen Lernens [15].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/105', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 88.899, 't': 480.85001464843754, 'r': 508.111, 'b': 430.56901464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 254]}]}, {'self_ref': '#/texts/106', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 89.291, 't': 426.65301464843753, 'r': 507.799, 'b': 362.8230146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 343]}]}, {'self_ref': '#/texts/107', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 89.291, 't': 349.5480146484375, 'r': 367.876, 'b': 339.8820146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 54]}]}], 'headings': ['2.3.1. Named Entity Recognition (NER)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.1. Named Entity Recognition (NER)\\nAbbildung 2.2 zeigt deutlich den Anstieg der Publikationen im Bereich der NER in den letzten 30 Jahren - insbesondere bedingt durch neue Modellarchitekturen. Eine zentrale Rolle spielt hierbei auch die Transformer-Architektur (vgl. Unterabschnitt 2.4.2).\\nDie NER ermöglicht es, relevante Entitäten aus unstrukturiertem Text zu identifizieren und herauszufiltern, um diese im nächsten Schritt in strukturierte Daten umzuwandeln oder für weitere Schritte eines übergeordneten Systems zur Verfügung zu stellen. Dies können unter anderem Datum, Namen, Events, Orte oder auch numerische Werte sein [12].\\nSei T eine gegebene Token-Sequenz (vgl. Abschnitt 2.3)'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/108', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 21, 'bbox': {'l': 254.007, 't': 325.0400146484376, 'r': 341.27, 'b': 314.1560146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 31]}]}, {'self_ref': '#/texts/109', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 89.291, 't': 300.49901464843754, 'r': 505.98, 'b': 277.3170146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 128]}]}, {'self_ref': '#/texts/110', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 21, 'bbox': {'l': 192.282, 't': 262.47501464843754, 'r': 402.996, 'b': 251.7360146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 56]}]}, {'self_ref': '#/texts/111', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 89.291, 't': 237.9670146484375, 'r': 505.986, 'b': 201.2020146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 179]}]}, {'self_ref': '#/texts/112', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 21, 'bbox': {'l': 88.866, 't': 187.8950146484375, 'r': 505.987, 'b': 164.7120146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 159]}]}, {'self_ref': '#/texts/115', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 9.82573560586824, 't': 817.4492092442975, 'r': 384.82252108763913, 'b': 793.3514597218226, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 41]}]}, {'self_ref': '#/texts/116', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 257.33333324583333, 't': 788.1113261943904, 'r': 276.66666657916664, 'b': 776.8244409484887, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 3]}]}, {'self_ref': '#/texts/117', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 89.291, 't': 754.4440146484375, 'r': 469.425, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 76]}]}], 'headings': ['2.3.1. Named Entity Recognition (NER)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.1. Named Entity Recognition (NER)\\n<!-- formula-not-decoded -->\\nderen Ziel es ist, eine Menge vordefinierter Entitäten zu identifizieren. Dabei besteht die Aufgabe darin, eine Menge von Tupeln\\n<!-- formula-not-decoded -->\\nzu erzeugen. Hierbei bezeichnen Is und Ie den Beginn bzw. das Ende einer Entität in der Sequenz, während l die zugehörige Kategorie aus einer vordefinierten Menge L repräsentiert.\\nEin typisches Beispiel - dargestellt in Abbildung 2.1 - ist der Satz: \\'Barack Obama wurde in Honolulu geboren.\\' Ein NER-System erkennt darin \\'Barack Obama\\' als\\n„Barack Obama wurde in Honolulu geboren.\"\\nOrt\\nEntität des Typs Person und \\'Honolulu\\' als Entität des Typs Ort (vgl. [12]).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/118', 'parent': {'$ref': '#/pictures/3'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 22, 'bbox': {'l': 88.899, 't': 658.8690146484375, 'r': 505.982, 'b': 635.6860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 107]}]}], 'headings': ['2.3.1. Named Entity Recognition (NER)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.1. Named Entity Recognition (NER)\\nAbbildung 2.1.: Beispiel für Named Entity Recognition mit erkannten Entitäten und zugehörigen Entitätstypen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/120', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 89.291, 't': 570.9430146484375, 'r': 507.799, 'b': 534.2120146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 198]}]}], 'headings': ['2.3.2. Arten benannter Entitäten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.2. Arten benannter Entitäten\\nIm Rahmen der NER lassen sich benannte Entitäten anhand ihrer strukturellen Eigenschaften in unterschiedliche Kategorien einteilen: verschachtelte, nichtfortgesetzte und fortgesetzte Entitäten [12].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/122', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 87.59, 't': 474.0250146484375, 'r': 507.499, 'b': 410.1950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 404]}]}], 'headings': ['Verschachtelte benannte Entitäten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Verschachtelte benannte Entitäten\\nVerschachtelte benannte Entitäten (nested named entities) treten auf, wenn eine Entität vollständig oder teilweise in einer anderen enthalten ist. Ein Beispiel ist der Satz: 'Barack Obama wurde in Honolulu, Hawaii geboren.' Hier stellt 'Honolulu, Hawaii' eine verschachtelte Entität dar, wobei 'Honolulu' als Hauptstadt und 'Hawaii' als US-Bundesstaat jeweils eigenständige geografische Entitäten bilden.\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/124', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 87.59, 't': 350.0090146484375, 'r': 507.505, 'b': 272.6300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 442]}]}], 'headings': ['Nicht-fortgesetzte benannte Entitäten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Nicht-fortgesetzte benannte Entitäten\\nNicht-fortgesetzte benannte Entitäten (non-continued named entities) bestehen aus zusammenhängenden, klar abgegrenzten Textabschnitten. Im Satz 'Google wurde von Larry Page und Sergey Brin gegründet' lassen sich die Entitäten 'Google', 'Larry Page' und 'Sergey Brin' eindeutig als voneinander getrennte Einheiten erkennen. Klassische NER-Modelle können diese Form der Entitäten durch einfache Sequenzlabeling-Methoden zuverlässig extrahieren.\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/126', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 22, 'bbox': {'l': 89.291, 't': 212.4430146484375, 'r': 508.11, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 319]}]}, {'self_ref': '#/texts/129', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 12.666665679659014, 't': 687.2233482284375, 'r': 20.000000920340977, 'b': 662.5566815617708, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/130', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 23.95883448648412, 't': 825.9820576703332, 'r': 50.70783249266901, 'b': 813.797971824386, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/131', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 23.94930645573383, 't': 798.0182347950177, 'r': 47.38402681299294, 'b': 788.4284609811343, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/132', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 13.333333151851855, 't': 777.8900147262153, 'r': 47.33333315185185, 'b': 763.8900147262152, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/133', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 24.000000193333324, 't': 747.8900145617708, 'r': 47.33333352666666, 'b': 739.2233478951041, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/134', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 28.666666440000004, 't': 723.2233479484375, 'r': 51.33333310666668, 'b': 714.5566812817708, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/135', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 29.333333453333335, 't': 698.5566812217708, 'r': 49.33333345333333, 'b': 689.2233478884375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/136', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 29.29167702203068, 't': 673.3302097838377, 'r': 51.37499001031193, 'b': 664.4498196166014, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/137', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 29.33333355333333, 't': 648.5566813617709, 'r': 51.333333553333325, 'b': 639.8900146951041, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}, {'page_no': 23, 'bbox': {'l': 12.666662182853193, 't': 765.8900156567709, 'r': 20.666670130139163, 'b': 685.2233489901041, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [5, 22]}]}, {'self_ref': '#/texts/138', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 81.33333387142856, 't': 821.2233480055803, 'r': 156.6666672047619, 'b': 813.890014672247, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 16]}]}, {'self_ref': '#/texts/139', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 56.66666663461539, 't': 805.8900146510016, 'r': 74.6666666346154, 'b': 804.5566813176683, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/140', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 61.97289547703639, 't': 608.6301945928672, 'r': 85.36043820164576, 'b': 599.8165012284059, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/141', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 67.21666211153654, 't': 811.2233481863921, 'r': 268.86666618054693, 'b': 798.461443152009, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 45]}]}, {'self_ref': '#/texts/142', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 303.9999994500001, 't': 764.5566813984375, 'r': 425.9999994500001, 'b': 754.5566813984375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 23]}]}], 'headings': ['Fortgesetzte benannte Entitäten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Fortgesetzte benannte Entitäten\\nZuletzt gibt es noch die fortgesetzten benannten Entitäten (continued named entities), diese setzen sich aus mehreren, nicht direkt aufeinanderfolgenden Textbestandteilen zusammen, die dennoch eine gemeinsame semantische Einheit bilden. Ein Beispiel ist der Satz: 'Der Patient zeigte einen produktiven Husten mit weißem\\nNumi\\n1600-\\n1400\\n· 1200\\n1000\\n800 -\\n600-\\n400 -\\n200- ber of publicatio\\nNER Publications\\n-----\\n1995\\n-- Deep Learning Era (Collobert et ali, 2011)\\nTransformers Era (BERT)\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/143', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 507.795, 'b': 690.5810146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 337]}]}, {'self_ref': '#/texts/151', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 233.33333385999995, 't': 691.2233481217709, 'r': 327.3333338599999, 'b': 677.2233481217709, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 17]}]}, {'self_ref': '#/texts/152', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 23, 'bbox': {'l': 126.433, 't': 419.55901464843754, 'r': 468.455, 'b': 409.9260146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 66]}]}], 'headings': ['Fortgesetzte benannte Entitäten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Fortgesetzte benannte Entitäten\\noder blutigem Auswurf.' Die Wortgruppen 'Husten mit weißem Auswurf' und 'Husten mit blutigem Auswurf' beziehen sich beide auf dasselbe Symptom und bilden zusammen eine fortgesetzte Entität. Die Erkennung solcher Strukturen erfordert kontextsensitives Modellverhalten, wie es etwa durch Transformer-basierte Architekturen ermöglicht wird.\\nDeep Learning Era\\nAbbildung 2.2.: Publikationen zu NER in den letzten 30 Jahren [15]\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/154', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 89.291, 't': 344.8710146484375, 'r': 506.228, 'b': 294.59001464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 253]}]}, {'self_ref': '#/texts/155', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 89.291, 't': 290.6740146484375, 'r': 507.799, 'b': 226.84401464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 331]}]}], 'headings': ['2.3.3. spaCy: Framework für NLP in Python'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.3. spaCy: Framework für NLP in Python\\nEin etabliertes und weit verbreitetes Framework für fortgeschrittene Anwendungen im Bereich des Natural Language Processing (NLP) ist spaCy 3 . Es wurde im Jahr 2015 von der Firma Explosion AI veröffentlicht und ist in Python sowie Cython implementiert.\\nspaCy ermöglicht die effiziente Entwicklung vollständiger NLP-Pipelines auf Produktionsniveau, ohne das Python-Ökosystem verlassen zu müssen. Die Architektur des Frameworks ist dabei modular aufgebaut und bietet standardisierte Komponenten wie Tokenisierung, Lemmatisierung, Part-of-Speech-Tagging, NER sowie syntaktisches Parsing.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/156', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 23, 'bbox': {'l': 89.291, 't': 222.9280146484375, 'r': 508.111, 'b': 186.19601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 240]}]}, {'self_ref': '#/texts/157', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 23, 'bbox': {'l': 94.436, 't': 172.14601464843747, 'r': 205.855, 'b': 162.96001464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/160', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 508.11, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 161]}]}], 'headings': ['2.3.3. spaCy: Framework für NLP in Python'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.3.3. spaCy: Framework für NLP in Python\\nEin wesentliches Merkmal von spaCy ist seine Orientierung an praktischen, performanten Anwendungen: Statt einer Vielzahl theoretischer Methoden liegt der Fokus auf Geschwindigkeit, Robustheit und einfacher Integration in produktive Systeme.\\n3 https://spacy.io/api\\nDurch eine aktive Entwickler-Community sowie regelmäßige Aktualisierungen fließen aktuelle Forschungsergebnisse kontinuierlich in die Weiterentwicklung ein [13].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/162', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 88.931, 't': 661.2390146484375, 'r': 508.111, 'b': 529.6630146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 719]}]}], 'headings': ['2.4. Large Language Models (LLM)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4. Large Language Models (LLM)\\nEin Meilenstein im NLP stellen große Sprachmodelle (Large Language Models (LLMs)) dar, da sie durch ihre besondere Architektur (vgl. Unterabschnitt 2.4.2) in sehr vielen Bereichen einsetzbar sind. Bei einem LLM handelt es sich um ein komplexes mathematisches Modell, das in der Lage ist, auf Basis eines gegebenen Texteingangs eine Wahrscheinlichkeitsverteilung über einen gewissen Wortschatz zu berechnen. Die Eingabe erfolgt in natürlicher Sprache und wird intern zunächst in Texttokens umgewandelt, die in Form von numerischen Vektoren (Embeddings) repräsentiert werden. Diese dienen dem Modell als Grundlage für die Inferenz. Die resultierenden Embeddings werden anschließend wieder in natürliche Sprache'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/162', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 88.931, 't': 661.2390146484375, 'r': 508.111, 'b': 529.6630146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 719]}]}, {'self_ref': '#/texts/163', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 88.866, 't': 525.7470146484375, 'r': 507.501, 'b': 461.9170146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 357]}]}], 'headings': ['2.4. Large Language Models (LLM)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4. Large Language Models (LLM)\\ndekodiert.\\nDas Training eines LLM erfolgt auf sehr großen Textdatensätzen aus dem Internet, wobei die Modellparameter (Gewichte) durch Optimierungstechniken angepasst werden [16]. Dadurch ist das Modell in der Lage, komplexe Strukturen der Sprache zu erfassen und kontextabhängige Zusammenhänge zu erkennen, was den Eindruck einer intelligenten Interaktion vermittelt.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/164', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 88.931, 't': 458.0010146484375, 'r': 507.8, 'b': 367.0730146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 531]}]}], 'headings': ['2.4. Large Language Models (LLM)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4. Large Language Models (LLM)\\nTechnisch basieren LLMs auf der sogenannten Transformer-Architektur, die als Meilenstein in der Verarbeitung natürlicher Sprache (NLP) gilt. Durch den Einsatz des sogenannten Attention-Mechanismus ist es möglich, den gesamten Textkontext zu berücksichtigen, was gegenüber früheren Modellen wie Recurrent Neural Networks (RNNs) oder Long Short-Term Memory Networks (LSTMs) eine signifikante Verbesserung darstellt. Zudem ermöglicht dieser Mechanismus die parallele Verarbeitung langer Textsequenzen (vgl. Unterabschnitt 2.4.2) [17].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/165', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 89.291, 't': 363.1560146484375, 'r': 507.799, 'b': 312.8760146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 266]}]}], 'headings': ['2.4. Large Language Models (LLM)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4. Large Language Models (LLM)\\nDiese Eigenschaften machen LLMs äußerst flexibel einsetzbar. Typische Anwendungsfelder umfassen unter anderem die Zusammenfassung von Texten, maschinelle Übersetzung, Textgenerierung sowie die gezielte Informationsextraktion aus Dokumenten (vgl. Abschnitt 2.1) [14].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/167', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 89.291, 't': 252.18601464843755, 'r': 458.979, 'b': 242.5530146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 71]}]}, {'self_ref': '#/texts/168', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 24, 'bbox': {'l': 254.007, 't': 227.71101464843753, 'r': 341.27, 'b': 216.82601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 31]}]}, {'self_ref': '#/texts/169', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 24, 'bbox': {'l': 89.291, 't': 203.2020146484375, 'r': 431.54, 'b': 193.53601464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 68]}]}, {'self_ref': '#/texts/170', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 24, 'bbox': {'l': 252.739, 't': 178.69401464843747, 'r': 342.537, 'b': 167.60501464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 29]}]}], 'headings': ['2.4.1. Funktionsweise eines Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.1. Funktionsweise eines Large Language Models\\nEin LLM erhält als Eingabe eine Sequenz von Tokens (vgl. Abschnitt 2.3)\\n<!-- formula-not-decoded -->\\nund generiert für jede Position i eine Wahrscheinlichkeitsverteilung\\n<!-- formula-not-decoded -->'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/173', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 88.931, 't': 754.4110146484375, 'r': 507.799, 'b': 636.3840146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 725]}]}], 'headings': ['2.4.1. Funktionsweise eines Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.1. Funktionsweise eines Large Language Models\\nüber das Vokabular des Modells. Diese Verteilung beschreibt die Wahrscheinlichkeit, mit der ein mögliches nächstes Token xi basierend auf dem bisherigen Kontext generiert wird. Das Modell folgt dabei einem autoregressiven Ansatz, wodurch zu jedem Zeitpunkt das nächste Token ausschließlich auf Grundlage der vorangegangenen Tokens vorhergesagt wird. LLM werden als large bezeichnet, da sie typischerweise über mehrere Milliarden Parameter verfügen und auf umfangreichen Datensätzen trainiert werden. Ihre Leistungsfähigkeit zeigt sich unter anderem in der Fähigkeit zu generalisieren und eine Vielzahl an Aufgaben der natürlichen Sprachverarbeitung NLP ohne aufgabenspezifisches Fine-Tuning der Modellparameter zu lösen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/173', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 88.931, 't': 754.4110146484375, 'r': 507.799, 'b': 636.3840146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 725]}]}], 'headings': ['2.4.1. Funktionsweise eines Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.1. Funktionsweise eines Large Language Models\\n[16].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/175', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 89.291, 't': 575.6940146484375, 'r': 507.799, 'b': 511.8640146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 363]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nDer Transformer stellt seit seiner Einführung durch Google die grundlegende Architektur für moderne LLMs dar und hat klassische sequenzielle Modelle wie RNNs oder LSTMs weitgehend abgelöst. Sein zentrales Konzept ist der Self-AttentionMechanismus, der es ermöglicht, Zusammenhänge zwischen beliebigen Positionen innerhalb einer Eingabesequenz effizient zu lernen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/176', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 88.866, 't': 507.9480146484375, 'r': 508.111, 'b': 295.0770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1214]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nEin Transformer-Modell besteht typischerweise aus mehreren gestapelten Encoderund/oder Decoder-Layern, wobei jeder Layer im Kern auf dem Multi-Head-SelfAttention-Mechanismus sowie nachgelagerten Feedforward-Schichten basiert. Die Self-Attention berechnet für jedes Token der Eingabe einen gewichteten Kontextvektor, indem alle anderen Token der Sequenz berücksichtigt werden. Dadurch werden sowohl lokale als auch globale Abhängigkeiten innerhalb der Sequenz effizient erfasst und verarbeitet. Die Attention-Funktion kann allgemein als eine Abbildung eines Query und einer Menge von Key-Value-Paaren auf einen Output beschrieben werden, wobei Query, Keys, Values und Output jeweils Vektoren sind. Der Output wird als gewichtete Summe der Values berechnet, wobei'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/176', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 88.866, 't': 507.9480146484375, 'r': 508.111, 'b': 295.0770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1214]}]}, {'self_ref': '#/texts/177', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 25, 'bbox': {'l': 199.356, 't': 273.10501464843753, 'r': 506.715, 'b': 243.51701464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 54]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\ndie Gewichtung durch eine Kompatibilitätsfunktion zwischen Query und Key bestimmt wird. Im Transformer wird hierzu die sogenannte Scaled Dot-Product Attention verwendet. Die Eingabe besteht aus Queries und Keys der Dimension dk sowie Values der Dimension dv . Für jeden Query wird das Skalarprodukt mit allen Keys berechnet, durch √ dk skaliert und anschließend eine Softmax-Funktion angewendet, um die Gewichte zu bestimmen. Die Formel hierfür lautet:\\n<!-- formula-not-decoded -->'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/178', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 25, 'bbox': {'l': 89.291, 't': 226.04701464843754, 'r': 507.799, 'b': 162.2170146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 390]}]}, {'self_ref': '#/texts/181', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 13.999999120000012, 't': 827.9110988792809, 'r': 151.33333245333336, 'b': 817.2604964696424, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 28]}]}, {'self_ref': '#/texts/182', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 62.00000018888888, 't': 715.4141110617156, 'r': 84.66666685555555, 'b': 706.7604966038843, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/183', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 58.66666688095237, 't': 690.118930349126, 'r': 88.66666688095238, 'b': 682.1309785418971, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/184', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 55.3333333, 't': 678.1370027134074, 'r': 61.3333333, 'b': 666.8207376531665, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/185', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 82.66666669166666, 't': 678.802665101073, 'r': 88.66666669166666, 'b': 666.8207373902296, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/186', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 54.66666670000001, 't': 665.4894121611383, 'r': 62.6666667, 'b': 656.1701350527046, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/187', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 89.291, 't': 603.0520146484375, 'r': 106.669, 'b': 593.4190146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 3]}]}, {'self_ref': '#/texts/188', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 26, 'bbox': {'l': 205.417, 't': 592.7720146484376, 'r': 506.715, 'b': 576.9970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 52]}]}, {'self_ref': '#/texts/189', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 89.291, 't': 560.0860146484375, 'r': 405.688, 'b': 550.4530146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 60]}]}, {'self_ref': '#/texts/190', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 26, 'bbox': {'l': 255.684, 't': 538.8480146484375, 'r': 338.593, 'b': 470.7220146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 90]}]}, {'self_ref': '#/texts/191', 'parent': {'$ref': '#/pictures/6'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 26, 'bbox': {'l': 101.964, 't': 232.5440146484375, 'r': 492.924, 'b': 222.91101464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 75]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nHierbei werden die sogenannten Query-, Key- und Value-Matrizen aus der Eingabesequenz erzeugt und jeweils durch lineare Transformationen berechnet. Das Matrixprodukt QK T ermöglicht es dem Modell, für jedes Token die Relevanz aller anderen Token explizit zu gewichten. Die Skalierung durch √ dk verhindert, dass bei großen Wertebereichen der Softmax-Input zu hohe Varianzen aufweist, was zu\\nScaled Dot-Product Attention\\nScale\\nMatMul\\n1\\n1\\nQ\\nmit\\n<!-- formula-not-decoded -->\\nDie Projektionsmatrizen besitzen dabei folgende Dimensionen:\\n<!-- formula-not-decoded -->\\nAbbildung 2.3.: Scaled Dot-Produkt Attention und Multi-Head Attention [18].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/192', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 89.291, 't': 207.04001464843748, 'r': 507.799, 'b': 170.30901464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 233]}]}, {'self_ref': '#/texts/193', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 262.66666594761904, 't': 827.2454362971466, 'r': 363.3333326142858, 'b': 817.9261591887129, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/194', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 298.66666660833334, 't': 813.9321833938629, 'r': 310.66666660833334, 'b': 802.615918333622, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/195', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 285.3333335291666, 't': 802.6159182878577, 'r': 316.6666668625, 'b': 787.9713399746047, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/196', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 287.99999984444446, 't': 771.3297737326577, 'r': 317.3333331777778, 'b': 762.6761592748264, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}, {'page_no': 26, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 450.033, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [7, 74]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nDie maximale Kontextlänge eines Transformers, also die Anzahl der Token, die das Modell in einem Durchgang berücksichtigen kann, ist eine zentrale architekturelle Eigenschaft. Sie wird maßgeblich durch die quadratische Skalierung der\\nMulti-Head Attention\\n1\\n(Linear\\nConcat kleinen Gradienten und somit erschwerter Optimierung führen könnte.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/197', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 89.291, 't': 740.8620146484375, 'r': 507.798, 'b': 649.9340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 487]}]}, {'self_ref': '#/texts/198', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 258.00000002666667, 't': 644.1882073263291, 'r': 266.0000000266667, 'b': 634.8689302178954, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/199', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 26, 'bbox': {'l': 338.6666667333334, 't': 643.5225448022026, 'r': 346.6666667333334, 'b': 635.5345929949737, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/200', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 26, 'bbox': {'l': 172.475, 't': 625.5390146484375, 'r': 506.715, 'b': 611.8980146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 67]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nUmdie Modellierungskapazität weiter zu erhöhen, wird im Transformer die MultiHead Attention eingesetzt. Dabei werden mehrere Attention-Layer (\"Heads\") parallel ausgeführt, die jeweils eigene gewichtete Kombinationen der Eingabesequenz lernen. Die Ergebnisse der einzelnen Heads werden anschließend zusammengeführt und erneut linear transformiert. Dies ermöglicht dem Modell, verschiedene Aspekte der Beziehungen zwischen Tokens gleichzeitig zu erfassen und komplexere Muster zu erkennen.\\nV\\nQ\\n<!-- formula-not-decoded -->'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/203', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 507.795, 'b': 677.0320146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 420]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nSelf-Attention-Operation limitiert, da sowohl der Rechen- als auch der Speicherbedarf mit O ( n 2 ) in der Sequenzlänge n wachsen. Praktisch legen Modellentwickler die Kontextlänge im Vorfeld als festen Wert fest, der sich an den Hardwarekapazitäten und den Anforderungen der jeweiligen Anwendung orientiert. Eine Erhöhung der Kontextlänge über die Trainingskonfiguration hinaus ist meist nur eingeschränkt möglich [17].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/204', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 89.291, 't': 663.7240146484376, 'r': 506.219, 'b': 586.3450146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 406]}]}], 'headings': ['2.4.2. Transformer'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.2. Transformer\\nDer Transformer hat sich insbesondere durch seine Flexibilität, Parallelisierbarkeit und Effektivität beim Lernen komplexer Abhängigkeiten als Standardarchitektur für NLP-Aufgaben etabliert. Moderne LLMs wie GPT, BERT oder T5 basieren alle auf Varianten des Transformers und nutzen dessen Fähigkeit, um Aufgaben aus den Bereichen NLU und NLG (vgl. Abschnitt 2.3) zu modellieren und effizient zu lösen [19].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/206', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 88.899, 't': 525.6550146484375, 'r': 506.225, 'b': 434.7270146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 510]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nIm Mai 2024 wurde der Generative Pre-trained Transformer 4 Omni (GPT-4o) von OpenAI vorgestellt und repräsentiert einen bedeutenden Fortschritt im Bereich der multimodalen LLM. Im Gegensatz zu seinen Vorgängermodellen, die primär auf die Verarbeitung von Textdaten spezialisiert waren, ermöglicht GPT-4o die Integration und Verarbeitung unterschiedlicher Datenmodalitäten wie Text, Bild und Audio in beliebigen Kombinationen. Dies umfasst sowohl das Verarbeiten als auch das Generieren dieser Modalitäten [20].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/207', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 89.291, 't': 430.8110146484375, 'r': 507.794, 'b': 380.5300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 270]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nZudem weist GPT-4o eine deutliche Verbesserung hinsichtlich der Geschwindigkeit und Effizienz im Vergleich zu früheren Versionen auf. Darüber hinaus setzt das Modell neue Maßstäbe in Bezug auf Genauigkeit, Kontextverständnis und Flexibilität bei der Aufgabenbearbeitung.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/208', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 89.291, 't': 376.6140146484375, 'r': 507.799, 'b': 163.74301464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1273]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nDie multimodale Architektur von GPT-4o erlaubt eine nahtlose Kontextverknüpfung zwischen den verschiedenen Datentypen. Durch die gleichzeitige Verwendung mehrerer Modalitäten als Ein- und Ausgabeparameter eröffnet GPT-4o neue Anwendungsszenarien, etwa im Bereich der Dokumentenverarbeitung, Barrierefreiheit sowie für komplexe Assistenzsysteme. Beispielsweise kann das Modell ein Bild analysieren, eine darin enthaltene Fragestellung in Textform erkennen, diese semantisch interpretieren und daraufhin eine passende Antwort in Textform geben [21]. Durch die Beschaffenheit multimodaler LLMs ist es möglich, Teil- oder Gesamtprozesse von klassischen Verfahren der Informationsextraktion wie'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/208', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 27, 'bbox': {'l': 89.291, 't': 376.6140146484375, 'r': 507.799, 'b': 163.74301464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1273]}]}, {'self_ref': '#/texts/211', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 29.33333326666667, 't': 621.8900147026042, 'r': 42.6666666, 'b': 613.2233480359375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 2]}]}, {'self_ref': '#/texts/212', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 22.622663098895885, 't': 552.7787892307672, 'r': 65.37733737461203, 'b': 543.6679067895645, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/213', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 22.434755290900455, 't': 540.774983342133, 'r': 64.89004958207884, 'b': 530.1122858679712, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}, {'self_ref': '#/texts/214', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 77.99999966190477, 't': 677.8900146103422, 'r': 125.3333329952381, 'b': 669.8900146103422, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/215', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 91.33333316111111, 't': 663.2233479484374, 'r': 111.99999982777778, 'b': 655.2233479484374, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/216', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 85.92658587934778, 't': 653.4967731754401, 'r': 117.40674691043502, 'b': 644.2832563043056, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/217', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 77.99999952, 't': 617.8900146084375, 'r': 125.99999952, 'b': 609.8900146084375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/218', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 81.32047245906126, 't': 603.290335938933, 'r': 122.67952702449095, 'b': 595.156359956267, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/219', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 84.63053863303902, 't': 593.3701954728566, 'r': 119.36946075217965, 'b': 584.4098339921437, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/220', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 90.66666671111112, 't': 523.8900145762153, 'r': 112.00000004444445, 'b': 515.2233479095487, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/221', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 79.99045349745047, 't': 513.9352317504013, 'r': 124.00954732883069, 'b': 504.5114640247746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}, {'self_ref': '#/texts/222', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 87.33333332777778, 't': 480.5566812317708, 'r': 115.99999999444442, 'b': 470.5566812317708, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/223', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 174.6297201233825, 't': 821.3489274401007, 'r': 206.03694668588253, 'b': 811.7644350745816, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/224', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 163.33333295238097, 't': 809.2233479484375, 'r': 216.66666628571429, 'b': 800.5566812817708, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 13]}]}, {'self_ref': '#/texts/225', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 173.29875786238958, 't': 786.6888812156554, 'r': 206.03457481795593, 'b': 777.7578147025939, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/226', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 176.61551380318951, 't': 762.7374963465104, 'r': 202.0511522309239, 'b': 755.0425328913102, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/227', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 165.98049932346225, 't': 738.6660166506426, 'r': 214.019500788306, 'b': 729.7806794568356, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nOCR, OCR-Nachverarbeitung oder NER zu ersetzen [22]. Durch das zusätzliche Semantikverständnis, welches durch das LLM im Training erlernt wird, haben diese Systeme zusätzliche Fähigkeiten, welche sich von klassischen Verfahren deutlich abheben. So ist es möglich, das System mit benötigtem Kontext anzureichern, um so bessere Ergebnisse zu erzielen. Insgesamt stellt GPT-4o einen Paradigmenwechsel innerhalb der LLMs dar, da die Grenzen zwischen den einzelnen Datenmodalitäten zunehmend kleiner werden und eine multimodale, KI-gestützte Informationsverarbeitung ermöglicht wird [21].\\nNx\\nPositional\\nEncoding\\nAdd & Norm\\nFeed\\nForward\\nAdd & Norm\\nMulti-Head\\nAttention\\nInput\\nEbedding\\nInputs\\nOutput\\nProbabilities\\nSoftmax\\nLinear\\nAdd & Norm'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/228', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 179.33333312666664, 't': 723.2233479551041, 'r': 199.99999979333333, 'b': 715.2233479551041, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 4]}]}, {'self_ref': '#/texts/229', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 173.98945903995886, 't': 712.5990546802581, 'r': 206.0105416001802, 'b': 704.5143080015879, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/230', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 166.666667, 't': 687.2233480103423, 'r': 213.33333366666668, 'b': 679.2233480103423, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/231', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 169.2734436031993, 't': 671.5715064754404, 'r': 210.05988922087508, 'b': 663.5418561051605, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/232', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 28, 'bbox': {'l': 159.96344989319246, 't': 469.42581123692236, 'r': 218.0365496653279, 'b': 458.3542182702069, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 15]}]}, {'self_ref': '#/texts/233', 'parent': {'$ref': '#/pictures/7'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 28, 'bbox': {'l': 88.899, 't': 276.84501464843754, 'r': 505.98, 'b': 253.66201464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 128]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nFeed\\nForward\\nAdd & Norm\\nMulti-Head\\n(shifted right)\\nAbbildung 2.4.: Transformer-Modell mit Self-Attention-Mechanismus, bestehend aus Encoder, Decoder und Multi-Head Attention [18].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/247', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.798, 'b': 609.2860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 851]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nAußerdem stellt das Modell einen signifikanten Fortschritt im Bereich der natürlichen Sprachverarbeitung dar. Aufgrund seiner umfangreichen Trainingsdaten und fortgeschrittenen Architektur ist das Modell in der Lage, komplexe Textdaten zu analysieren, relevante Informationen präzise zu extrahieren und diese in strukturierter Form aufzubereiten. Dadurch eignet es sich insbesondere für Aufgaben der Informationsextraktion und -strukturierung in unstrukturierten Dokumenten. Im Kontext der Dokumentenverarbeitung ermöglicht dies beispielsweise die automatische Erkennung und Klassifikation von Entitäten, das Verständnis semantischer Zusammenhänge sowie die Generierung von Zusammenfassungen oder Antworten auf'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/247', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.798, 'b': 609.2860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 851]}]}], 'headings': ['2.4.3. Multimodales LLM GPT-4o'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.3. Multimodales LLM GPT-4o\\nspezifische Fragestellungen. Dadurch wird die Grundlage für eine effiziente und weitgehend automatisierte Datenverarbeitung geschaffen [21].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/249', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 88.899, 't': 548.5960146484375, 'r': 508.113, 'b': 362.8230146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1123]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nAls Prompt wird die Texteingabe eines LLMs bezeichnet, die in natürlicher Sprache erfolgt. Prompt Engineering ist ein zentraler Ansatz, um die Ausgabequalität von Sprachmodellen (LLMs) gezielt zu steuern und zu optimieren. Durch die systematische Gestaltung und Anpassung von Prompts kann nicht nur die Genauigkeit der Ergebnisse verbessert, sondern auch die Fehlerquote signifikant reduziert werden. Prompt Engineering ermöglicht es, die Fähigkeiten großer Sprachmodelle effektiv auszuschöpfen, indem Aufgabenstellungen so formuliert werden, dass das Modell relevante Informationen korrekt extrahiert, verarbeitet und während der Inferenz im Kontext verwendet. Die Entwicklung eines optimierten Prompts ist nicht trivial, da bei der Konstruktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/249', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 88.899, 't': 548.5960146484375, 'r': 508.113, 'b': 362.8230146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1123]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nverschiedene Faktoren zu berücksichtigen sind. Dazu zählen das vorherige Training des Modells sowie Aspekte wie Wortwahl, Stil, Ton, Struktur und Gesamtkontext. Ein schlecht konstruierter Prompt kann das Modell daran hindern, akkurate Ausgaben zu generieren. Der Aufbau eines Prompts wird in der Literatur zwischen System Prompt , Role Prompt und Context Prompt unterschieden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/250', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 88.866, 't': 345.3580146484375, 'r': 507.8, 'b': 213.78201464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nDie Konfiguration der Ausgabe eines Sprachmodells (LLM) stellt einen zentralen Aspekt für das Prompt Engineering dar. Neben der Ausgestaltung des Prompts beeinflussen verschiedene Parameter die Art, Qualität und Konsistenz der generierten Texte. Zu den wichtigsten Konfigurationsparametern zählen beispielsweise die sogenannte Temperatur, die den Grad der Zufälligkeit bei der Textgenerierung steuert; eine niedrigere Temperatur sorgt dafür, dass das Ergebnis deterministischer wird. Zusätzlich gibt es die Parameter Top-k - und Top-p . Mit diesen zwei Parametern wird der Suchraum für mögliche nächste Tokens eingeschränkt. Darüber hinaus kann die maximale Länge der Ausgabe in Token eingestellt werden, was Rechenressourcen schont und Kosten spart.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/251', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 29, 'bbox': {'l': 89.291, 't': 209.8660146484375, 'r': 508.114, 'b': 173.13401464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 246]}]}, {'self_ref': '#/texts/254', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 30, 'bbox': {'l': 88.899, 't': 754.4110146484375, 'r': 505.985, 'b': 717.6800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 220]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nEine sorgfältige Konfiguration dieser Parameter ist entscheidend, um konsistente, relevante und den jeweiligen Anforderungen entsprechende Ergebnisse zu erzielen. Die richtige Balance zwischen Kreativität (Diversität der Ausgabe) und Zuverlässig-\\nkeit (Reproduzierbarkeit und Genauigkeit) ist dabei abhängig von der jeweiligen Anwendungsdomäne und Aufgabe. In der Praxis wird die optimale Konfiguration oft empirisch durch Tests und iterativer Anpassung gefunden [2].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/255', 'parent': {'$ref': '#/tables/7'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 30, 'bbox': {'l': 88.931, 't': 605.0100146484375, 'r': 505.99, 'b': 581.8280146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 144]}]}, {'self_ref': '#/tables/7', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/255'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 30, 'bbox': {'l': 130.03736877441406, 't': 705.5973052978516, 'r': 464.4656982421875, 'b': 621.748046875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/256', 'parent': {'$ref': '#/tables/8'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 30, 'bbox': {'l': 88.931, 't': 431.49201464843753, 'r': 505.981, 'b': 408.3100146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 144]}]}, {'self_ref': '#/tables/8', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/256'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 30, 'bbox': {'l': 98.73052978515625, 't': 555.5775756835938, 'r': 495.9909973144531, 'b': 449.22662353515625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nTabelle 2.1.: Prompt mit geringer Temperatur von 0.1 und niedrigem Token-Limit von 5: Die Ausgabe ist sehr vorhersehbar und endet nach 5 Tokens.\\n\\nWert, Temperatur = . Wert, Token Limit = 5. Prompt, Temperatur = Beschreibe die Ware: Elektronische Bauteile.. Prompt, Token Limit = Beschreibe die Ware: Elektronische Bauteile.. Ausgabe, Temperatur = Elektronische Bauteile sind kleine. Ausgabe, Token Limit = Elektronische Bauteile sind kleine\\n\\nTabelle 2.2.: Prompt mit hoher Temperatur von 0.9 und Top-P 0.5 mit einem hohen Token-Limit von 20: Die Ausgabe ist kreativer und ausführlicher.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/8', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/256'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 30, 'bbox': {'l': 98.73052978515625, 't': 555.5775756835938, 'r': 495.9909973144531, 'b': 449.22662353515625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nWert, Temperatur = 0.9. Wert, Top-P = 0.5 20. Wert, Token Limit = . Prompt, Temperatur = Beschreibe die Ware: Elektronische Bauteile.. Prompt, Top-P = Beschreibe die Ware: Elektronische Bauteile.. Prompt, Token Limit = Beschreibe die Ware: Elektronische Bauteile.. Ausgabe, Temperatur = Elektronische Bauteile sind wichtige Komponenten in zahlreichen tech- nischen Geräten. Sie werden in Computern, Smartphones, aber auch in komplexen Maschinen verwendet und können sehr unterschiedlich sein.. Ausgabe, Top-P = Elektronische Bauteile sind wichtige Komponenten in zahlreichen tech- nischen Geräten. Sie werden in Computern, Smartphones, aber auch in komplexen Maschinen verwendet und können'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/8', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/256'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 30, 'bbox': {'l': 98.73052978515625, 't': 555.5775756835938, 'r': 495.9909973144531, 'b': 449.22662353515625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.4.4. Prompt Engineering'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.4.4. Prompt Engineering\\nsehr unterschiedlich sein.. Ausgabe, Token Limit = Elektronische Bauteile sind wichtige Komponenten in zahlreichen tech- nischen Geräten. Sie werden in Computern, Smartphones, aber auch in komplexen Maschinen verwendet und können sehr unterschiedlich sein.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/258', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 30, 'bbox': {'l': 89.291, 't': 343.9540146484375, 'r': 505.988, 'b': 293.6730146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 318]}]}], 'headings': ['Zero-shot Prompting'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Zero-shot Prompting\\nUnter Zero-shot Prompting versteht man die einfachste Art des Prompts. Hier wird der Prompt als einfache Beschreibung oder Aufgabenstellung beschrieben. Dies können einfache Fragen, Instruktionen oder zufälliger Text sein. Bei dieser Methode des Promptings werden dem Modell keine Beispiele zur Verfügung gestellt [2].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/263', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 31, 'bbox': {'l': 150.581, 't': 745.7610146484375, 'r': 501.387, 'b': 725.0090146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 135]}]}, {'self_ref': '#/texts/264', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 31, 'bbox': {'l': 150.94, 't': 719.4600146484376, 'r': 501.392, 'b': 686.7530146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 169]}]}, {'self_ref': '#/texts/265', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 31, 'bbox': {'l': 150.94, 't': 675.7310146484375, 'r': 501.658, 'b': 643.0230146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 152]}]}, {'self_ref': '#/texts/266', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 31, 'bbox': {'l': 88.931, 't': 625.9880146484376, 'r': 507.795, 'b': 602.8060146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 119]}]}], 'headings': ['Ausgabe'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Ausgabe\\nExtrahiere die folgenden Entitäten aus dem untenstehenden Zolldokument: Versender, Empfänger, Warenbezeichnung, Zolltarifnummer, Menge.\\nDokument: 'Der Versender: ABC Logistics GmbH, Empfänger: Müller Import Export AG, Warenbezeichnung: Elektronische Bauteile, Zolltarifnummer: 85423990, Menge: 500 Stück.'\\nVersender: ABC Logistics GmbH; Empfänger: Müller Import Export AG; Warenbezeichnung: Elektronische Bauteile; Zolltarifnummer: 85423990; Menge: 500 Stück\\nTabelle 2.3.: Beispiel eines Zero-Shot Prompts mit Parametereinstellung zur Extraktion von Entitäten aus Zolldokumenten\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/268', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 31, 'bbox': {'l': 88.866, 't': 538.4500146484376, 'r': 507.799, 'b': 420.4230146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 662]}]}], 'headings': ['In-Context Learning (ICL)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"In-Context Learning (ICL)\\nBeim ICL wird der Prompt mit zusätzlichem Wissen angereichert. Dies wird entweder in Form von Beispielen (z. B. Aufgaben-Lösungs-Paare) oder durch die Integration von externem Wissen aus Dokumenten. Dadurch wird das LLM befähigt, während der Inferenz aus den im Prompt enthaltenen Informationen zu 'lernen', ohne die Modellgewichte, wie beim klassischen Training, zu verändern. Durch das Bereitstellen von zusätzlichem Kontext innerhalb des Prompts kann das Modell die Muster und Zusammenhänge erkennen und auf neue Aufgaben übertragen. Dieses Verhalten wird erst durch das vorherige Fine-Tuning eines LLM auf beispielbasierte Antwortgenerierung ermöglicht [23].\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/269', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 31, 'bbox': {'l': 89.291, 't': 416.5070146484375, 'r': 506.219, 'b': 366.2260146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 270]}]}], 'headings': ['In-Context Learning (ICL)'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='In-Context Learning (ICL)\\nInsbesondere Few-Shot Learning, bei dem dem Modell ein oder mehrere Beispiele im Prompt zur Verfügung gestellt werden, erzielt in der Regel deutlich bessere Ergebnisse als Zero-Shot Prompting, bei dem lediglich eine Aufgabenstellung, aber keine Beispiele gegeben werden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/273', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 95.269, 't': 531.7850146484375, 'r': 138.985, 'b': 522.7090146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/274', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.94, 't': 740.4710146484375, 'r': 198.92, 'b': 731.6740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}]}, {'self_ref': '#/texts/275', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.611, 't': 728.5160146484375, 'r': 501.662, 'b': 719.7190146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 69]}, {'page_no': 32, 'bbox': {'l': 150.452, 't': 716.5610146484375, 'r': 500.836, 'b': 683.8530146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [70, 281]}]}, {'self_ref': '#/texts/276', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.94, 't': 668.7400146484375, 'r': 198.92, 'b': 659.9430146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}]}, {'self_ref': '#/texts/277', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.611, 't': 656.7850146484375, 'r': 501.662, 'b': 647.9880146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 71]}, {'page_no': 32, 'bbox': {'l': 150.452, 't': 644.8300146484376, 'r': 500.833, 'b': 600.1670146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [72, 279]}]}, {'self_ref': '#/texts/278', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.94, 't': 585.0540146484375, 'r': 218.656, 'b': 576.2570146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 13]}]}], 'headings': ['Prompt'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Prompt\\nAusgabe\\nBeispiel 1:\\nText: 'Der Versender: Exportfirma XY, Empfänger: Technik AG, Warenbe- zeichnung: Maschinen, Zolltarifnummer: 12345678, Menge: 10 Stück.' Extrahierte Entitäten: Versender: Exportfirma XY; Empfänger: Technik AG; Warenbezeichnung: Maschinen; Zolltarifnummer: 12345678; Menge: 10 Stück\\nBeispiel 2:\\nText: 'Der Versender: Hans Spedition, Empfänger: Auto AG, Warenbezeich- nung: Ersatzteile, Zolltarifnummer: 87654321, Menge: 20 Stück.' Extrahierte Entitäten: Versender: Hans Spedition; Empfänger: Auto AG; Warenbezeichnung: Ersatzteile; Zolltarifnummer: 87654321; Menge: 20 Stück\\nNeue Aufgabe:\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/279', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.611, 't': 573.0990146484376, 'r': 501.392, 'b': 540.3910146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 165]}]}, {'self_ref': '#/texts/280', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 150.94, 't': 531.6060146484375, 'r': 501.658, 'b': 498.8990146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 152]}]}, {'self_ref': '#/texts/281', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 88.931, 't': 481.8640146484375, 'r': 505.988, 'b': 458.68201464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 102]}]}], 'headings': ['Prompt'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Prompt\\nText: 'Der Versender: ABC Logistics GmbH, Empfänger: Müller Import Export AG, Warenbezeichnung: Elektronische Bauteile, Zolltarifnummer: 85423990, Menge: 500 Stück.'\\nVersender: ABC Logistics GmbH; Empfänger: Müller Import Export AG; Warenbezeichnung: Elektronische Bauteile; Zolltarifnummer: 85423990; Menge: 500 Stück\\nTabelle 2.4.: In-Context Learning (ICL) mit Beispielen zur Extraktion von Entitäten aus Zolldokumenten\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/283', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 32, 'bbox': {'l': 89.291, 't': 394.3250146484375, 'r': 506.226, 'b': 330.4950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 371]}]}], 'headings': ['One-shot & Few-shot Learning'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='One-shot & Few-shot Learning\\nDiese Promptingmethoden sind Unterkategorien von ICL. Die Modellleistung wird bei diesen Verfahren durch zusätzliches Wissen im Kontextfenster optimiert. Das LLM wird sozusagen in eine gewisse Richtung gelenkt, und bekommt durch ein oder mehrere Aufgaben-Lösungs-Paare Ansätze, an eine Problemstellung heran zu gehen und diese in einem definierten Umfeld umzusetzen [24].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/287', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.94, 't': 750.7430146484376, 'r': 340.807, 'b': 741.9460146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 41]}]}, {'self_ref': '#/texts/288', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.94, 't': 736.3960146484375, 'r': 501.656, 'b': 727.5990146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 69]}]}, {'self_ref': '#/texts/289', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.452, 't': 724.4410146484375, 'r': 500.836, 'b': 689.3430146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 211]}]}, {'self_ref': '#/texts/290', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.94, 't': 669.4480146484375, 'r': 218.656, 'b': 660.6510146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 13]}]}, {'self_ref': '#/texts/291', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.94, 't': 655.1010146484375, 'r': 501.392, 'b': 622.3940146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 165]}]}, {'self_ref': '#/texts/292', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 95.269, 't': 611.5510146484376, 'r': 138.985, 'b': 602.4750146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 7]}]}, {'self_ref': '#/texts/293', 'parent': {'$ref': '#/groups/2'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 150.94, 't': 611.3720146484375, 'r': 501.658, 'b': 578.6650146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 154]}]}], 'headings': ['Prompt'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Prompt\\nExtrahiere die Entitäten wie im Beispiel:\\nText: 'Der Versender: Exportfirma XY, Empfänger: Technik AG, Warenbe-\\nzeichnung: Maschinen, Zolltarifnummer: 12345678, Menge: 10 Stück.' Extrahierte Entitäten: Versender: Exportfirma XY; Empfänger: Technik AG; Warenbezeichnung: Maschinen; Zolltarifnummer: 12345678; Menge: 10 Stück\\nNeue Aufgabe:\\nText: 'Der Versender: ABC Logistics GmbH, Empfänger: Müller Import Export AG, Warenbezeichnung: Elektronische Bauteile, Zolltarifnummer: 85423990, Menge: 500 Stück.'\\nAusgabe\\nVersender: ABC Logistics GmbH; Empfänger: Müller Import Export AG; Wa- renbezeichnung: Elektronische Bauteile; Zolltarifnummer: 85423990; Menge: 500 Stück\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/294', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 33, 'bbox': {'l': 88.931, 't': 561.6300146484375, 'r': 507.799, 'b': 538.4480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 89]}]}], 'headings': ['Prompt'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Prompt\\nTabelle 2.5.: One-Shot/Few-Shot Prompting zur Extraktion von Entitäten aus Zolldokumenten'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/296', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 89.291, 't': 474.0910146484375, 'r': 508.111, 'b': 383.1630146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 498]}]}], 'headings': ['Instruktionsbasiertes Lernen'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Instruktionsbasiertes Lernen\\nBeim instruktionsbasierten Lernen wird ein Large Language Model (LLM) durch eine explizite, natürlichsprachlich formulierte Anweisung dazu aufgefordert, eine bestimmte Aufgabe auszuführen. Im Gegensatz zu Few-Shot-Prompting werden dabei keine Beispiele vorgegeben, sondern die Zielaufgabe lediglich beschrieben. Diese Methode nutzt die Fähigkeit von modernen LLMs, Aufgaben allein auf Basis sprachlicher Instruktionen zu generalisieren, ohne dass eine Änderung der Modellparameter erforderlich ist.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/297', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 89.291, 't': 379.2470146484375, 'r': 506.23, 'b': 301.86801464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 304]}]}, {'self_ref': '#/texts/298', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 33, 'bbox': {'l': 89.291, 't': 352.14801464843754, 'r': 508.11, 'b': 288.3190146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 240]}, {'page_no': 33, 'bbox': {'l': 88.899, 't': 284.40201464843744, 'r': 505.985, 'b': 261.22001464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [241, 347]}]}], 'headings': ['Instruktionsbasiertes Lernen'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Instruktionsbasiertes Lernen\\nDurch sogenanntes Instruction Tuning, das im Rahmen der Modellentwicklung auf großen Mengen an Aufgaben-Anweisungen erfolgt, wie z.B. bei FLAN oder Dies ermöglicht eine flexible und anwenderfreundliche Nutzung, insbesondere bei standardisierten Aufgaben wie der Extraktion benannter Entitäten aus Texten.\\nSuper-NaturalInstructions [19, 25], wird das Modell darauf vorbereitet, verschiedenartige Aufgabenstrukturen aus reinen Instruktionen heraus zu interpretieren. Diese Methode ist besonders für domänenspezifische Extraktionsaufgaben geeignet, bei denen der Informationsbedarf klar definiert ist und sich mit einer einzelnen Anweisung erfassen lässt.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/303', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 750.7430146484376, 'r': 501.392, 'b': 703.6890146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 246]}]}, {'self_ref': '#/texts/304', 'parent': {'$ref': '#/groups/3'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 698.1400146484375, 'r': 322.964, 'b': 689.3430146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/305', 'parent': {'$ref': '#/groups/3'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 683.7940146484375, 'r': 327.776, 'b': 674.9970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/306', 'parent': {'$ref': '#/groups/3'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 669.4480146484375, 'r': 360.165, 'b': 660.6510146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 43]}]}, {'self_ref': '#/texts/307', 'parent': {'$ref': '#/groups/3'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 655.1020146484375, 'r': 348.807, 'b': 646.3050146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 42]}]}, {'self_ref': '#/texts/308', 'parent': {'$ref': '#/groups/3'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 640.7550146484375, 'r': 303.497, 'b': 631.9580146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 32]}]}, {'self_ref': '#/texts/309', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 150.94, 't': 620.9360146484375, 'r': 501.658, 'b': 588.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 152]}]}, {'self_ref': '#/texts/310', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 34, 'bbox': {'l': 88.931, 't': 571.1940146484375, 'r': 506.226, 'b': 548.0120146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 123]}]}], 'headings': ['Ausgabe'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Ausgabe\\nExtrahiere die Entitäten Schritt für Schritt aus dem folgenden Zolldokument: Dokument: 'Der Versender: ABC Logistics GmbH, Empfänger: Müller Import Export AG, Warenbezeichnung: Elektronische Bauteile, Zolltarifnummer: 85423990, Menge: 500 Stück.'\\nSchritt 1: Suche nach dem Versender.\\nSchritt 2: Suche nach dem Empfänger.\\nSchritt 3: Suche nach der Warenbezeichnung.\\nSchritt 4: Suche nach der Zolltarifnummer.\\nSchritt 5: Suche nach der Menge.\\nVersender: ABC Logistics GmbH; Empfänger: Müller Import Export AG; Warenbezeichnung: Elektronische Bauteile; Zolltarifnummer: 85423990; Menge: 500 Stück\\nTabelle 2.6.: instruktionsbasiertes Prompting mit Schrittweisen Anweisungen für Extraktion von Entitäten aus Zolldokumenten\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/311', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 88.931, 't': 518.6840146484375, 'r': 507.8, 'b': 427.7560146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 510]}]}], 'headings': ['Ausgabe'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Ausgabe\\nDiese Methoden führen häufig zu einer signifikanten Verbesserung der generierten Ausgabesequenz. Darüber hinaus lassen sich die verschiedenen PromptingTechniken - wie Instruction-Based Learning und In-Context Learning - gezielt miteinander kombinieren, um deren jeweilige Stärken zu vereinen. Hybride Promptingansätze haben sich in aktuellen Studien als besonders leistungssteigernd erwiesen und bilden somit eine wichtige Grundlage für den effektiven Einsatz von LLM in komplexen Extraktionsaufgaben [26, 27].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/313', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 89.291, 't': 357.76601464843753, 'r': 507.798, 'b': 266.8380146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 494]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nUnter Zolldaten werden in dieser Arbeit spezifische, im internationalen Warenverkehr regelmäßig vorkommende Dokumentenarten verstanden. Zu den zentralen Zolldokumenten zählen insbesondere der Frachtbrief, das Zolldokument selbst, die Handelsrechnung, der Lieferschein, die Warenverkehrsbescheinigung sowie das Präferenzdokument. Diese Dokumente sind essenziell für die Abwicklung und Kontrolle grenzüberschreitender Warenbewegungen und enthalten für die Zollabfertigung relevante Informationen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/314', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 88.997, 't': 262.92101464843745, 'r': 507.8, 'b': 199.0920146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 330]}]}, {'self_ref': '#/texts/315', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 34, 'bbox': {'l': 88.899, 't': 195.17501464843758, 'r': 508.108, 'b': 171.99301464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 153]}]}, {'self_ref': '#/texts/318', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 35, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 505.988, 'b': 717.6800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 225]}]}, {'self_ref': '#/texts/319', 'parent': {'$ref': '#/tables/9'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 35, 'bbox': {'l': 88.931, 't': 412.7160146484375, 'r': 505.988, 'b': 389.5340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 132]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nEinige dieser Dokumenttypen, wie beispielsweise der Frachtbrief oder das Zolldokument, folgen einem standardisierten Aufbau mit festgelegtem Schema, was ihre automatisierte Verarbeitung begünstigt. Andere Dokumente, etwa Rechnungen oder Lieferscheine, können hingegen je nach Aussteller in Format und Struktur erheblich variieren.\\nIm Folgenden werden die einzelnen Dokumentenarten näher beleuchtet und die Anforderungen, wie wichtige Entitäten, in Form eines Spaltenschemas definiert.\\nHierbei werden die Schemas in zwei Kategorien unterteilt, das erste Schema stellt die Kopfdaten einer einzelnen Sendung dar, während das zweite Schema sich auf die Einzelpositionen pro Artikel innerhalb einer Sendung bezieht.\\n'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/9', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/319'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 35, 'bbox': {'l': 98.54618835449219, 't': 704.3908386230469, 'r': 495.7586669921875, 'b': 424.60650634765625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nTabelle 2.7.: Zentrale Zolldokumente mit Felder für die zu extrahierenden Entitäten der Kopfdaten einer Sendung und Grad des Layouts'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/9', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/319'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 35, 'bbox': {'l': 98.54618835449219, 't': 704.3908386230469, 'r': 495.7586669921875, 'b': 424.60650634765625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nHandelsrechnung, Felder = Rechnungsnummer, Rech- nungsdatum, Bestellnummer. Handelsrechnung, Layout = Variabel. Lieferschein, Felder = Lieferscheinnummer, Liefer- datum, Empfänger, gelieferte Waren, Menge. Lieferschein, Layout = Variabel. Frachtbrief, Felder = Packstückanzahl, Bruttoge- wicht, Versendungsdatum. Frachtbrief, Layout = Variabel. Zolldokument (T1), Felder = Referenznummer (MRN), Zoll- siegel (Seal[19 10]), Warenei- gangsnummerstempel, Gültig- keit, Gesamtpositionen, Ge- samtpakete, Gesamtgewicht. Zolldokument (T1), Layout = Strukturiert. Warenverkehrsbescheinigung (ATR), Felder = Dokumenten-Nr.,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/9', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/319'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 35, 'bbox': {'l': 98.54618835449219, 't': 704.3908386230469, 'r': 495.7586669921875, 'b': 424.60650634765625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/322', 'parent': {'$ref': '#/tables/10'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 36, 'bbox': {'l': 166.108, 't': 167.11001464843753, 'r': 428.81, 'b': 157.4770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 51]}]}, {'self_ref': '#/tables/10', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/322'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 36, 'bbox': {'l': 97.6452407836914, 't': 758.3035583496094, 'r': 496.2268371582031, 'b': 179.75, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nAussteller, Ursprungsland, Bestim- mungsland, Warenbezeich- nung. Warenverkehrsbescheinigung (ATR), Layout = Strukturiert. Präferenzdokument (EUR1), Felder = Präferenznachweis-Nr., Aus- steller, Ursprungsland, Be- günstigte Waren, Referenz auf Handelsabkommen. Präferenzdokument (EUR1), Layout = Strukturiert\\n\\nTabelle 2.8.: Beschreibung der Felder der Kopfdaten'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/10', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/322'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 36, 'bbox': {'l': 97.6452407836914, 't': 758.3035583496094, 'r': 496.2268371582031, 'b': 179.75, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nRechnungsnummer, Beschreibung = Eindeutige Kennung der ausgestellten Handels- rechnung. Rechnungsdatum, Beschreibung = Ausstellungsdatum der Handelsrechnung. Bestellnummer, Beschreibung = Interne oder externe Referenznummer der Be- stellung. Lieferscheinnummer, Beschreibung = Eindeutige Nummer zur Identifikation des Lie- ferscheins. Lieferdatum, Beschreibung = Datum der Warenlieferung bzw. des Versands. Empfänger, Beschreibung = Name und Adresse des Warenempfängers. Gelieferte Waren, Beschreibung = Auflistung der im Lieferschein enthaltenen Wa- renpositionen. Menge, Beschreibung = Gesamtmenge bzw. Summeder gelieferten Waren. Packstückanzahl, Beschreibung = Anzahl der'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/10', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/322'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 36, 'bbox': {'l': 97.6452407836914, 't': 758.3035583496094, 'r': 496.2268371582031, 'b': 179.75, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nPackstücke, die transportiert werden. Bruttogewicht, Beschreibung = Gesamtgewicht der Sendung inkl. Verpackung (Bruttomasse). Versendungsdatum, Beschreibung = Datum des Versands der Ware. Referenznummer (MRN), Beschreibung = Movement Reference Number, eindeutige Refe- renz für das Zolldokument T1. Zollsiegel (Seal[19 10]), Beschreibung = Nummer und Kennzeichen des verwendeten Zoll- siegels. Wareneingangsnummerstempel, Beschreibung = Nummer zur Kennzeichnung des Wareneingangs beim Zoll. Gültigkeit, Beschreibung = Zeitliche Gültigkeit oder Frist des Dokuments. Gesamtpositionen, Beschreibung = Anzahl der im Dokument aufgeführten Einzelpo- sitionen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/10', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/322'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 36, 'bbox': {'l': 97.6452407836914, 't': 758.3035583496094, 'r': 496.2268371582031, 'b': 179.75, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nGesamtpakete, Beschreibung = Gesamtzahl der in der Sendung enthaltenen Pa- kete. Gesamtgewicht, Beschreibung = Brutto- oder Nettogewicht der gesamten Sendung. Dokumenten-Nr., Beschreibung = Offizielle Nummer des ausgestellten Dokuments (z. B. ATR). Aussteller, Beschreibung = Verantwortliche Organisation oder Person, die das Dokument ausstellt. Ursprungsland, Beschreibung = Herkunftsland der Ware. Bestimmungsland, Beschreibung = Zielland der Ware. Warenbezeichnung, Beschreibung = Vollständige handelsübliche Bezeichnung der Wa- re. Präferenznachweis-Nr., Beschreibung = Nummer des Präferenzdokuments (z. B. EUR1). Begünstigte Waren,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/10', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/322'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 36, 'bbox': {'l': 97.6452407836914, 't': 758.3035583496094, 'r': 496.2268371582031, 'b': 179.75, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/325', 'parent': {'$ref': '#/tables/11'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 37, 'bbox': {'l': 95.811, 't': 341.6550146484375, 'r': 499.11, 'b': 332.0220146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 79]}]}, {'self_ref': '#/tables/11', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/325'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 37, 'bbox': {'l': 93.22360229492188, 't': 758.1053771972656, 'r': 502.0169372558594, 'b': 354.23797607421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nBeschreibung = Waren, für die eine Zollbegünstigung beantragt wird. Referenz auf Handelsabkommen, Beschreibung = Bezug zu einem bestimmten Handelsabkommen, das eine Präferenz begründet\\n\\nTabelle 2.9.: Felder der Einzelpositionen für die Extraktion aus Zolldokumenten'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/11', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/325'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 37, 'bbox': {'l': 93.22360229492188, 't': 758.1053771972656, 'r': 502.0169372558594, 'b': 354.23797607421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nArtikelnummer, Beschreibung = Eindeutige Identifikationsnummer des Ar- tikels. Preis, Beschreibung = Preis der Einzelposition (numerisch). Menge, Beschreibung = Anzahl bzw. Menge der Warenposition (nu- merisch). Menge_Maßeinheit, Beschreibung = Maßeinheit der angegebenen Menge (z. B. kg, Stück). Eigenmasse, Beschreibung = Nettomasse des Artikels (numerisch). Eigenmasse_Maßeinheit, Beschreibung = Maßeinheit der Nettomasse (z. B. kg). Anmelde- und handelsstatistische Menge, Beschreibung = Statistische Zusatzmenge gemäß Zollan- meldung (numerisch). Beantragte Begünstigung, Beschreibung = Zollrechtlich beantragte Begünstigung'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/11', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/325'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 37, 'bbox': {'l': 93.22360229492188, 't': 758.1053771972656, 'r': 502.0169372558594, 'b': 354.23797607421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\n(z. B. Präferenz). Betriebliche Identifikationsnummer, Beschreibung = Interne Identifikationsnummer des Unter- nehmens. Container-Nummer, Beschreibung = Nummer des Containers bei Container- transport. Packstückzeichen und -nummer, Beschreibung = Kennzeichnung und Nummerierung des Packstücks. Packstückanzahl, Beschreibung = Anzahl der Packstücke (ganzzahlig). Packstückart, Beschreibung = Art des Packstücks (z. B. Karton, Palette). Rohmasse_Maßeinheit, Beschreibung = Maßeinheit der Bruttomasse. Ursprungsland, Beschreibung = Ursprungsland der Ware (ISO-Code oder Klartext). Warenbezeichnung, Beschreibung = Beschreibung der Ware. Warennummer, Beschreibung ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/11', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/325'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 37, 'bbox': {'l': 93.22360229492188, 't': 758.1053771972656, 'r': 502.0169372558594, 'b': 354.23797607421875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['2.5. Definition der Zolldaten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.5. Definition der Zolldaten\\nZolltarifnummer (HS-Code). Referenz zu Dokument, Beschreibung = Verweis auf ein zugehöriges Dokument (z. B. Rechnungsnummer)'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/329', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 88.899, 't': 719.7690146484375, 'r': 507.799, 'b': 683.0380146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 195]}]}, {'self_ref': '#/texts/330', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 88.899, 't': 679.1220146484375, 'r': 507.796, 'b': 628.8410146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 263]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nDie Bewertung der in dieser Arbeit erzielten Ergebnisse erfolgt durch den Vergleich eines hybriden Verfahrens, zweier klassischer Methoden sowie eines State-of-theArt-Systems auf Basis eines LLM.\\nZiel dieser Gegenüberstellung ist es, die Leistungsfähigkeit der Systeme hinsichtlich der Lösung eines Teilproblems des angestrebten Gesamtsystems objektiv zu beurteilen. Ein Vergleich des vollständigen Systems würde jedoch den Rahmen dieser Arbeit überschreiten.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/331', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 89.291, 't': 624.9250146484375, 'r': 507.8, 'b': 574.6440146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 266]}]}, {'self_ref': '#/texts/332', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 89.291, 't': 558.9260146484376, 'r': 506.72, 'b': 508.0670146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 242]}]}, {'self_ref': '#/texts/333', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 38, 'bbox': {'l': 217.269, 't': 495.5070146484375, 'r': 506.715, 'b': 471.01101464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 62]}]}, {'self_ref': '#/texts/334', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 89.291, 't': 451.3720146484375, 'r': 507.799, 'b': 427.6110146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 127]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nUmdie Genauigkeit und Qualität der verschiedenen Ansätze messbar und vergleichbar zu machen, werden klassische Metriken aus dem Bereich der Klassifikation angewandt. Dazu zählen Accuracy (Genauigkeit), Precision (Präzision), Recall (Sensitivität) sowie der F1-Score.\\nAccuracy (Genauigkeit): Bei der Accuracy auf Entitätsebene wird der Anteil der korrekt erkannten Entitäten (d. h. mit korrektem Typ und exakter Position) an allen im Goldstandard enthaltenen sowie vom System vorhergesagten Entitäten gemessen:\\n<!-- formula-not-decoded -->\\nPrecision (Präzision): Die Präzision beschreibt den Anteil der vom System extrahierten Entitäten, die tatsächlich korrekt sind:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/335', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 116.564, 't': 415.2690146484375, 'r': 509.913, 'b': 380.8970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 107]}]}, {'self_ref': '#/texts/336', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 116.564, 't': 377.17701464843753, 'r': 465.509, 'b': 353.6900146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/337', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 89.291, 't': 341.06901464843753, 'r': 505.98, 'b': 317.3090146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 124]}]}, {'self_ref': '#/texts/338', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 38, 'bbox': {'l': 130.53, 't': 304.74801464843745, 'r': 506.716, 'b': 280.10001464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 95]}]}, {'self_ref': '#/texts/339', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 116.564, 't': 269.2460146484375, 'r': 488.375, 'b': 259.3080146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 72]}]}, {'self_ref': '#/texts/340', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 38, 'bbox': {'l': 89.291, 't': 246.68701464843753, 'r': 505.986, 'b': 222.92701464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 132]}]}, {'self_ref': '#/texts/341', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 38, 'bbox': {'l': 228.464, 't': 210.36701464843748, 'r': 506.715, 'b': 185.71901464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 58]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nPrecision = Anzahl korrekter Treffer Anzahl korrekter Treffer + Anzahl fälschlich erkannter Entitäten (2.5)\\nHierbei steht die Anzahl fälschlich erkannter Entitäten für die False Positives .\\nRecall (Sensitivität): Der Recall beschreibt den Anteil der tatsächlich relevanten Entitäten, die vom System erkannt wurden:\\n<!-- formula-not-decoded -->\\nHierbei steht die Anzahl übersehener Entitäten für die False Negatives .\\nF1-Score: Der F1-Score ist das harmonische Mittel aus Präzision und Recall und stellt einen Kompromiss zwischen beiden Metriken dar:\\n<!-- formula-not-decoded -->'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/344', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 507.799, 'b': 663.4830146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 496]}]}, {'self_ref': '#/texts/345', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 650.1750146484375, 'r': 506.23, 'b': 613.4440146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 173]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nDiese Metriken werden auf die extrahierten Entitäten angewendet und ermöglichen eine differenzierte Bewertung der Extraktionsergebnisse hinsichtlich Korrektheit und Vollständigkeit. Die Accuracy wird in dieser Arbeit bewusst als Recallorientiertes Maß interpretiert, um sicherzustellen, dass alle relevanten Entitäten erkannt werden. Dies ist insbesondere im zollrechtlichen Kontext von zentraler Bedeutung, da unvollständige Extraktionen schwerwiegende Konsequenzen nach sich ziehen können [28].\\nZur Bewertung des Gesamtsystems auf Klassenebene werden zusätzlich folgende aggregierte Metriken herangezogen, die eine gewichtete Betrachtung einzelner Klassen ermöglichen:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/346', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 597.7250146484375, 'r': 506.23, 'b': 560.4160146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 212]}]}, {'self_ref': '#/texts/347', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 39, 'bbox': {'l': 203.408, 't': 545.5410146484376, 'r': 506.715, 'b': 534.8340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 49]}]}, {'self_ref': '#/texts/348', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 512.2190146484376, 'r': 505.984, 'b': 488.4590146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 134]}]}, {'self_ref': '#/texts/349', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 39, 'bbox': {'l': 116.564, 't': 455.66001464843754, 'r': 508.463, 'b': 418.91001464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 111]}]}, {'self_ref': '#/texts/350', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 406.1810146484375, 'r': 507.792, 'b': 382.42001464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 122]}]}, {'self_ref': '#/texts/351', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 39, 'bbox': {'l': 138.287, 't': 370.2990146484375, 'r': 506.716, 'b': 343.1750146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 98]}]}, {'self_ref': '#/texts/352', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 323.4100146484375, 'r': 507.791, 'b': 299.6500146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 107]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nSupport: Der Support bezeichnet die Anzahl der tatsächlichen Vorkommen einer Klasse im Datensatz. Er spielt eine implizite Rolle bei der Berechnung der Micro Metriken, da häufigere Klassen höher gewichtet werden:\\n<!-- formula-not-decoded -->\\nMicro-Accuracy: Die Micro-Accuracy aggregiert die korrekten Vorhersagen und die insgesamt betrachteten Fälle über alle Klassen hinweg:\\n<!-- formula-not-decoded -->\\nMicro-Precision: Die Micro-Precision aggregiert die korrekten und fälschlich erkannten Entitäten über alle Klassen hinweg:\\n<!-- formula-not-decoded -->\\nMicro-Recall: Der Micro-Recall aggregiert die korrekten und übersehenen Entitäten über alle Klassen hinweg:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/353', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 39, 'bbox': {'l': 179.184, 't': 287.52801464843753, 'r': 506.716, 'b': 260.4040146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 86]}]}, {'self_ref': '#/texts/354', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 240.63901464843752, 'r': 507.797, 'b': 216.87901464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 86]}]}, {'self_ref': '#/texts/355', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 39, 'bbox': {'l': 195.252, 't': 217.41601464843757, 'r': 506.716, 'b': 192.76801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 83]}]}, {'self_ref': '#/texts/356', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 39, 'bbox': {'l': 89.291, 't': 177.38701464843757, 'r': 507.794, 'b': 167.04501464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/359', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 116.564, 't': 754.4110146484375, 'r': 230.935, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 23]}]}, {'self_ref': '#/texts/360', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 40, 'bbox': {'l': 223.806, 't': 733.4260146484376, 'r': 506.716, 'b': 701.5240146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 49]}]}, {'self_ref': '#/texts/361', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 680.9080146484375, 'r': 505.985, 'b': 657.1470146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 95]}]}, {'self_ref': '#/texts/362', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 40, 'bbox': {'l': 239.155, 't': 656.7540146484375, 'r': 506.716, 'b': 624.8520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 43]}]}, {'self_ref': '#/texts/363', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 608.7190146484376, 'r': 505.99, 'b': 584.9590146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 95]}]}, {'self_ref': '#/texts/364', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 40, 'bbox': {'l': 256.925, 't': 584.5660146484375, 'r': 506.716, 'b': 552.6630146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 35]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\n<!-- formula-not-decoded -->\\nMicro-F1: Der Micro-F1-Score basiert auf aggregierter Micro-Precision und MicroRecall:\\n<!-- formula-not-decoded -->\\nMacro-Precision: Die Macro-Precision ist der ungewichtete Durchschnitt der Präzi-\\nsion über alle Klassen:\\n<!-- formula-not-decoded -->\\nMacro-Recall: Der Macro-Recall ist der ungewichtete Durchschnitt des Recalls über alle Klassen:\\n<!-- formula-not-decoded -->\\nMacro-F1: Der Macro-F1-Score ist der ungewichtete Durchschnitt der F1-Scores über alle Klassen:\\n<!-- formula-not-decoded -->'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/365', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 88.757, 't': 535.9530146484375, 'r': 506.23, 'b': 431.47501464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 587]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nAuf die Macro-Accuracy wird in dieser Arbeit nicht näher eingegangen, da die Bewertung auf Klassenebene primär anhand der Micro-Metriken erfolgt. Für die abschließende Beurteilung der globalen Modellleistung wird ausschließlich der Macro-F1-Wert herangezogen. Dieser erlaubt eine ausgewogene Bewertung der Extraktionsqualität über alle Klassen hinweg, unabhängig von deren Verteilung im Datensatz. Zur Berechnung des Macro-F1 werden die Macro-Precision und der Macro-Recall benötigt, die jeweils als ungewichtetes Mittel der entsprechenden Werte über alle Klassen hinweg bestimmt werden.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/366', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 427.55901464843754, 'r': 507.795, 'b': 404.3770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 124]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nSomit ist es möglich, Schwachstellen beim Erkennen einzelner Klassen zu identifizieren und gegebenenfalls zu optimieren [8].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/367', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 386.9110146484375, 'r': 508.108, 'b': 255.33601464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nDie in Zolldokumenten enthaltenen Entitäten können sowohl numerische Werte als auch Zeichenketten umfassen. Während bei numerischen Angaben die Bewertung der Extraktion auf Basis exakter Übereinstimmung erfolgen kann, gestaltet sich dies bei Zeichenketten schwieriger. Zur Bewertung der Ähnlichkeit extrahierter Zeichenfolgen werden daher häufig Metriken wie die Levenshtein-Distanz eingesetzt. Die Levenshtein-Distanz stellt einen grundlegenden Algorithmus im Bereich des Zeichenkettenvergleichs dar. Sie misst die Unähnlichkeit zwischen zwei Zeichenfolgen, indem sie die minimale Anzahl an einzelnen Zeichenoperationen berechnet, die erforderlich sind, um eine Zeichenkette in eine andere'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/367', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 386.9110146484375, 'r': 508.108, 'b': 255.33601464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}, {'self_ref': '#/texts/368', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 88.866, 't': 242.02801464843753, 'r': 507.499, 'b': 218.84601464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 134]}]}, {'self_ref': '#/texts/369', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 205.53801464843752, 'r': 119.804, 'b': 195.9050146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}, {'page_no': 40, 'bbox': {'l': 89.291, 't': 191.98901464843755, 'r': 118.386, 'b': 182.3560146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [7, 13]}]}, {'self_ref': '#/texts/370', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 40, 'bbox': {'l': 89.291, 't': 178.43901464843748, 'r': 116.367, 'b': 168.80601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/371', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 40, 'bbox': {'l': 119.4, 't': 208.1450146484375, 'r': 315.818, 'b': 167.2790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 114]}]}, {'self_ref': '#/texts/374', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 41, 'bbox': {'l': 89.291, 't': 740.8620146484375, 'r': 507.792, 'b': 717.6800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 115]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"2.6. Evaluationsmetriken für die Bewertung des Systems\\nzu überführen. Zu diesen Operationen zählen das Einfügen, Löschen sowie das Ersetzen eines Zeichens.\\nEin häufig zitiertes Beispiel ist die Umwandlung des Wortes 'kitten' in 'sitting', wofür genau drei Editieroperationen notwendig sind:\\nkitten sitten\\nsittin\\n```\\n→ sitten (Ersetzung von 'k' durch 's') → sittin (Ersetzung von 'e' durch 'i') → sitting (Einfügen von 'g' am Ende)\\n```\\nEine Editierung zählt als eines dieser Operationen - Einfügen, Löschen oder Ersetzen eines einzelnen Zeichens [29].\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/375', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 41, 'bbox': {'l': 88.866, 't': 704.3720146484375, 'r': 508.109, 'b': 599.8940146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 594]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nUm die erkannten Entitäten mit einer gewissen Toleranz zu bewerten, wird die Zeichenketten-Distanz mittels der Levenshtein-Distanz zwischen der erkannten Entität und dem korrespondierenden Label berechnet. Überschreitet diese Distanz einen definierten Schwellenwert nicht, so gilt die Entität als korrekt erkannt und wird als True Positive gewertet. Entitäten, die nicht erkannt oder falsch klassifiziert werden, fallen entsprechend in die Kategorien False Negative oder False Positive. Diese Einteilung bildet die Grundlage zur Berechnung der Metriken Accuracy, Precision, Recall und F1-Score.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/376', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 41, 'bbox': {'l': 89.291, 't': 595.9780146484375, 'r': 507.799, 'b': 559.2470146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 175]}]}, {'self_ref': '#/texts/377', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 41, 'bbox': {'l': 94.436, 't': 172.17601464843756, 'r': 286.552, 'b': 162.99001464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 37]}]}], 'headings': ['2.6. Evaluationsmetriken für die Bewertung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='2.6. Evaluationsmetriken für die Bewertung des Systems\\nFür die Berechnung der Levenshtein-Distanz wird in dieser Arbeit die PythonBibliothek thefuzz 4 verwendet, welche eine effiziente Implementierung des Algorithmus bereitstellt.\\n4 https://github.com/seatgeek/thefuzz'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/379', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 42, 'bbox': {'l': 88.757, 't': 618.9190146484375, 'r': 508.108, 'b': 297.6540146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1909]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nKlassische Extraktionspipelines, die auf der Kombination von OCR und NER basieren, sind in vielen industriellen Anwendungen etabliert und bieten eine solide Basis für strukturierte Informationsextraktion. Sie stoßen jedoch an Grenzen, sobald neue Entitätstypen auftreten und müssen daher oft explizit auf domänenspezifischen Anwendungsfällen trainiert oder nachtrainiert werden. Dies erfordert in der Regel sehr viele Trainingsdaten, die aufwändig vorbereitet und gelabelt werden müssen, um ein leistungsfähiges System zu erstellen. Moderne Ansätze auf Basis großer Sprachmodelle (LLM) ermöglichen eine flexible Textextraktion - vergleichbar mit OCR sowie die Identifikation verschiedenster Entitäten,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/379', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 42, 'bbox': {'l': 88.757, 't': 618.9190146484375, 'r': 508.108, 'b': 297.6540146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1909]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nohne dass eine aufwändige Nachtrainierung oder explizite Merkmalsentwicklung erforderlich ist. Die Verarbeitung erfolgt dabei als durchgängige End-to-End-Lösung. Dies wird auch dadurch erreicht, dass die Modelle schon vorab auf sehr großen Datensätzen trainiert werden und die Modellfähigkeit zusätzlich durch weitere Optimierungsverfahren wie Reinforcement Learning from Human Feedback (RLHF) nachjustiert wird, wobei menschliches Feedback in die Gewichtsanpassungen des LLMs mit einbezogen wird [30]. Durch diese Flexibilität können LLMs in sehr vielen Anwendungsbereichen eingesetzt werden, ohne viel Zeit in die Erstellung oder Vorbereitung von Testdaten zu investieren. Daher werden'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/379', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 42, 'bbox': {'l': 88.757, 't': 618.9190146484375, 'r': 508.108, 'b': 297.6540146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1909]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nin dieser Arbeit beide Ansätze systematisch miteinander verglichen, um sowohl die Vorteile bewährter Methoden als auch das Potenzial aktueller LLMTechnologien für die Extraktion von Zolldaten zu evaluieren. Als Vergleichsbasis dient ein hybrider Ansatz, der Tesseract-OCR mit integrierter Layoutanalyse sowie spaCy-NER kombiniert. Beide Komponenten gelten als etablierte und robuste Werkzeuge im Bereich der NLP-basierten Informationsextraktion und haben sich in zahlreichen Studien als leistungsfähig erwiesen [7, 13].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/380', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 42, 'bbox': {'l': 88.757, 't': 293.73801464843746, 'r': 507.799, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 792]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nWie bereits in Abschnitt 1.1 erläutert, kann die Generalisierbarkeit von Sprachmodellen (LLMs) selbst bei großen Trainingsdatenmengen an ihre Grenzen stoßen insbesondere bei sehr spezifischen Anwendungsfällen und in hochspezialisierten Domänen. Um dieses Problem zu umgehen, ist es möglich, den in Unterabschnitt 2.4.2 erwähnten Modellkontext (Aufmerksamkeitsschicht) der Transformerarchitektur zu nutzen, um die Modellleistung zu steigern [17]. Seit der Entwicklung der LLM sind zahlreiche Methoden entstanden, um die Leistungsfähigkeit dieser Modelle nicht durch explizites Nachtraining der Modellgewichte, sondern durch Kontextanreicherung während'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/380', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 42, 'bbox': {'l': 88.757, 't': 293.73801464843746, 'r': 507.799, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 792]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nder Inferenz zu verbessern. Eine zentrale Methodik ist das Promptengineering (vgl. Unterabschnitt 2.4.4), bei dem das Modell mithilfe gezielt'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/383', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.8, 'b': 609.2860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 805]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\ngestalteter Eingabeaufforderungen (Prompts) dazu angeregt wird, Aufgaben in bestimmter Weise zu lösen oder bestimmte Informationen zu extrahieren. Besonders hervorzuheben sind das In-Context Learning, bei dem das Modell durch das Bereitstellen weniger Beispiele im Prompt ('Few-Shot Learning') in die Lage versetzt wird, neue Aufgaben ohne zusätzliche Trainingsdaten zu bearbeiten, oder auch das instruktionsbasierte Lernen, bei dem das Modell die Aufgabenstellung in einer bestimmten Abfolge von Schritten lösen soll. Die genannten Methoden haben sich als äußerst wirkungsvoll erwiesen, da sie die Anpassungsfähigkeit und Generalisierungsfähigkeit von LLMs erheblich erhöhen und somit den Einsatz in\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/383', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.8, 'b': 609.2860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 805]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nheterogenen und dynamischen Anwendungsszenarien, wie der Extraktion von Zolldaten, ermöglichen [31, 32].'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/384', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 88.866, 't': 605.3700146484375, 'r': 508.116, 'b': 257.00701464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1981]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nUm das hybride System, bestehend aus OCR und NER, durch ein LLM-basiertes System abzubilden, wird die Aufgabe in zwei Teilaufgaben unterteilt. Im ersten Schritt werden die PDF-Dateien pro Sendung eingelesen und anschließend in Bildformate umgewandelt, da es sich häufig um gescannte oder fotografierte Dateien handelt. Dies ist notwendig, da MLLM direkt auf Bilddaten arbeiten und so in der Lage sind, durch gezieltes Prompting Entitäten direkt aus dem visuellen Dokumentkontext heraus zu extrahieren und von Bild zu Text vorherzusagen (siehe Implementierung (vgl. Listing A.1). Dieser Teilschritt vereint die Aufgaben des OCR- und NER-Systems in einem einzigen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/384', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 88.866, 't': 605.3700146484375, 'r': 508.116, 'b': 257.00701464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1981]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nVerarbeitungsschritt und ermöglicht dadurch sowohl die Extraktion der relevanten Entitäten als auch die Zuordnung der korrekten Attribut-Wert-Paare. Im klassischen, hybriden Ansatz müsste letzteres als zusätzlicher, oft sehr aufwändiger Verarbeitungsschritt separat implementiert werden. Ausgabe dieses Schrittes sind die Entitäten in Form einer JSON-Datei. Im zweiten Schritt werden die nun teilstrukturierten Daten mithilfe des LLM in ein vollständig strukturiertes Format überführt. Dazu erhält das Sprachmodell sowohl die im vorherigen Schritt extrahierten Attribut-Wert-Paare im JSON-Format als Kontext, als auch einen spezifischen Aufgabenprompt.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/384', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 88.866, 't': 605.3700146484375, 'r': 508.116, 'b': 257.00701464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1981]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nDie Ausgabe des Modells erfolgt wiederum im JSON-Format, wobei eine Schema-Prüfung durch vordefinierte Vorlagen erfolgt. Diese Vorlagen dienen dazu, dass das Modell die Ausgabe entsprechend des gewünschten Zielschemas generiert und im richtigen Format parst. Die Abbildung 3.1 zeigt die High-Level-Darstellung der entwickelten Datenpipeline zur Extraktion von Entitäten aus Zolldokumenten. Der schematische Ablauf illustriert die zentralen Verarbeitungsschritte von der Einlesung der PDF-Dateien, über die Konvertierung in Bilddaten und die anschließende Entitätsextraktion mittels multimodaler LLM, bis hin zur strukturierten Ausgabe der extrahierten Informationen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/385', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 43, 'bbox': {'l': 89.291, 't': 243.69901464843747, 'r': 507.799, 'b': 166.32001464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 467]}]}, {'self_ref': '#/texts/388', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 17.96807064121845, 't': 802.8865949134897, 'r': 66.03192867344501, 'b': 793.893434330809, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 12]}]}, {'self_ref': '#/texts/389', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 109.98742646724016, 't': 808.0789483634923, 'r': 150.67923961828183, 'b': 799.3270344337787, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}, {'page_no': 44, 'bbox': {'l': 107.9463579691023, 't': 799.6490537411572, 'r': 152.7203091816674, 'b': 789.8256321828062, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [12, 21]}]}, {'self_ref': '#/texts/390', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 199.31529396314195, 't': 830.6907929811358, 'r': 239.3513733698802, 'b': 822.5396174312137, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/391', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 207.99999983333336, 't': 821.9663505927123, 'r': 230.66666650000002, 'b': 813.9968849438574, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/392', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 193.3333332666667, 't': 806.0274193199069, 'r': 243.99999993333336, 'b': 798.7220758084566, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 15]}, {'page_no': 44, 'bbox': {'l': 199.3063277915882, 't': 797.5359002712745, 'r': 237.36033881860644, 'b': 789.9464192232729, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [16, 27]}]}, {'self_ref': '#/texts/393', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 204.62978459455974, 't': 774.2889758501387, 'r': 232.03688145735273, 'b': 766.704794093675, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/394', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 292.64423267667695, 't': 774.896418876296, 'r': 322.0224344792486, 'b': 766.7614733963279, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nDie Leistungsfähigkeit des eingesetzten Modells wurde im Rahmen dieser Arbeit gezielt durch den Einsatz unterschiedlicher Prompting-Techniken optimiert. Zur Sicherstellung einer hohen Reproduzierbarkeit wurde der Temperatur-Parameter, der das Maß an Zufälligkeit bei der Textgenerierung beeinflusst, standardmäßig auf den deterministischen Wert 0 gesetzt (vgl. Unterabschnitt 2.4.4). Die Effektivität multimodaler Large Language Models (LLMs) hängt maßgeblich von der\\nPDF auslesen\\nPDF zu Bild umwandeln\\nOCR / NER\\nErsatz\\nLLM - Entitäten extrahieren\\nSchritt 1\\nSchritt 2'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/395', 'parent': {'$ref': '#/pictures/8'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 44, 'bbox': {'l': 88.899, 't': 678.0660146484375, 'r': 507.794, 'b': 641.3350146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 188]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nAbbildung 3.1.: Schematische Übersicht der Datenpipeline zur Entitätsextraktion aus Zolldokumenten. Die Abbildung illustriert die zentralen Verarbeitungsschritte durch ein multimodales LLM'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/396', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 88.866, 't': 616.0190146484375, 'r': 507.799, 'b': 376.0490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1360]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nQualität der verwendeten Prompts ab. In dieser Arbeit wurden sechs PromptingTechniken implementiert (vgl. Kapitel 4, Abschnitt A.3, Abschnitt A.2). Die Evaluierung der entwickelten Prompttechniken erfolgte anhand definierter Metriken (vgl. Abschnitt 2.6), wobei insbesondere die Extraktionsgenauigkeit sowie die Robustheit gegenüber variierenden Dokumentstrukturen analysiert wurden. Da für den Vergleich der unterschiedlichen Ansätze zur Extraktion von Entitäten aus Zolldokumenten eine objektive Bewertung der Modellleistung erforderlich ist, wird ein gelabelter Datensatz benötigt. Die manuelle Annotation dient dabei als Grundwahrheit, anhand dessen die'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/396', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 88.866, 't': 616.0190146484375, 'r': 507.799, 'b': 376.0490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1360]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nExtraktionsgenauigkeit sowohl der klassischen als auch der LLM-basierten Methoden gemessen werden kann. Im Rahmen dieser Arbeit wurden die relevanten Entitäten in einer Stichprobe von Zolldokumenten nach einem vorab definierten einheitlichen Schema (vgl. Abschnitt 2.5) markiert. Die Annotation erfolgte manuell, wobei die Entitätenklassen berücksichtigt wurden. Um die Qualität der Annotation sicherzustellen, wurden die Daten zunächst von einem Annotator gelabelt und anschließend mit dem Fachbereich für Zollprozesse abgeglichen. Im Falle von Unstimmigkeiten erfolgte eine Klärung im Konsens. Der so entstandene Datensatz bildet die Grundlage für die'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/396', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 88.866, 't': 616.0190146484375, 'r': 507.799, 'b': 376.0490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1360]}]}, {'self_ref': '#/texts/397', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 44, 'bbox': {'l': 379.3333334888889, 't': 806.6915412940482, 'r': 412.6666668222222, 'b': 798.0579535077886, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}], 'headings': ['3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='3. Lösungsansatz zur Extraktion der Inhalte von Zolldokumenten\\nEvaluierung und den Vergleich der Modellansätze.\\nDaten zur'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/399', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 45, 'bbox': {'l': 88.899, 't': 644.1500146484375, 'r': 507.8, 'b': 524.2310146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 639]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nDas System ist in Python 3.9 5 auf der Plattform Dataiku 6 implementiert (schematisch dargestellt in Anhang C) und nutzt die Azure OpenAI API, um sicherzustellen, dass keine übermittelten Daten in das Trainingsmodell zurückfließen. Die Datenverarbeitung erfolgt lokal, während die Modellanfragen über die Cloud-basierte API abgewickelt werden. Im Folgenden werden die zentralen Komponenten der Implementierung dargestellt, insbesondere die Integration der OCR- und NERKomponenten, die Verarbeitungspipeline zur Extraktion der Zolldaten sowie das verwendete Prompt-Design. Die vollständige Implementierung ist im Abschnitt A.1 dokumentiert.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/400', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 45, 'bbox': {'l': 88.866, 't': 520.3140146484375, 'r': 508.107, 'b': 415.8370146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 571]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nDie erste Teilaufgabe umfasst die Komponenten OCR und NER innerhalb der Extraktionspipeline. Zu diesem Zweck wird dem Modell ein Bild übergeben, das zuvor mit der Python-Bibliothek Pillow 7 aus dem ursprünglichen PDF-Dokument extrahiert wurde. Durch diese Vorgehensweise kann die multimodale Verarbeitungsfähigkeit des LLM genutzt werden, sodass das Modell in der Lage ist, die visuellen Informationen zu interpretieren und die enthaltenen Entitäten in Textform zu extrahieren. Die Rückgabe erfolgt im JSON-Format und beinhaltet sämtliche im Dokument erkannten Entitäten.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/401', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 45, 'bbox': {'l': 85.226, 't': 393.4140146484375, 'r': 369.281, 'b': 205.29001464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 303]}]}, {'self_ref': '#/texts/402', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 45, 'bbox': {'l': 94.436, 't': 308.27301464843754, 'r': 381.235, 'b': 162.9520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 185]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\n```\\n1 # LLM API Call Part 1 2 response = client.chat.completions.create( 3 model=AZURE_OPENAI_MODEL, 4 response_format={ \"type\": \"json_object\" }, 5 messages=[ 6 { 7 \"role\": \"system\", 8 \"content\": 9 }, 10 { 11 \"role\": \"user\", 12 \"content\": [ 13 {\"type\": \"text\", 14 { 15 \"type\": \"image_url\", 16 \"image_url\": {\\n```\\nsystem_prompt.format(url=url) \"text\": user_prompt}, 5 https://www.python.org/downloads/release/python-390/ 6 https://www.dataiku.com 7 https://pillow.readthedocs.io/en/stable/index.html'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/405', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/406'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 46, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 458.944, 'b': 637.3520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 167]}]}, {'self_ref': '#/texts/406', 'parent': {'$ref': '#/texts/405'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 46, 'bbox': {'l': 104.577, 't': 627.4580146484375, 'r': 490.705, 'b': 617.8250146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 73]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\n```\\n17 \"url\": f\"data:image/png;base64,{base64_image}\", 18 \"detail\": \"high\" 19 } 20 } 21 ] 22 } 23 ], 24 temperature=0.0, 25 ) 26 return response.choices[0].message.content\\n```\\n\\nListing 4.1: LLM als OCR-Ersatz - PDF zu Bild und Bild zu Text Extraktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/407', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 46, 'bbox': {'l': 88.986, 't': 597.8560146484375, 'r': 508.111, 'b': 466.2800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 782]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nNachdem die in Teilaufgabe eins extrahierten Entitäten persistiert wurden, erhält das LLM im Rahmen von Teilaufgabe zwei diese Entitäten als kontextuelle Information. Ergänzt wird dieser Kontext durch ein strukturelles Zielschema im JSON-Format sowie eine textuelle Prompt-Anweisung. Auf Basis dieser Eingaben generiert das Modell die Zielausgabe in Form einer JSON-Datei (vgl. Listing 4.2). Die Einhaltung des vorgesehenen Ausgabeformats wird durch einen nachgelagerten Parser gewährleistet, welcher die Modellantwort anhand eines vordefinierten Schemas validiert. Diese Validierungsfunktionalität wird über die Azure API bereitgestellt. Der Parser nutzt hierzu ein referenziertes Schemainstanzmodell, welches auch'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/407', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 46, 'bbox': {'l': 88.986, 't': 597.8560146484375, 'r': 508.111, 'b': 466.2800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 782]}]}, {'self_ref': '#/texts/408', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 46, 'bbox': {'l': 85.226, 't': 458.0550146484375, 'r': 381.235, 'b': 162.33301464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 448]}]}, {'self_ref': '#/texts/411', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 47, 'bbox': {'l': 89.291, 't': 737.8730146484376, 'r': 505.986, 'b': 728.2400146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 80]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nverschachtelte Datenstrukturen überprüfen kann (vgl. Listing 4.3).\\n```\\n1 # LLM Aufruf Teilaufgabe zwei 2 response = client.beta.chat.completions.parse( 3 model=AZURE_OPENAI_MODEL, 4 messages=[ 5 { 6 \"role\": \"system\", 7 \"content\": system_prompt 8 }, 9 { 10 \"role\": \"user\", 11 \"content\": [ 12 { 13 \"type\": \"text\", 14 \"text\": user_prompt.format( 15 json_raw=json_raw, 16 schema_json=final_schema 17 ) 18 } 19 ] 20 } 21 ], 22 response_format=ZollSchema, 23 temperature=0.0, 24 ) 25 return response.choices[0].message.parsed\\n```\\nListing 4.2: Schemamigration des extrahierten JSON-Contents aus Teilaufgabe eins'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/412', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 88.757, 't': 705.9660146484375, 'r': 505.985, 'b': 655.6850146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 244]}]}, {'self_ref': '#/texts/413', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/414'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 47, 'bbox': {'l': 90.765, 't': 645.9230146484375, 'r': 375.258, 'b': 577.3510146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 167]}]}, {'self_ref': '#/texts/414', 'parent': {'$ref': '#/texts/413'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 47, 'bbox': {'l': 152.314, 't': 566.6880146484375, 'r': 442.965, 'b': 557.0550146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 55]}]}, {'self_ref': '#/texts/415', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 89.291, 't': 534.7810146484375, 'r': 507.776, 'b': 511.5990146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 140]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nUm Anforderungen der Ausgabe zu gewährleisten, werden Modelle in Form von Schlüssel-Wert-Tupeln definiert. Diese können beliebig verschachtelt werden und Werte der Tupel können wiederum ein Modell beinhalten. Ein Modell kann wie folgt aussehen.\\n```\\n1 class ZollSchema(BaseModel): 2 document_data: Zollkopfdaten 3 goods_positions: List[Zolleinzelpositionen] 4 sendung: str 5 token_count_doc: int 6 prompt_version: str\\n```\\n\\nListing 4.3: Pydantic Modell für eine Schemaüberprüfung\\nEin zentraler Bestandteil der Implementierung stellt das gezielte Design der Prompts zur Steuerung des Verhaltens des eingesetzten LLMs dar.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/416', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 88.931, 't': 507.6830146484375, 'r': 507.799, 'b': 443.8530146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 371]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nIm Rahmen der Entwicklung wurden sechs unterschiedliche Prompting-Strategien evaluiert, die sich hinsichtlich Struktur, Grad der Beispielhaftigkeit und Kontexttiefe unterscheiden. Dazu zählen klassische Ansätze wie Zero-Shot- und OneShot-Prompting sowie kombinierte Verfahren, die instruktionsbasiertes Lernen (Instruction-Based Learning (IBL)) mit Beispielen verknüpfen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/417', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 88.899, 't': 439.9370146484375, 'r': 507.797, 'b': 281.26201464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nAufgrund des Umfangs der jeweiligen Promptformulierungen wird in diesem Kapitel ausschließlich die Zero-Shot-Methode für beide Teilaufgaben exemplarisch dargestellt. Die übrigen Varianten - Kombinationen aus One-Shot und IBL sowie Few-Shot und IBL - bauen auf den hier beschriebenen Grundstrukturen auf und ergänzen diese durch zusätzliche Beispiele. Eine vollständige Übersicht über sämtliche Promptformulierungen findet sich im Anhang (Abschnitt A.2, Abschnitt A.3). Die im Folgenden dargestellten Prompts verwenden das Zero-Shot-Verfahren, bei dem das LLM lediglich eine natürliche Spracheingabe in Form einer Anweisung erhält, jedoch ohne explizite Beispiele oder Zwischenschritte. Die Formulierung der Prompts erfolgte iterativ'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/417', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 88.899, 't': 439.9370146484375, 'r': 507.797, 'b': 281.26201464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}, {'self_ref': '#/texts/418', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 47, 'bbox': {'l': 88.986, 't': 277.3460146484375, 'r': 507.792, 'b': 186.41801464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 494]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"4. Implementierung\\nund wurde anhand empirischer Testergebnisse hinsichtlich Genauigkeit, Robustheit gegenüber OCR-bedingten Fehlern sowie Antwortkonsistenz optimiert.\\nJeder Prompt besteht aus zwei funktionalen Komponenten: einem System-Prompt und einem User-Prompt. Der System-Prompt definiert den globalen Rahmen sowie die Rollenzuweisung für das Modell - etwa die Aufgabe als 'Experte für Dokumentenanalyse' - und legt das erwartete Antwortformat fest. Der User-Prompt enthält die eigentliche Instruktion und ggf. den Eingabetext (z. B. extrahierte Entitäten oder das OCR-Ergebnis). Zusammen steuern beide Komponenten die Verarbeitung und Ausgabe des Modells.\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/421', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 505.981, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 102]}]}], 'headings': ['4. Implementierung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='4. Implementierung\\nIm Folgenden sind zwei Prompt-Szenarien für unterschiedliche Aufgabenbereiche des Systems aufgelistet:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/424', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 140.03, 't': 669.0510146484376, 'r': 483.793, 'b': 605.2210146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 297]}]}, {'self_ref': '#/texts/425', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 140.139, 't': 591.9130146484375, 'r': 481.989, 'b': 528.0830146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 340]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents: Waybill (Frachtbrief) - T1 Transit Document (Zolldokument) - Invoice (Rechnung) - Delivery Note (Lieferschein) - Movement Certificate (ATR) - Movement Certificate (EUR1)\\nYour task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Always provide the key \"referenz zu dokument\" : { url }'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/427', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 140.564, 't': 491.8350146484375, 'r': 484.112, 'b': 455.1030146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 172]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExtract all relevant fields in the customs document in JSON format. Use original language for the values. If the document has no relevant data, return an empty JSON object.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/430', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 140.182, 't': 395.9140146484375, 'r': 484.114, 'b': 304.9860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 441]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are a data transformation tool that takes in JSON data and a reference JSON schema, and outputs JSON data according to the schema. Not all of the data in the input JSON will fit the schema, so you may need to omit some data or add null values to the output JSON. Translate all data into German if not already in German. Ensure values are formatted as specified in the schema (e.g. dates as YYYY-MM-DD). Here is the schema: {schema json}.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/432', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 48, 'bbox': {'l': 140.204, 't': 268.7370146484375, 'r': 482.276, 'b': 232.00601464843749, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 187]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nTransform the following raw JSON data according to the provided schema. Ensure all data is in English and formatted as specified by values in the schema. Here is the raw JSON: {json raw}.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/434', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 49, 'bbox': {'l': 88.866, 't': 642.6360146484375, 'r': 508.108, 'b': 483.9620146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 929]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"5. Evaluierung des Systems\\nFür die Evaluierung und Bewertung des Systems wurden pro Prompttechnik definierte Testszenarien durchgeführt, anhand derer die Extraktionsleistung systematisch analysiert wurde. Für jede Prompttechnik wurde die Version getrackt, um Genauigkeit des Systems über alle verwendeten Methoden zu dokumentieren. Bei der Systemgegenüberstellung des klassischen Systems zu dem LLM-basierten System wurden die Entitäten keiner Klasse zugeordnet. Da im Rahmen dieser Arbeit kein Modell neu trainiert wurde, sondern auf bereits vortrainierte Modelle zurückgegriffen wurde, beschränkte sich die Evaluation auf eine binäre Klassifikation. Es wurde zwischen den Fällen 'Entität gefunden' und 'Entität nicht gefunden' unterschieden. Eine feinere Klassifikation nach Entitätstypen hätte ein\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/434', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 49, 'bbox': {'l': 88.866, 't': 642.6360146484375, 'r': 508.108, 'b': 483.9620146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 929]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nFinetuning des Modells oder die Definition regelbasierter Extraktionslogik erfordert, wofür jedoch ein großer annotierter Datensatz notwendig gewesen wäre.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/435', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 49, 'bbox': {'l': 88.931, 't': 480.0460146484375, 'r': 508.111, 'b': 240.0770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1341]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nDie Bewertung der Extraktionsleistung basierte auf zwei unterschiedlichen Vergleichsverfahren, abhängig vom Typ der extrahierten Entität. Numerische Werte (z.B. Mengen, Preise oder Gewichtseinheiten) wurden auf Basis exakter Übereinstimmung mit den Referenzwerten geprüft. Eine numerische Extraktion wurde dabei nur dann als korrekt gewertet, wenn der erkannte Wert exakt dem erwarteten Zielwert entsprach. Für Zeichenketten (z.B. Produktbezeichnungen, Zolltarifnummern oder Ursprungsangaben) kam ein Vergleich mittels Levenshtein-Distanz (vgl. Abschnitt 2.6) zur Anwendung. Dieses Verfahren erlaubt eine gewisse Toleranz gegenüber kleineren OCR-Fehlern oder typografischen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/435', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 49, 'bbox': {'l': 88.931, 't': 480.0460146484375, 'r': 508.111, 'b': 240.0770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1341]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nAbweichungen, ohne die strukturelle Korrektheit der Extraktion wesentlich zu beeinträchtigen [33]. Dabei wurde ein Schwellenwert (Threshold) von 90% gewählt, sodass erkannte Entitäten als korrekt klassifiziert wurden, wenn ihre Ähnlichkeit zum Zielwert mindestens 90% betrug. Die Auswahl dieses Schwellenwerts erfolgte, da die Metriken Micro-Accuracy, Micro-Recall und Micro-F1 im Bereich von 85% bis 100% kaum Schwankungen zeigten, während die Micro-Precision insbesondere bei den Kopfdaten ab einem Schwellenwert von mehr als 90% signifikant abnimmt (vgl. Abbildung 5.1, Abbildung 5.2). Diese Festlegung basiert auf empirischen Analysen der entsprechenden Metriken.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/436', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 49, 'bbox': {'l': 89.291, 't': 222.6110146484375, 'r': 505.985, 'b': 172.33101464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 325]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nDurch die im ersten Teilschritt erfolgte Extraktion sämtlicher potenzieller Entitäten mittels des LLMs ergibt sich ein relativ niedriger Accuracy-Wert von 0,17 und ein Precision-Wert von maximal 0,25. Im Vergleich dazu weist der zweite Teilschritt eine etwas höhere Accuracy von 0,25 und eine signifikant höhere Präzision mit'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/439', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 50, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 508.113, 'b': 677.0320146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 481]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\neinem Maximalwert von 0,56 auf (vgl. Tabelle 5.1, Tabelle 5.2). Die Ursache für die geringere Präzision im ersten Schritt liegt in der begrenzten Kontextinformation, die dem Modell hinsichtlich des gewünschten Ausgabeformats zur Verfügung stand. Dies führte zu einer Vielzahl von falsch-positiven Entitäten. Diese Entitäten waren zwar semantisch korrekt und im Dokument vorhanden, jedoch im Kontext des spezifischen Dokumententyps bzw. des zugehörigen Zollprozesses nicht relevant.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/440', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 50, 'bbox': {'l': 88.997, 't': 673.1160146484375, 'r': 507.799, 'b': 595.7370146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 415]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nIn Bezug auf den Recall zeigt sich, dass im ersten Teilschritt mit einem Höchstwert von 0,55 eine deutlich höhere Erkennungsrate erzielt wurde als im zweiten Schritt, in dem maximal 0,32 erreicht wurde. Allerdings liegt auch dieser Recall-Wert außerhalb eines für reale Zollanwendungen akzeptablen Bereichs, da die Vielzahl irrelevanter Entitäten zu einer geringeren praktischen Verwertbarkeit der Ergebnisse führt.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/441', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 50, 'bbox': {'l': 88.997, 't': 591.8210146484375, 'r': 507.798, 'b': 514.4420146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 478]}]}, {'self_ref': '#/texts/442', 'parent': {'$ref': '#/tables/12'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 50, 'bbox': {'l': 88.931, 't': 352.9400146484375, 'r': 505.988, 'b': 316.20901464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 171]}]}, {'self_ref': '#/tables/12', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/442'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 50, 'bbox': {'l': 88.38735961914062, 't': 502.23974609375, 'r': 505.9640808105469, 'b': 364.8191223144531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nDer resultierende F1-Score beträgt 0,3 im ersten und 0,4 im zweiten Teilschritt. Dies verdeutlicht, dass die Strategien beider kombinierter Ansätze derzeit noch nicht die erforderliche Extraktionsgenauigkeit für eine produktive Nutzung im Zollkontext erreichen. Die Ergebnisse unterstreichen die Notwendigkeit, den semantischen Kontext sowie die Formatierungsvorgaben stärker im Prompt-Design zu berücksichtigen, um die Präzision ohne signifikanten Verlust an Recall zu erhöhen.\\n\\nTabelle 5.1.: Auswertung der aggregierten Metriken - absteigend sortiert nach Recall - für alle Dokumente Promptmethode für die Extraktion durch Gpt-4o in Teilschritt eins'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/12', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/442'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 50, 'bbox': {'l': 88.38735961914062, 't': 502.23974609375, 'r': 505.9640808105469, 'b': 364.8191223144531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n877, FP = 3418. 877, FN = 725. 877, Accuracy = 0.17. 877, Precision = 0.2. 877, Recall = 0.55. 877, F1 = 0.3. 877, Methode = One-Shot. 870, FP = 2679. 870, FN = 732. 870, Accuracy = 0.2. 870, Precision = 0.25. 870, Recall = 0.54. 870, F1 = 0.34. 870, Methode = Few-Shot. 861, FP = 2948. 861, FN = 741. 861, Accuracy = 0.19. 861, Precision = 0.23. 861, Recall = 0.54. 861, F1 = 0.32. 861, Methode = One-Shot + IBL. 852, FP = 2854. 852, FN = 750. 852, Accuracy = 0.19. 852, Precision = 0.23. 852, Recall = 0.53. 852, F1 = 0.32. 852, Methode ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/12', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/442'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 50, 'bbox': {'l': 88.38735961914062, 't': 502.23974609375, 'r': 505.9640808105469, 'b': 364.8191223144531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/445', 'parent': {'$ref': '#/tables/13'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 51, 'bbox': {'l': 88.931, 't': 609.4500146484376, 'r': 506.221, 'b': 572.7190146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 221]}]}, {'self_ref': '#/tables/13', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/445'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 51, 'bbox': {'l': 88.20414733886719, 't': 758.0637741088867, 'r': 506.21624755859375, 'b': 621.4242095947266, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nFew-Shot + IBL. 624, FP = 3605. 624, FN = 978. 624, Accuracy = 0.12. 624, Precision = 0.15. 624, Recall = 0.39. 624, F1 = 0.21. 624, Methode = Zero-Shot. 616, FP = 3898. 616, FN = 986. 616, Accuracy = 0.11. 616, Precision = 0.14. 616, Recall = 0.38. 616, F1 = 0.2. 616, Methode = IBL\\n\\nTabelle 5.2.: Auswertung der aggregierten Metriken - absteigend sortiert nach Recall - für alle Dokumente pro Promptmethode für die Schemamigration der in Schritt eins gefundenen Entitäten durch Gpt-4o in Teilschritt zwei'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/13', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/445'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 51, 'bbox': {'l': 88.20414733886719, 't': 758.0637741088867, 'r': 506.21624755859375, 'b': 621.4242095947266, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n518, FP = 469. 518, FN = 1084. 518, Accuracy = 0.25. 518, Precision = 0.52. 518, Recall = 0.32. 518, F1 = 0.4. 518, Methode = IBL. 401, FP = 310. 401, FN = 1201. 401, Accuracy = 0.21. 401, Precision = 0.56. 401, Recall = 0.25. 401, F1 = 0.35. 401, Methode = Zero-Shot. 172, FP = 307. 172, FN = 1430. 172, Accuracy = 0.09. 172, Precision = 0.36. 172, Recall = 0.11. 172, F1 = 0.17. 172, Methode = One-Shot + IBL. 162, FP = 376. 162, FN = 1440. 162, Accuracy = 0.08. 162, Precision = 0.3. 162, Recall = 0.1. 162, F1 = 0.15. 162, Methode = One-Shot. 155, FP = 317. 155, FN ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/13', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/445'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 51, 'bbox': {'l': 88.20414733886719, 't': 758.0637741088867, 'r': 506.21624755859375, 'b': 621.4242095947266, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n1447. 155, Accuracy = 0.08. 155, Precision = 0.33. 155, Recall = 0.1. 155, F1 = 0.15. 155, Methode = Few-Shot + IBL. 142, FP = 275. 142, FN = 1460. 142, Accuracy = 0.08. 142, Precision = 0.34. 142, Recall = 0.09. 142, F1 = 0.14. 142, Methode = Few-Shot'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/446', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 51, 'bbox': {'l': 89.291, 't': 543.3910146484375, 'r': 508.108, 'b': 262.7740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1622]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nIm Vergleich dazu weist der Ansatz, der auf einer Kombination aus der Extraktion der Dokumenteninhalte durch Tesseract-OCR und der Entitätserkennung durch spaCy-NER basiert, eine deutlich geringere Extraktionsqualität auf (vgl. Tabelle 5.3). Die Analyse der Ergebnisse zeigt, dass die OCR-Komponente eine vergleichsweise hohe Fehlerquote aufweist, was insbesondere bei komplexen Layouts und geringer Scanqualität zu fehlerhaften oder unvollständigen Texteingaben führt. Infolgedessen ist auch die Qualität der nachgelagerten NER-Erkennung beeinträchtigt. Zwar identifiziert spaCy im Vergleich zum LLM eine größere Anzahl an Entitäten, was an den falsch positiven Werten zu erkennen ist,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/446', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 51, 'bbox': {'l': 89.291, 't': 543.3910146484375, 'r': 508.108, 'b': 262.7740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1622]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\njedoch ist der Anteil korrekt erkannter und relevanter Entitäten äußerst gering. Dies spiegelt sich deutlich in den Evaluationsmetriken wider: Die Accuracy liegt bei 0,06, die Precision bei lediglich 0,07, während ein Recall von 0,28 erreicht wird. Der daraus resultierende F1-Score beträgt 0,11. Diese Werte verdeutlichen, dass der klassische OCR-NER-Ansatz ohne Feinjustierung des Modells auf die spezifischen Zolldaten in der vorliegenden Anwendung weder hinreichend präzise, noch robust genug ist, um den Anforderungen an eine zuverlässige und kontextbezogene Extraktion von Zolldaten gerecht zu werden. Der Ansatz wurde ausschließlich im Rahmen von Teilschritt eins evaluiert, da eine Vorhersage der Entitäten gemäß dem definierten'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/446', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 51, 'bbox': {'l': 89.291, 't': 543.3910146484375, 'r': 508.108, 'b': 262.7740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1622]}]}, {'self_ref': '#/texts/447', 'parent': {'$ref': '#/tables/14'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 51, 'bbox': {'l': 116.964, 't': 199.05201464843753, 'r': 477.957, 'b': 189.4190146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 70]}]}, {'self_ref': '#/tables/14', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/447'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 51, 'bbox': {'l': 88.51636505126953, 't': 252.1807861328125, 'r': 505.9010314941406, 'b': 210.5975341796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nZollschema mit regelbasierten NER-Modellen wie spaCy - ohne explizite Modellierung zollspezifischer Entitätstypen - nicht möglich ist, eine für Teilschritt zwei benötigte Vergleichsbasis abzubilden.\\nTabelle 5.3.: Auswertung spaCy NER für die Extraktion Teilschritt eins\\n\\n447, FP = 5853. 447, FN = 1155. 447, Accuracy = 0.06. 447, Precision = 0.07. 447, Recall = 0.28. 447, F1 = 0.11'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/450', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 52, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 507.799, 'b': 622.8350146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 748]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nDie Bewertung des LLM-basierten Systems erfolgte durch den Abgleich der finalen Ausgabe mit einem speziell für den Zollanwendungsfall definierten Ausgabeschema. Dabei wurden sowohl die Kopfdaten als auch die Einzelpositionen pro Sendung analysiert (vgl. Tabelle 2.8). Neben den klassischen Metriken Precision, Recall und F1-Score auf Klassenebene wurden zusätzlich gewichtete Micro- und Macro-Durchschnitte berechnet. Diese ergänzenden Kennzahlen ermöglichten eine differenzierte Analyse der Extraktionsleistung einzelner Entitätsklassen und erlauben Rückschlüsse auf spezifische Schwächen. Dadurch lassen sich gezielte Nachjustierungen in zukünftigen Systemen ableiten und die Robustheit gegenüber domänenspezifischen Herausforderungen verbessern.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/451', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 52, 'bbox': {'l': 89.291, 't': 605.3700146484375, 'r': 507.8, 'b': 555.0890146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 282]}]}, {'self_ref': '#/texts/452', 'parent': {'$ref': '#/tables/15'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 52, 'bbox': {'l': 100.824, 't': 417.4980146484375, 'r': 494.097, 'b': 407.8650146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 75]}]}, {'self_ref': '#/tables/15', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/452'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 92.34635925292969, 't': 542.37109375, 'r': 501.95819091796875, 'b': 429.3252258300781, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nBei den Kopfdaten aller 30 Sendungen wurde im Zero-Shot-Modus ein Bestwert von 0,33 für die Micro-Precision, 0,14 für den Micro-Recall und 0,20 für den Micro-F1Score erzielt. Das bedeutet, dass lediglich 14% der benötigten Entitäten korrekt einer passenden Klasse zugeordnet wurden.\\n\\nTabelle 5.4.: Micro-basierte Metriken zur Bewertung der Kopfdatenextraktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/15', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/452'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 92.34635925292969, 't': 542.37109375, 'r': 501.95819091796875, 'b': 429.3252258300781, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nIBL, TP = 54. IBL, FP = 128. IBL, FN = 308. IBL, Mic.-Acc. = 0.11. IBL, Mic.-Prec. = 0.3. IBL, Mic.-Rec. = 0.15. IBL, Micro-F1 = 0.2. Zero-Shot, TP = 51. Zero-Shot, FP = 104. Zero-Shot, FN = 311. Zero-Shot, Mic.-Acc. = 0.11. Zero-Shot, Mic.-Prec. = 0.33. Zero-Shot, Mic.-Rec. = 0.14. Zero-Shot, Micro-F1 = 0.2. Few-Shot + IBL, TP = 28. Few-Shot + IBL, FP = 208. Few-Shot + IBL, FN = 334. Few-Shot + IBL, Mic.-Acc. = 0.05. Few-Shot + IBL, Mic.-Prec. = 0.12. Few-Shot + IBL, Mic.-Rec. = 0.08. Few-Shot'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/15', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/452'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 92.34635925292969, 't': 542.37109375, 'r': 501.95819091796875, 'b': 429.3252258300781, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n+ IBL, Micro-F1 = 0.09. One-Shot, TP = 23. One-Shot, FP = 247. One-Shot, FN = 339. One-Shot, Mic.-Acc. = 0.04. One-Shot, Mic.-Prec. = 0.09. One-Shot, Mic.-Rec. = 0.06. One-Shot, Micro-F1 = 0.07. Few-Shot, TP = 22. Few-Shot, FP = 202. Few-Shot, FN = 340. Few-Shot, Mic.-Acc. = 0.04. Few-Shot, Mic.-Prec. = 0.1. Few-Shot, Mic.-Rec. = 0.06. Few-Shot, Micro-F1 = 0.08. One-Shot + IBL, TP = 23. One-Shot + IBL, FP = 223. One-Shot + IBL, FN = 339. One-Shot + IBL, Mic.-Acc. = 0.04. One-Shot + IBL, Mic.-Prec. = 0.09.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/15', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/452'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 92.34635925292969, 't': 542.37109375, 'r': 501.95819091796875, 'b': 429.3252258300781, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/453', 'parent': {'$ref': '#/tables/16'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 52, 'bbox': {'l': 99.509, 't': 256.51801464843743, 'r': 495.411, 'b': 246.8850146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 75]}]}, {'self_ref': '#/tables/16', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/453'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 135.3126983642578, 't': 381.1279602050781, 'r': 459.1041259765625, 'b': 268.0418701171875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nOne-Shot + IBL, Mic.-Rec. = 0.06. One-Shot + IBL, Micro-F1 = 0.08\\n\\nTabelle 5.5.: Macro-basierte Metriken zur Bewertung der Kopfdatenextraktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/16', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/453'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 52, 'bbox': {'l': 135.3126983642578, 't': 381.1279602050781, 'r': 459.1041259765625, 'b': 268.0418701171875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nIBL, Macro-Precision = 0.18. IBL, Macro-Recall = 0.09. IBL, Macro-F1 = 0.17. Zero-Shot, Macro-Precision = 0.19. Zero-Shot, Macro-Recall = 0.09. Zero-Shot, Macro-F1 = 0.19. Few-Shot + IBL, Macro-Precision = 0.09. Few-Shot + IBL, Macro-Recall = 0.12. Few-Shot + IBL, Macro-F1 = 0.09. One-Shot, Macro-Precision = 0.04. One-Shot, Macro-Recall = 0.12. One-Shot, Macro-F1 = 0.08. Few-Shot, Macro-Precision = 0.06. Few-Shot, Macro-Recall = 0.07. Few-Shot, Macro-F1 = 0.07. One-Shot + IBL, Macro-Precision = 0.05. One-Shot + IBL, Macro-Recall = 0.07. One-Shot + IBL, Macro-F1 = 0.07'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/454', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 52, 'bbox': {'l': 89.291, 't': 217.55701464843753, 'r': 507.799, 'b': 167.27601464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 315]}]}, {'self_ref': '#/texts/457', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 53, 'bbox': {'l': 89.291, 't': 754.4110146484375, 'r': 507.794, 'b': 717.6800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 195]}]}, {'self_ref': '#/texts/458', 'parent': {'$ref': '#/tables/17'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 53, 'bbox': {'l': 88.931, 't': 566.2680146484375, 'r': 507.792, 'b': 543.0860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 87]}]}, {'self_ref': '#/tables/17', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/458'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 91.25425720214844, 't': 693.8180694580078, 'r': 502.8179931640625, 'b': 578.4704284667969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nFür die Einzelpositionen aller 30 Sendungen pro Promptversion wurden im ZeroShot-Modus eine maximale Micro-Precision von 0,69, ein Micro-Recall von 0,53 sowie ein Micro-F1-Score von 0,60 erzielt. Das bedeutet, dass 60% der benötigten Entitäten über alle Klassen hinweg korrekt extrahiert wurden. Im Vergleich zu den\\nErgebnissen der Kopfdaten stellt dies eine signifikante Verbesserung dar. Dennoch reicht diese Leistung nicht aus, um die notwendige Fehlertoleranzschwelle für kritische Zollprozesse zu erfüllen.\\n\\nTabelle 5.6.: Micro-basierte Metriken zur Bewertung der Extraktion der Einzelpositionen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/17', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/458'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 91.25425720214844, 't': 693.8180694580078, 'r': 502.8179931640625, 'b': 578.4704284667969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nZero-Shot, TP = 214. Zero-Shot, FP = 97. Zero-Shot, FN = 188. Zero-Shot, Mic.-Acc. = 0.43. Zero-Shot, Mic.-Prec. = 0.69. Zero-Shot, Mic.-Rec. = 0.53. Zero-Shot, Micro-F1 = 0.60. IBL, TP = 205. IBL, FP = 171. IBL, FN = 285. IBL, Mic.-Acc. = 0.31. IBL, Mic.-Prec. = 0.55. IBL, Mic.-Rec. = 0.42. IBL, Micro-F1 = 0.47. One-Shot + IBL, TP = 17. One-Shot + IBL, FP = 25. One-Shot + IBL, FN = 40. One-Shot + IBL, Mic.-Acc. = 0.21. One-Shot + IBL, Mic.-Prec. = 0.4. One-Shot + IBL, Mic.-Rec. = 0.3. One-Shot'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/17', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/458'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 91.25425720214844, 't': 693.8180694580078, 'r': 502.8179931640625, 'b': 578.4704284667969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n+ IBL, Micro-F1 = 0.34. One-Shot, TP = 30. One-Shot, FP = 66. One-Shot, FN = 92. One-Shot, Mic.-Acc. = 0.16. One-Shot, Mic.-Prec. = 0.31. One-Shot, Mic.-Rec. = 0.25. One-Shot, Micro-F1 = 0.28. Few-Shot + IBL, TP = 9. Few-Shot + IBL, FP = 26. Few-Shot + IBL, FN = 39. Few-Shot + IBL, Mic.-Acc. = 0.12. Few-Shot + IBL, Mic.-Prec. = 0.26. Few-Shot + IBL, Mic.-Rec. = 0.19. Few-Shot + IBL, Micro-F1 = 0.22. Few-Shot, TP = 6. Few-Shot, FP = 21. Few-Shot, FN = 30. Few-Shot, Mic.-Acc. = 0.11. Few-Shot, Mic.-Prec.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/17', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/458'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 91.25425720214844, 't': 693.8180694580078, 'r': 502.8179931640625, 'b': 578.4704284667969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/459', 'parent': {'$ref': '#/tables/18'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 53, 'bbox': {'l': 88.931, 't': 391.7380146484375, 'r': 507.795, 'b': 368.5560146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 87]}]}, {'self_ref': '#/tables/18', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/459'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 135.3564910888672, 't': 516.3240356445312, 'r': 459.24560546875, 'b': 404.0357666015625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\n= 0.22. Few-Shot, Mic.-Rec. = 0.17. Few-Shot, Micro-F1 = 0.19\\n\\nTabelle 5.7.: Macro-basierte Metriken zur Bewertung der Extraktion der Einzelpositionen'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/18', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/459'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 53, 'bbox': {'l': 135.3564910888672, 't': 516.3240356445312, 'r': 459.24560546875, 'b': 404.0357666015625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nZero-Shot, Macro-Precision = 0.41. Zero-Shot, Macro-Recall = 0.34. Zero-Shot, Macro-F1 = 0.35. IBL, Macro-Precision = 0.4. IBL, Macro-Recall = 0.29. IBL, Macro-F1 = 0.31. One-Shot + IBL, Macro-Precision = 0.18. One-Shot + IBL, Macro-Recall = 0.22. One-Shot + IBL, Macro-F1 = 0.19. One-Shot, Macro-Precision = 0.14. One-Shot, Macro-Recall = 0.17. One-Shot, Macro-F1 = 0.15. Few-Shot + IBL, Macro-Precision = 0.12. Few-Shot + IBL, Macro-Recall = 0.12. Few-Shot + IBL, Macro-F1 = 0.12. Few-Shot, Macro-Precision = 0.11. Few-Shot, Macro-Recall = 0.11. Few-Shot, Macro-F1 = 0.11'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/462', 'parent': {'$ref': '#/pictures/9'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 54, 'bbox': {'l': 88.899, 't': 525.7020146484375, 'r': 507.794, 'b': 502.5200146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 80]}]}, {'self_ref': '#/texts/488', 'parent': {'$ref': '#/pictures/10'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 54, 'bbox': {'l': 88.899, 't': 224.93001464843746, 'r': 507.794, 'b': 201.74801464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 87]}]}], 'headings': ['5. Evaluierung des Systems'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='5. Evaluierung des Systems\\nAbbildung 5.1.: Kopfdaten: Micro-Metriken in Abhängigkeit der LevenshteinDistanz\\nAbbildung 5.2.: Einzelpositionen: Micro-Metriken in Abhängigkeit der LevenshteinDistanz'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/515', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.757, 't': 642.6570146484376, 'r': 507.799, 'b': 524.6300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 655]}]}], 'headings': ['6. Zusammenfassung und Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6. Zusammenfassung und Ausblick\\nIn diesem Kapitel werden die zentralen Ergebnisse der vorliegenden Arbeit zusammengefasst und ein Ausblick auf zukünftige Forschungs- und Entwicklungsmöglichkeiten gegeben. Nach einer kompakten Darstellung der wesentlichen Erkenntnisse aus den empirischen Analysen und der Evaluation des entwickelten Systems werden darauf aufbauend Potenziale und Herausforderungen für weiterführende Arbeiten sowie mögliche Anwendungsperspektiven aufgezeigt. Ziel ist es, die erreichten Fortschritte im Kontext der automatisierten Informationsextraktion aus Zolldokumenten kritisch zu reflektieren und Ansatzpunkte für eine kontinuierliche Weiterentwicklung aufzuzeigen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/517', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.931, 't': 454.64801464843754, 'r': 507.799, 'b': 323.0730146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 733]}]}], 'headings': ['6.1. Erreichte Ergebnisse'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.1. Erreichte Ergebnisse\\nIm Rahmen der Evaluation zeigte sich, dass die Extraktionsgenauigkeit auf Ebene der Einzelpositionen deutlich höher ausfiel als bei den Kopfdaten (vgl. Tabelle 5.6, Tabelle 5.4). Insbesondere die Wahl des Schwellenwerts für die Levenshtein-Distanz hatte einen maßgeblichen Einfluss auf die erzielten Metriken: Während die Metriken Micro-Accuracy und Micro-Recall sowie der Micro-F1 über einen weiten Schwellenwertbereich weitgehend stabil blieben, war bei den Kopfdaten ab einem Schwellenwert von mehr als 90% ein deutlicher Rückgang der Precision zu beobachten (vgl. Abbildung 5.2, Abbildung 5.1). Die besten Ergebnisse hinsichtlich Micro-Accuracy und Micro-F1 wurden für die Einzelpositionen bei'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/517', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.931, 't': 454.64801464843754, 'r': 507.799, 'b': 323.0730146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 733]}]}, {'self_ref': '#/texts/518', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.866, 't': 319.15701464843755, 'r': 507.797, 'b': 255.3270146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 348]}]}], 'headings': ['6.1. Erreichte Ergebnisse'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.1. Erreichte Ergebnisse\\nSchwellenwerten größer 90% erzielt.\\nDie Ergebnisse verdeutlichen zudem, dass die Leistungsfähigkeit des Systems maßgeblich von der Qualität und Struktur der zugrunde liegenden Daten beeinflusst wird. Insgesamt zeigen die empirischen Analysen, dass die Extraktionspipeline derzeit noch nicht ausreichend robust ist, um zollkritische Prozesse vollumfänglich und automatisiert abzulösen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/520', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 89.291, 't': 185.34501464843754, 'r': 507.799, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 153]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nDurch die aktuell unzureichende Extraktionsgenauigkeit, insbesondere bei den Kopfdaten, sowie die beobachteten Schwankungen in den erzielten Metriken be-'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/523', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.799, 'b': 555.0890146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1160]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nsteht weiterhin Optimierungsbedarf im Gesamtsystem. Zukünftige Arbeiten sollten sich daher auf die Verbesserung der Extraktionsleistung und der Robustheit der Extraktionspipeline konzentrieren. Insbesondere könnten weiterführende Untersuchungen die Verwendung unterschiedlicher Ähnlichkeits- und Distanzmaße prüfen, wie beispielsweise der Cosinus-Ähnlichkeit oder darauf aufbauender Metriken wie dem BERTScore zur Bewertung von LLMs [8]. Auch der Einsatz fortgeschrittener Sprachmodelle oder die Integration domänenspezifischen Kontexts könnte zu einer signifikanten Steigerung der Extraktionsleistung beitragen. Darüber hinaus erscheint eine Evaluation des Ansatzes auf größeren und diversifizierten Datensätzen unter Berücksichtigung weiterer'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/523', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 88.866, 't': 754.4110146484375, 'r': 507.799, 'b': 555.0890146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1160]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nÄhnlichkeits- und Distanzmaße sinnvoll, um die Generalisierbarkeit der Ergebnisse zu überprüfen. Es liegt nahe zu vermuten, dass die Systemleistung durch zusätzliche Vorverarbeitungsschritte, etwa eine vorgelagerte Dokumententyp-Klassifikation, weiter gesteigert werden könnte [34]. Auf dieser Basis könnten anschließend spezialisierte Prompts eingesetzt werden, die auf die jeweilige Dokumentenart abgestimmt sind.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/524', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 88.899, 't': 551.1730146484375, 'r': 507.797, 'b': 406.0480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 825]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nDie im Rahmen dieser Arbeit erzielten Ergebnisse lassen sich prinzipiell durch verschiedene Maßnahmen erweitern. Zum einen besteht die Möglichkeit, das entwickelte System um zusätzliche Dokumenttypen oder weitere Felder zu ergänzen, um eine breitere Abdeckung im Bereich zollrelevanter Unterlagen zu erreichen. Zum anderen kann die Extraktionspipeline durch gezielte und feinere Vorverarbeitungsschritte weiter verbessert werden. Darüber hinaus eröffnet der modulare Aufbau des Ansatzes Potenzial für die Einbindung zusätzlicher Verarbeitungsschritte, etwa zur Validierung, semantischen Anreicherung oder Nachbearbeitung der extrahierten Daten. Insgesamt bieten sich somit vielfältige Ansatzpunkte, um die'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/524', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 88.899, 't': 551.1730146484375, 'r': 507.797, 'b': 406.0480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 825]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nFunktionalität und Leistungsfähigkeit des Systems sukzessive auszubauen und an sich wandelnde Anforderungen anzupassen.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/525', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 89.291, 't': 402.1320146484375, 'r': 507.799, 'b': 270.55601464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 756]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nDie Übertragbarkeit der im Rahmen dieser Arbeit gewonnenen Erkenntnisse auf andere Anwendungsbereiche oder Dokumenttypen ist grundsätzlich gegeben, unterliegt jedoch bestimmten Einschränkungen. Insbesondere hängt der Erfolg einer Übertragung maßgeblich von der Ähnlichkeit der zugrundeliegenden Dokumentstrukturen sowie von der Verfügbarkeit passender Trainingsdaten ab. Für stark abweichende oder heterogene Dokumenttypen kann eine erneute Anpassung der Extraktionspipeline oder eine gezielte Feinabstimmung der verwendeten Prompts erforderlich werden. Nichtsdestotrotz legt die entwickelte Methodik ein Fundament, das mit überschaubarem Aufwand für verwandte Aufgabenstellungen im Bereich der automatisierten Informationsextraktion adaptiert werden'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/525', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 56, 'bbox': {'l': 89.291, 't': 402.1320146484375, 'r': 507.799, 'b': 270.55601464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 756]}]}], 'headings': ['6.2. Ausblick'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='6.2. Ausblick\\nkann.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/527', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 652.0610146484375, 'r': 508.117, 'b': 601.7470146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 264]}]}, {'self_ref': '#/texts/528', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 593.3480146484375, 'r': 437.717, 'b': 583.7150146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 66]}]}, {'self_ref': '#/texts/529', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 575.3490146484376, 'r': 510.566, 'b': 525.0350146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 220]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [1] Patrizio Bellan u. a. Process Extraction from Text: Benchmarking the State of the Art and Paving the Way for Future Challenges . arXiv:2110.03754 [cs]. Okt. 2023. DOI: 10.48550/arXiv.2110.03754 . URL: http://arxiv.org/abs/ 2110.03754 (besucht am 27. 07. 2025).\\n- [2] Michael Sherman u.a. 'Reviewers and Contributors'. en. In: ().\\n- [3] Anisa Rula und Jennifer D'Souza. Procedural Text Mining with Large Language Models . arXiv:2310.03376 [cs]. Okt. 2023. DOI: 10.48550/arXiv. 2310.03376 . URL: http://arxiv.org/abs/2310.03376 (besucht am 27. 07. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/530', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 516.6690146484375, 'r': 510.566, 'b': 466.35501464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 229]}]}, {'self_ref': '#/texts/531', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 457.9890146484375, 'r': 507.294, 'b': 407.6750146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 259]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [4] Noman Islam, Zeeshan Islam und Nazia Noor. A Survey on Optical Character Recognition System . arXiv:1710.05703 [cs]. Okt. 2017. DOI: 10.48550/arXiv. 1710.05703 . URL: http://arxiv.org/abs/1710.05703 (besucht am 17. 04. 2025).\\n- [5] Jiawei Wang u. a. Detect-Order-Construct: A Tree Construction based Approach for Hierarchical Document Structure Analysis . arXiv:2401.11874 [cs]. März 2024. DOI: 10.48550/arXiv.2401.11874 . URL: http://arxiv.org/abs/ 2401.11874 (besucht am 02. 06. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/532', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 399.30901464843754, 'r': 508.112, 'b': 348.9950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 258]}]}, {'self_ref': '#/texts/533', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 340.5960146484375, 'r': 505.981, 'b': 317.4130146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 126]}]}, {'self_ref': '#/texts/534', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 309.0140146484375, 'r': 508.115, 'b': 231.6350146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 368]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [6] Vishwanath D u. a. Deep Reader: Information extraction from Document images via relation extraction and Natural Language . arXiv:1812.04377 [cs]. Dez. 2018. DOI: 10.48550/arXiv.1812.04377 . URL: http://arxiv.org/abs/ 1812.04377 (besucht am 02. 06. 2025).\\n- [7] Kirill Smelyakov u. a. 'Effectiveness of Modern Text Recognition Solutions and Tools for Common Data Sources'. en. In: ().\\n- [8] '(PDF) Performance Metrics for Multilabel Emotion Classification: Comparing Micro, Macro, and Weighted F1-Scores'. en. In: ResearchGate (Apr. 2025). DOI: 10.3390/app14219863 . URL: https://www.researchgate.net/ publication/385324843_Performance_Metrics_for_Multilabel_ Emotion_Classification_Comparing_Micro_Macro_and_Weighted_ F1-Scores (besucht am 28. 07. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/535', 'parent': {'$ref': '#/groups/4'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 57, 'bbox': {'l': 95.357, 't': 223.2360146484375, 'r': 507.794, 'b': 172.95501464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 283]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [9] Meharuniza Nazeem u.a. 'Open-Source OCR Libraries: A Comprehensive Study for Low Resource Language'. In: Proceedings of the 21st International Conference on Natural Language Processing (ICON) . Hrsg. von Sobha Lalitha Devi und Karunesh Arora. AU-KBC Research Centre, Chennai, In-\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/538', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 118.942, 't': 754.4110146484375, 'r': 509.256, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 135]}]}, {'self_ref': '#/texts/539', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 723.6500146484375, 'r': 509.256, 'b': 659.7880146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 363]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- dia: NLP Association of India (NLPAI), Dez. 2024, S. 416-421. URL: https: //aclanthology.org/2024.icon-1.48/ (besucht am 31. 05. 2025).\\n- [10] R. Smith. 'An Overview of the Tesseract OCR Engine'. en. In: Ninth International Conference on Document Analysis and Recognition (ICDAR 2007) Vol 2 . ISSN: 1520-5363. Curitiba, Parana, Brazil: IEEE, Sep. 2007, S. 629-633. ISBN: 978-0-7695-2822-9. DOI: 10.1109/ICDAR.2007.4376991 . URL: http: //ieeexplore.ieee.org/document/4376991/ (besucht am 17. 04. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/540', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 652.1760146484376, 'r': 507.29, 'b': 601.8960146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 240]}]}, {'self_ref': '#/texts/541', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 594.3170146484375, 'r': 508.112, 'b': 557.5530146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 219]}]}, {'self_ref': '#/texts/542', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 549.9410146484375, 'r': 507.8, 'b': 526.7590146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 136]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [11] Prakash Nadkarni, Lucila Ohno-Machado und Wendy Chapman. 'Natural language processing: An introduction'. In: Journal of the American Medical Informatics Association : JAMIA 18 (Sep. 2011), S. 544-51. DOI: 10.1136/ amiajnl-2011-000464 .\\n- [12] Diksha Khurana u.a. Natural Language Processing: State of The Art, Current Trends and Challenges . en. Aug. 2017. DOI: 10.1007/s11042-022-13428-4 . URL: https://arxiv.org/abs/1708.05148v1 (besucht am 02. 06. 2025).\\n- [13] Matthew Honnibal u.a. 'spaCy: Industrial-strength Natural Language Processing in Python'. In: (2020). DOI: 10.5281/zenodo.1212303 .\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/543', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 519.1810146484376, 'r': 508.764, 'b': 468.86701464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 212]}]}, {'self_ref': '#/texts/544', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 461.2890146484375, 'r': 508.112, 'b': 410.97501464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 230]}]}, {'self_ref': '#/texts/545', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 403.3970146484375, 'r': 536.134, 'b': 366.6320146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 201]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [14] Google. Whitepaper Foundational Large Language Models & Text Generation . eng. Okt. 2024. URL: http://archive.org/details/whitepaperfoundational-large-language-models-text-generation (besucht am 10.06.2025).\\n- [15] Imed Keraghel, Stanislas Morbieu und Mohamed Nadif. Recent Advances in Named Entity Recognition: A Comprehensive Survey and Comparative Study . en. Jan. 2024. URL: https://arxiv.org/abs/2401.10825v3 (besucht am 03. 06. 2025).\\n- [16] Tong Xiao und Jingbo Zhu. Foundations of Large Language Models . arXiv:2501.09223 [cs]. Jan. 2025. DOI: 10.48550/arXiv.2501.09223 . URL: http://arxiv. org/abs/2501.09223 (besucht am 26. 01. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/546', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 359.0540146484375, 'r': 508.114, 'b': 322.2890146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 184]}]}, {'self_ref': '#/texts/547', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 314.7110146484375, 'r': 510.563, 'b': 250.84801464843758, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 292]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [17] Ashish Vaswani u.a. Attention Is All You Need . arXiv:1706.03762 [cs]. Aug. 2023. DOI: 10.48550/arXiv.1706.03762 . URL: http://arxiv.org/abs/ 1706.03762 (besucht am 22. 12. 2024).\\n- [18] Stefania Cristina. How to Implement Scaled Dot-Product Attention from Scratch in TensorFlow and Keras . en-US. Sep. 2022. URL: https://www. machinelearningmastery.com/how- to- implement- scaled- dotproduct- attention- from- scratch- in- tensorflow- and- keras/ (besucht am 03. 07. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/548', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 243.23701464843748, 'r': 508.116, 'b': 206.5050146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 161]}]}, {'self_ref': '#/texts/549', 'parent': {'$ref': '#/groups/5'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 58, 'bbox': {'l': 89.291, 't': 198.92701464843753, 'r': 510.566, 'b': 162.16301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 169]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [19] Jason Wei u. a. 'Finetuned Language Models are Zero-Shot Learners'. In: Okt. 2021. URL: https://openreview.net/forum?id=gEZrGCozdqR (besucht am 19.02.2025).\\n- [20] OpenAI u.a. GPT-4o System Card . arXiv:2410.21276 [cs]. Okt. 2024. DOI: 10. 48550/arXiv.2410.21276 . URL: http://arxiv.org/abs/2410.21276 (besucht am 15. 04. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/552', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 754.4440146484375, 'r': 510.564, 'b': 704.1300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 271]}]}, {'self_ref': '#/texts/553', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 695.7640146484375, 'r': 508.111, 'b': 645.4500146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 285]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [21] Sakib Shahriar u. a. Putting GPT-4o to the Sword: A Comprehensive Evaluation of Language, Vision, Speech, and Multimodal Proficiency . arXiv:2407.09519 [cs]. Juni 2024. DOI: 10.48550/arXiv.2407.09519 . URL: http://arxiv. org/abs/2407.09519 (besucht am 15. 04. 2025).\\n- [22] Gavin Greif, Niclas Griesshaber und Robin Greif. Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents . arXiv:2504.00414 [cs]. Apr. 2025. DOI: 10.48550/arXiv.2504.00414 . URL: http://arxiv.org/abs/2504.00414 (besucht am 15. 04. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/554', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 637.0840146484375, 'r': 510.571, 'b': 586.7700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 226]}]}, {'self_ref': '#/texts/555', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 578.4040146484375, 'r': 510.571, 'b': 528.0900146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 227]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [23] Gabriel Recchia. Teaching Autoregressive Language Models Complex Tasks By Demonstration . arXiv:2109.02102 [cs]. Dez. 2021. DOI: 10.48550/arXiv. 2109.02102 . URL: http://arxiv.org/abs/2109.02102 (besucht am 19. 02. 2025).\\n- [24] Dhananjay Ashok und Zachary C. Lipton. PromptNER: Prompting For Named Entity Recognition . arXiv:2305.15444 [cs]. Juni 2023. DOI: 10.48550/arXiv. 2305.15444 . URL: http://arxiv.org/abs/2305.15444 (besucht am 03. 06. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/556', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 519.7240146484376, 'r': 510.566, 'b': 469.41001464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 246]}]}, {'self_ref': '#/texts/557', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 461.0440146484375, 'r': 508.111, 'b': 424.2800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 212]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [25] Yizhong Wang u.a. Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks . arXiv:2204.07705 [cs]. Okt. 2022. DOI: 10. 48550/arXiv.2204.07705 . URL: http://arxiv.org/abs/2204.07705 (besucht am 27. 06. 2025).\\n- [26] Jiawei Chen u. a. Learning In-context Learning for Named Entity Recognition . arXiv:2305.11038 [cs]. Mai 2023. DOI: 10.48550/arXiv.2305.11038 . URL: http://arxiv.org/abs/2305.11038 (besucht am 27. 06. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/558', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 415.8800146484375, 'r': 508.111, 'b': 324.9520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 438]}]}, {'self_ref': '#/texts/559', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 316.5860146484375, 'r': 510.562, 'b': 266.27201464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 240]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [27] Jiasheng Zhang u.a. '2INER: Instructive and In-Context Learning on FewShot Named Entity Recognition'. In: Findings of the Association for Computational Linguistics: EMNLP 2023 . Hrsg. von Houda Bouamor, Juan Pino und Kalika Bali. Singapore: Association for Computational Linguistics, Dez. 2023, S. 3940-3951. DOI: 10.18653/v1/2023.findings-emnlp.259 . URL: https://aclanthology.org/2023.findings-emnlp.259/ (besucht am 27. 06. 2025).\\n- [28] K. M. Sajjadul Islam u. a. LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs . arXiv:2505.08704 [cs]. Mai 2025. DOI: 10. 48550/arXiv.2505.08704 . URL: http://arxiv.org/abs/2505.08704 (besucht am 21. 07. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/560', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 59, 'bbox': {'l': 89.291, 't': 257.9060146484376, 'r': 508.111, 'b': 207.5920146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 284]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [29] Andres Azqueta-Gavaldón und Joaquin Ramos Cosgrove. Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification . arXiv:2507.11086 [cs]. Juli 2025. DOI: 10.48550/arXiv.2507.11086 . URL: http://arxiv.org/abs/2507.11086 (besucht am 21. 07. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/563', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 60, 'bbox': {'l': 89.291, 't': 754.4440146484375, 'r': 510.569, 'b': 704.1300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 223]}]}, {'self_ref': '#/texts/564', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 60, 'bbox': {'l': 89.291, 't': 695.7640146484375, 'r': 514.0, 'b': 659.0000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 216]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Literatur\\n- [30] Long Ouyang u.a. Training language models to follow instructions with human feedback . arXiv:2203.02155 [cs]. März 2022. DOI: 10.48550/arXiv. 2203.02155 . URL: http://arxiv.org/abs/2203.02155 (besucht am 10. 02. 2025).\\n- [31] Andrew K. Lampinen u.a. Can language models learn from explanations in context? arXiv:2204.02329 [cs]. Okt. 2022. DOI: 10.48550/arXiv.2204. 02329 . URL: http://arxiv.org/abs/2204.02329 (besucht am 19. 02. 2025).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/565', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 60, 'bbox': {'l': 89.291, 't': 650.6330146484376, 'r': 510.57, 'b': 613.8690146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 195]}]}, {'self_ref': '#/texts/566', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 60, 'bbox': {'l': 89.291, 't': 605.4690146484376, 'r': 507.794, 'b': 541.6400146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 321]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [32] Tom B. Brown u. a. Language Models are Few-Shot Learners . arXiv:2005.14165 [cs]. Juli 2020. DOI: 10.48550/arXiv.2005.14165 . URL: http://arxiv. org/abs/2005.14165 (besucht am 19. 02. 2025).\\n- [33] Zeyi Wen u.a. '2ED: An Efficient Entity Extraction Algorithm Using TwoLevel Edit-Distance'. In: 2019 IEEE 35th International Conference on Data Engineering (ICDE) . ISSN: 2375-026X. Apr. 2019, S. 998-1009. DOI: 10.1109/ ICDE.2019.00093 . URL: https://ieeexplore.ieee.org/document/ 8731344/ (besucht am 27. 07. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/567', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 60, 'bbox': {'l': 89.291, 't': 533.2400146484375, 'r': 527.091, 'b': 482.9600146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 297]}]}], 'headings': ['Literatur'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Literatur\\n- [34] Shuo Jiang u. a. 'Deep Learning for Technical Document Classification'. In: IEEE Transactions on Engineering Management 71 (2024). arXiv:2106.14269 [cs], S. 1163-1179. ISSN: 0018-9391, 1558-0040. DOI: 10.1109/TEM.2022. 3152216 . URL: http://arxiv.org/abs/2106.14269 (besucht am 28. 07. 2025).\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/570', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 61, 'bbox': {'l': 89.291, 't': 603.6700146484375, 'r': 505.98, 'b': 580.4880146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 122]}]}, {'self_ref': '#/texts/571', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 61, 'bbox': {'l': 85.226, 't': 570.7260146484375, 'r': 482.854, 'b': 167.40801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 740]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\nIn Listing A.1 ist die Umsetzung der Umwandlung der PDF-Dateien zu Bildformaten sowie der Extraktionsschritt über das LLM.\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/571', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 61, 'bbox': {'l': 85.226, 't': 570.7260146484375, 'r': 482.854, 'b': 167.40801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 740]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n1 # Module 2 import dataiku 3 import pandas as pd, numpy as np 4 from dataiku import pandasutils as pdu 5 import os 6 import fitz # PyMuPDF 7 import io 8 from PIL import Image 9 import base64 10 import json 11 from openai import AzureOpenAI 12 import tiktoken 13 import logging 14 import re 15 16 17 logger = logging.getLogger(__name__) 18 19 20 logging.basicConfig( 21 level=logging.INFO, 22 format=\\'%(asctime)s [%(levelname)s] [%(name)s] %(message)s\\' 23 ) 24 25 26 # Daten einlesen 27 zolldokumente = dataiku.Folder(\"8hG3cHjI\") 28 prompts = dataiku.Dataset(\"Prompts_Task_1\") 29 prompts_df = prompts.get_dataframe() 30 31 # Projektvariablen für Azure OpenAI einlesen 32 project = dataiku.Project()'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/571', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 61, 'bbox': {'l': 85.226, 't': 570.7260146484375, 'r': 482.854, 'b': 167.40801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 740]}]}, {'self_ref': '#/texts/571', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 61, 'bbox': {'l': 85.226, 't': 570.7260146484375, 'r': 482.854, 'b': 167.40801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 740]}]}, {'self_ref': '#/texts/574', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 62, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 514.735, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1551]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n33 variables = project.get_variables() 34\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/574', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 62, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 514.735, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1551]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"A.1. Implementierung der Extraktionspipeline\\n35 AZURE_OPENAI_ENDPOINT = variables['standard']['AZURE_OPENAI_ENDPOINT'] 36 AZURE_OPENAI_KEY = variables['standard']['AZURE_OPENAI_KEY'] 37 AZURE_OPENAI_API_VERSION = variables['standard']['AZURE_OPENAI_API_VERSION'] 38 AZURE_OPENAI_MODEL = variables['standard']['AZURE_OPENAI_MODEL'] 39 FOLDER_URL = variables['standard']['FOLDER_URL'] 40 41 # Tiktoken um Tokenanzahl pro Dokument zu bestimmen 42 encoding = tiktoken.encoding_for_model('gpt-4o') 43 44 45 # Azure OpenAI client 46 client = AzureOpenAI( 47 azure_endpoint=AZURE_OPENAI_ENDPOINT, 48 api_key=AZURE_OPENAI_KEY, 49 api_version=AZURE_OPENAI_API_VERSION 50 ) 51 52 # Prompts der verschiedenen Verfahren 53 parameters =\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/574', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 62, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 514.735, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1551]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\nprompts_df[[\\'Version\\', \\'System Prompt\\', \\'User Prompt\\']] 54 55 56 # Funktion um PDF in Bild umzuwandeln 57 def pdf_to_base64_images(pdf_stream): 58 try: 59 pdf_document = fitz.open(stream=pdf_stream, filetype=\"pdf\") # Opening the PDF from the stream 60 base64_images = [] 61 62 for page_num in range(len(pdf_document)): 63 logger.info(f\"[PDF->BASE64]: pagenumber {page_num}\") 64 page = pdf_document.load_page(page_num) # Get the page 65 pix = page.get_pixmap() # Convert the page to a pixmap (image) 66 img = Image.open(io.BytesIO(pix.tobytes())) # Convert pixmap to PIL Image 67 68 # Save image to BytesIO instead of temporary file 69 img_byte_arr ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/574', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 62, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 514.735, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1551]}]}, {'self_ref': '#/texts/574', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 62, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 514.735, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1551]}]}, {'self_ref': '#/texts/577', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 63, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 532.668, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1267]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\nio.BytesIO() 70 img.save(img_byte_arr, format=\"PNG\") 71 img_byte_arr.seek(0) 72 73 # Convert the image to base64 74 base64_image = base64.b64encode(img_byte_arr.read()).decode(\\'utf-8\\') 75 base64_images.append(base64_image)\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/577', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 63, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 532.668, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1267]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n76 77 return base64_images 78 except Exception as e: 79 logger.error(f\"[PDF TO BASE 64] Error: {e}\") 80 81 82 83 # Funktion für Extraktion mit OpenAI Gpt-4o 84 def extract_customs_data(base64_image, url, system_prompt, user_prompt, max_retries=5, backoff_factor=2): 85 last_exception = None 86 for attempt in range(1, max_retries + 1): 87 try: 88 logger.info(f\"[GPT4 CALL]: sys prompt {system_prompt[:20]}\") 89 logger.info(f\"[PDF->BASE64]: usr prompt {user_prompt[:20]}\") 90 91 # LLM Aufruf 92 response = client.chat.completions.create( 93 model=AZURE_OPENAI_MODEL, 94 response_format={ \"type\": \"json_object\" }, 95 messages=[ 96 { 97 \"role\": \"system\", 98'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/577', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 63, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 532.668, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1267]}]}, {'self_ref': '#/texts/577', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 63, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 532.668, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1267]}]}, {'self_ref': '#/texts/580', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 64, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 494.818, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1749]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n\"content\": system_prompt.format(url=url) 99 }, 100 { 101 \"role\": \"user\", 102 \"content\": [ 103 {\"type\": \"text\", \"text\": user_prompt}, 104 {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\", \"detail\": \"high\"}} 105 ] 106 } 107 ], 108 temperature=0.0, 109 ) 110 return response.choices[0].message.content 111 except Exception as e: 112 last_exception = e 113 logger.warning(f\"[GPT4 EXTRACT] Attempt {attempt}/{max_retries} failed: {e}\") 114 if attempt < max_retries: 115 sleep_time = backoff_factor ** (attempt -1) 116 logger.info(f\"[GPT4 EXTRACT]Retrying in {sleep_time} seconds...\")\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/580', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 64, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 494.818, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1749]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n117 time.sleep(sleep_time) 118 logger.error(f\"[GPT4 EXTRACT] All {max_retries} attempts failed.\") 119 raise last_exception 120 121 122 123 # Funktion für Multiseiten PDF extraktion und Umwandlung in JSON 124 def extract_from_multiple_pages(base64_images, original_filename, sendungsnummer, output_folder, url, system_prompt, user_prompt, version): 125 entire_documents = [] 126 tokens_count = {\\'count_tokens_doc\\':0} 127 version_prompt = {\\'prompt_version\\':version} 128 sendung = {\\'sendung\\': sendungsnummer} 129 130 for num, base64_image in enumerate(base64_images): 131 try: 132 document_json = extract_customs_data(base64_image, url, system_prompt, user_prompt) 133 document_data = json.loads(document_json) 134 logger.info(f\"[DOC EXTRACT MULT]'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/580', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 64, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 494.818, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1749]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\ndoc number: {num}, version: {version}\") 135 logger.info(f\"[DOC EXTRACT MULT] doc content: {document_json[:200]}\") 136 if isinstance(document_data, list): 137 entire_documents.extend(document_data) 138 elif isinstance(document_data, dict): 139 entire_documents.append(document_data) 140 else: 141 logger.warning(f\"Unerwarteter Typ von document_data: {type(document_data)}\") 142 except Exception as e: 143 logger.error(f\"[GPT4 EXTRACT MULT] Error: {e}\") 144 tokens = encoding.encode(str(entire_documents)) 145 tokens_count[\\'count_tokens_doc\\'] = len(tokens) 146 147 entire_documents.append(sendung) 148 entire_documents.append(tokens_count) 149 entire_documents.append(version_prompt) 150 151 # Dateinname definieren 152'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/580', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 64, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 494.818, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1749]}]}, {'self_ref': '#/texts/580', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 64, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 494.818, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1749]}]}, {'self_ref': '#/texts/583', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/584'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 65, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 490.825, 'b': 446.0700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 857]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"A.1. Implementierung der Extraktionspipeline\\noutput_filename = original_filename.replace('.pdf', f'extracted_{version}.json') 153 154 # Json in verteiltes Dateisystem schreiben 155 json_object = json.dumps(entire_documents, ensure_ascii=False, indent=4).encode('utf-8') 156 with output_folder.get_writer(output_filename) as writer:\\n```\\n```\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/583', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/584'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 65, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 490.825, 'b': 446.0700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 857]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\n157 writer.write(json_object) 158 159 # Funktionsaufrufe 160 output_folder = dataiku.Folder() 161 for version, system_prompt, user_prompt in parameters.itertuples(index=False, name=None): 162 for path in zolldokumente.list_paths_in_partition(): 163 sendungsnummer = path.split(\\'/\\')[1].split(\\'/\\')[0] 164 url = FOLDER_URL + path 165 filename = os.path.basename(path) 166 if path.endswith(\".pdf\"): 167 try: 168 # PDF zu Bild konvertieren 169 with zolldokumente.get_download_stream(path) as stream: 170 pdf_bytes = stream.read() 171 pdf_stream = io.BytesIO(pdf_bytes) 172 base64_images = pdf_to_base64_images(pdf_stream) 173 174 # Dateiinhalt extrahieren 175'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/583', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/584'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 65, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 490.825, 'b': 446.0700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 857]}]}, {'self_ref': '#/texts/583', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/584'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 65, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 490.825, 'b': 446.0700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 857]}]}, {'self_ref': '#/texts/583', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/584'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 65, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 490.825, 'b': 446.0700146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 857]}]}, {'self_ref': '#/texts/584', 'parent': {'$ref': '#/texts/583'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 65, 'bbox': {'l': 89.291, 't': 435.08801464843754, 'r': 505.99, 'b': 411.9060146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 106]}]}], 'headings': ['A.1. Implementierung der Extraktionspipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.1. Implementierung der Extraktionspipeline\\nextract_from_multiple_pages(base64_images, filename, sendungsnummer, output_folder, url, system_prompt, user_prompt, version) 176 except Exception as e: 177 logger.error(f\"Error processing {path}: {e}\")\\n```\\nListing A.1: LLM als OCR Ersatz - Umwandlung von PDF in Bild und Extraktion der Entitäten von Bild zu Text\\n'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}, {'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\n```\\n1 # Module 2 import dataiku 3 import pandas as pd, numpy as np 4 from dataiku import pandasutils as pdu 5 import os 6 import io 7 import json 8 from openai import AzureOpenAI 9 from pydantic import BaseModel 10 from typing import List, Optional 11 from datetime import datetime 12 13 # Pydantic Modelle um Schema Prüfung für Output durchzuführen 14 class Zollkopfdaten(BaseModel): 15 frachtbrief_packstueckanzahl: Optional[int] 16 frachtbrief_bruttogewicht: Optional[float] 17 frachtbrief_versendungsdatum: Optional[datetime] 18 zolldokument_MRN: Optional[str] 19 zolldokument_verschluss_feld_19_10: Optional[str] 20 zolldokument_wareneingangsnummer_stempel: Optional[str] 21'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\nzolldokument_frist: Optional[datetime] 22 zolldokument_positionen_insgesamt: Optional[int] 23 zolldokument_packstücke_insgesamt: Optional[int] 24 zolldokument_gesamtrohmasse: Optional[float] 25 rechnung_rechnungsnummer: Optional[str] 26 rechnung_rechnungsdatum: Optional[datetime] 27 rechnung_bestellnummern: List[Optional[str]] 28 rechnung_lieferplan: Optional[str] 29 rechnung_einzelpositionen_gesamtanzahl: Optional[int] 30 rechnung_ursprungserklaerung_text: Optional[str] 31 lieferschein_lieferscheinnummern: List[Optional[str]] 32 lieferschein_lieferantennamen: Optional[str] 33 lieferschein_versenderland: Optional[str]'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\n34 lieferschein_lieferplan: Optional[str] 35 lieferschein_einzelpositionen_anzahl: Optional[int] 36 lieferschein_ursprungserklaerung_text: Optional[str] 37 incoterm: Optional[str] 38 eori_gb_ukraine_registrierungsnummer: Optional[str] 39 atr_feld_4: Optional[str] 40 atr_feld_5: Optional[str] 41 atr_feld_6: Optional[str] 42 atr_feld_12_stempel: Optional[str] 43 atr_feld_13_stempel: Optional[str] 44 eur1_feld_2: Optional[str] 45 eur1_feld_4: Optional[str] 46 eur1_feld_5: Optional[str] 47 eur1_feld_11_stempel: Optional[str] 48'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}, {'self_ref': '#/texts/588', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 66, 'bbox': {'l': 85.226, 't': 735.0160146484375, 'r': 470.898, 'b': 164.32601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1867]}]}, {'self_ref': '#/texts/591', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 67, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 464.921, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\neur1_feld_12_stempel: Optional[str]\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/591', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 67, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 464.921, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\n49 sendungsnummer: None 50 referenz_zu_dokument: str 51 52 53 class Zolleinzelpositionen(BaseModel): 54 artikelnummer: Optional[str] 55 preis: Optional[float] 56 waehrung: Optional[str] 57 menge: Optional[float] 58 menge_maßeinheit: Optional[str] 59 eigenmasse: Optional[float] 60 eigenmasse_maßeinheit: Optional[str] 61 anmelde_und_handelsstatistische_menge: Optional[float] 62 beantragte_beguenstigung: Optional[str] 63 betriebliche_identifikationsnummer: Optional[str] 64 container_nummer: Optional[str] 65 packstueckzeichen_und_nummer: Optional[str] 66 packstueckanzahl: Optional[int] 67 packstueckart: Optional[str] 68 rohmasse:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/591', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 67, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 464.921, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\nOptional[float] 69 rohmasse_maßeinheit: Optional[str] 70 ursprungsland: Optional[str] 71 warenbezeichnung: Optional[str] 72 warennummer: Optional[str] 73 sendungsnummer: None 74 referenz_zu_dokument: str 75 76 77 class ZollSchema(BaseModel): 78 document_data: Zollkopfdaten 79 goods_positions: List[Zolleinzelpositionen] 80 sendung: str 81 token_count_doc: int 82 prompt_version: str 83 84 85 # Dateien einlesen 86 json_ohne_schema = dataiku.Folder() 87 prompts = dataiku.Dataset() 88 prompts_df = prompts.get_dataframe() 89 schema = dataiku.Folder() 90 91 # Projekt Variablen für Azure OpenAI 92 project = dataiku.Project() 93 variables ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/591', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 67, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 464.921, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}, {'self_ref': '#/texts/591', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 67, 'bbox': {'l': 85.226, 't': 753.7460146484375, 'r': 464.921, 'b': 171.1010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1465]}]}, {'self_ref': '#/texts/594', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 68, 'bbox': {'l': 79.687, 't': 752.2910146484376, 'r': 490.826, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1322]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content=\"Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\nproject.get_variables() 94 AZURE_OPENAI_ENDPOINT = variables['standard']['AZURE_OPENAI_ENDPOINT'] 95 AZURE_OPENAI_KEY = variables['standard']['AZURE_OPENAI_KEY'] 96 AZURE_OPENAI_API_VERSION =\\n```\\n```\"),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/594', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 68, 'bbox': {'l': 79.687, 't': 752.2910146484376, 'r': 490.826, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1322]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\nvariables[\\'standard\\'][\\'AZURE_OPENAI_API_VERSION\\'] 97 AZURE_OPENAI_MODEL = variables[\\'standard\\'][\\'AZURE_OPENAI_MODEL\\'] 98 99 # Azure OpenAI client 100 client = AzureOpenAI( 101 azure_endpoint=AZURE_OPENAI_ENDPOINT, 102 api_key=AZURE_OPENAI_KEY, 103 api_version=AZURE_OPENAI_API_VERSION 104 ) 105 106 # Prompts der verschiedenen Verfahren 107 parameters = prompts_df[[\\'Version\\', \\'System Prompt\\', \\'User Prompt\\']] 108 109 # Schemata zusammenführen 110 final_schema = {} 111 for index, path in enumerate(schema.list_paths_in_partition()): 112 filename = os.path.basename(path) 113 if path.endswith(\".json\"): 114 try: 115 with schema.get_download_stream(path) as stream: 116 json_objects ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/594', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 68, 'bbox': {'l': 79.687, 't': 752.2910146484376, 'r': 490.826, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1322]}]}, {'self_ref': '#/texts/594', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 68, 'bbox': {'l': 79.687, 't': 752.2910146484376, 'r': 490.826, 'b': 171.58901464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1322]}]}, {'self_ref': '#/texts/597', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/598'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 69, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 496.803, 'b': 278.6970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1102]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\njson.load(stream) 117 if index == 0: 118 final_schema[\\'document_data\\'] = json_objects 119 elif index == 1: 120 final_schema[\\'goods_positions\\'] = json_objects 121 else: 122 break 123 except Exception as e: 124 print(f\"Error processing {path}: {e}\") 125 126 127 def transform_customs_data(json_raw, system_prompt, user_prompt, tokens): 128 response = client.beta.chat.completions.parse( 129 model=AZURE_OPENAI_MODEL, 130 messages=[ 131 { 132 \"role\": \"system\", 133 \"content\": system_prompt 134 }, 135 { 136 \"role\": \"user\", 137 \"content\": [ 138 { 139 \"type\": \"text\", 140 \"text\": user_prompt.format(json_raw=json_raw, schema_json=final_schema)\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/597', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/598'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 69, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 496.803, 'b': 278.6970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1102]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\n141 } 142 ] 143 } 144 ], 145 response_format=ZollSchema, 146 temperature=0.0, 147 ) 148 return response.choices[0].message.parsed 149 150 output_folder = dataiku.Folder() 151 152 for version, system_prompt, user_prompt in parameters.itertuples(index=False, name=None): 153 for path in json_ohne_schema.list_paths_in_partition(): 154 # Dateiname definieren 155 filename = os.path.basename(path) 156 if path.endswith(\".json\"): 157 try: 158 with json_ohne_schema.get_download_stream(path) as stream: 159 json_objects = json.load(stream) 160 161 tokens = [obj.get(\\'tokens\\', 0) for obj in json_objects] 162 total_token_count = sum(tokens) 163 164 # Transformieren der Json Datei in'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/597', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/598'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 69, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 496.803, 'b': 278.6970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1102]}]}, {'self_ref': '#/texts/597', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/598'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 69, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 496.803, 'b': 278.6970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1102]}]}, {'self_ref': '#/texts/597', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/598'}], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 69, 'bbox': {'l': 79.687, 't': 753.7460146484375, 'r': 496.803, 'b': 278.6970146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1102]}]}, {'self_ref': '#/texts/598', 'parent': {'$ref': '#/texts/597'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 69, 'bbox': {'l': 129.482, 't': 268.0350146484375, 'r': 465.799, 'b': 258.40201464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 63]}]}], 'headings': ['Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Listing A.2 beschreibt die Implementierung der Schema-Migration über das LLM.\\nvordefiniertes Schema 165 transformed_json = transform_customs_data(json_objects, system_prompt, user_prompt, total_token_count) 166 json_string = transformed_json.model_dump_json(indent=1) 167 transformed_filename = f\"transformed_{filename}\" 168 with output_folder.get_writer(transformed_filename) as writer: 169 writer.write(json_string.encode(\"utf-8\")) 170 except Exception as e: 171 print(f\"Error processing {path}: {e}\")\\n```\\nListing A.2: LLM um Daten in vordefiniertes Schema zu migrieren\\n'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/602', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 89.291, 't': 719.9650146484375, 'r': 507.798, 'b': 669.4890146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 290]}]}], 'headings': ['A.2. Prompt Design für Datenextraktion'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.2. Prompt Design für Datenextraktion\\nErgänzend zu dem definierten Prompt aus ?? werden im Folgenden die übrigen Prompting-Verfahren vorgestellt, um die Leistungsfähigkeit der Informationsextraktion weiter zu erhöhen. Dabei werden One-Shot Prompting und Few-Shot Prompting jeweils mit instruktionsbasiertem Prompting kombiniert.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/605', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.182, 't': 603.1530146484375, 'r': 481.982, 'b': 579.9710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 127]}]}, {'self_ref': '#/texts/606', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 566.6630146484375, 'r': 250.975, 'b': 557.0300146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 23]}]}, {'self_ref': '#/texts/607', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 553.1140146484375, 'r': 334.124, 'b': 543.4810146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/608', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 539.5650146484376, 'r': 242.488, 'b': 529.9320146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/609', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 526.0150146484375, 'r': 287.76, 'b': 516.3820146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 30]}]}, {'self_ref': '#/texts/610', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 512.4660146484375, 'r': 287.837, 'b': 502.83301464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 28]}]}, {'self_ref': '#/texts/611', 'parent': {'$ref': '#/groups/8'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 138.753, 't': 498.9170146484375, 'r': 295.713, 'b': 489.2840146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 29]}]}, {'self_ref': '#/texts/612', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.182, 't': 485.3680146484375, 'r': 483.799, 'b': 380.8900146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 538]}]}, {'self_ref': '#/texts/613', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 376.9740146484375, 'r': 247.844, 'b': 367.3410146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents:\\n- Waybill (Frachtbrief)\\n- T1 Transit Document (Zolldokument)\\n- Invoice (Rechnung)\\n- Delivery Note (Lieferschein)\\n- Movement Certificate (ATR)\\n- Movement Certificate (EUR1)\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. Your task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Use the one given example and generalize it to solve your task, also follow the given instructions step by step to solve your task. Always provide the key \"referenz\\n```\\nzu dokument\" : url .\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/615', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 331.09301464843753, 'r': 270.862, 'b': 321.46001464843744, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/616', 'parent': {'$ref': '#/groups/9'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 140.259, 't': 317.5430146484375, 'r': 368.161, 'b': 307.9100146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/617', 'parent': {'$ref': '#/groups/9'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 303.99401464843754, 'r': 321.328, 'b': 294.3610146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/618', 'parent': {'$ref': '#/groups/9'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 290.44501464843756, 'r': 348.437, 'b': 280.8120146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 43]}]}, {'self_ref': '#/texts/619', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 253.95501464843755, 'r': 244.615, 'b': 244.32201464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/620', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.564, 't': 240.40601464843758, 'r': 188.248, 'b': 230.77301464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}, {'self_ref': '#/texts/621', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.204, 't': 226.85701464843748, 'r': 483.497, 'b': 203.6740146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/622', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 70, 'bbox': {'l': 140.259, 't': 190.36701464843748, 'r': 173.608, 'b': 180.73401464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/625', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 71, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 566.019, 'b': 298.19001464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 852]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions:\\n1. Extract all relevant fields of the document.\\n2. Keep values in original language.\\n3. The reference of the document is: {url}.\\nHere is the example:\\nExample:\\nText: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\"\\nJSON:\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/625', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 71, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 566.019, 'b': 298.19001464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 852]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n{ \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, ... \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\": \"https://firma.sharepoint.com/...pdf\" }, \"goods_positions\": [ { \"artikelnummer\":'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/625', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 71, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 566.019, 'b': 298.19001464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 852]}]}, {'self_ref': '#/texts/625', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 71, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 566.019, 'b': 298.19001464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 852]}]}, {'self_ref': '#/texts/626', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 71, 'bbox': {'l': 140.564, 't': 284.3470146484375, 'r': 370.877, 'b': 274.71401464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 46]}]}, {'self_ref': '#/texts/627', 'parent': {'$ref': '#/groups/10'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 71, 'bbox': {'l': 104.499, 't': 261.6020146484375, 'r': 507.796, 'b': 238.11501464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 78]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, ... \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" }, \"... more article if applicable ...\" ] }\\n```\\nExtract all relevant fields from the document.\\n- Kombination Few-Shot- mit instuktionsbasiertem Prompting für Datenextraktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/629', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 71, 'bbox': {'l': 140.182, 't': 174.87701464843758, 'r': 481.982, 'b': 165.24401464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 67]}]}, {'self_ref': '#/texts/632', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 754.4110146484375, 'r': 449.193, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 59]}]}, {'self_ref': '#/texts/633', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 731.4700146484375, 'r': 250.975, 'b': 721.8370146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 23]}]}, {'self_ref': '#/texts/634', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 717.9210146484376, 'r': 334.124, 'b': 708.2880146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/635', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 704.3720146484375, 'r': 242.488, 'b': 694.7390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/636', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 690.8230146484375, 'r': 287.76, 'b': 681.1900146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 30]}]}, {'self_ref': '#/texts/637', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 677.2730146484375, 'r': 287.837, 'b': 667.6400146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 28]}]}, {'self_ref': '#/texts/638', 'parent': {'$ref': '#/groups/11'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 138.753, 't': 663.7240146484376, 'r': 295.713, 'b': 654.0910146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 29]}]}, {'self_ref': '#/texts/639', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.182, 't': 650.1750146484375, 'r': 483.799, 'b': 545.6980146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 538]}]}, {'self_ref': '#/texts/640', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 541.7810146484375, 'r': 247.844, 'b': 532.1480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and\\ntransport documents. There are six main types of documents:\\n- Waybill (Frachtbrief)\\n- T1 Transit Document (Zolldokument)\\n- Invoice (Rechnung)\\n- Delivery Note (Lieferschein)\\n- Movement Certificate (ATR)\\n- Movement Certificate (EUR1)\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. Your task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Use the one given example and generalize it to solve your task, also follow the given instructions step by step to solve your task. Always provide the key \"referenz\\n```\\nzu dokument\" : url .\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/642', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 495.9000146484375, 'r': 270.862, 'b': 486.2670146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/643', 'parent': {'$ref': '#/groups/12'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 140.259, 't': 482.3510146484375, 'r': 368.161, 'b': 472.71801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/644', 'parent': {'$ref': '#/groups/12'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 468.8010146484375, 'r': 321.328, 'b': 459.1680146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/645', 'parent': {'$ref': '#/groups/12'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 455.2520146484375, 'r': 348.437, 'b': 445.61901464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 43]}]}, {'self_ref': '#/texts/646', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 418.7620146484375, 'r': 244.615, 'b': 409.12901464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/647', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 405.21301464843754, 'r': 188.248, 'b': 395.5800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}, {'self_ref': '#/texts/648', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 72, 'bbox': {'l': 140.204, 't': 391.6640146484375, 'r': 483.497, 'b': 368.48201464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions:\\n1. Extract all relevant fields of the document.\\n2. Keep values in original language.\\n3. The reference of the document is: {url}.\\nHere is the example:\\nExample:\\nText: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\"'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/650', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 72, 'bbox': {'l': 140.564, 't': 330.6400146484375, 'r': 448.201, 'b': 174.09401464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 381]}]}, {'self_ref': '#/texts/653', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 73, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 483.799, 'b': 173.01701464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1158]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n```\\n{ \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\",\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/653', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 73, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 483.799, 'b': 173.01701464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1158]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"referenz_zu_dokument\": \"https://firma...pdf\" }, \"goods_positions\": [ { \"artikelnummer\": \"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" } ] } Example 2: Text: Shipment number: SN-20240701-002 Waybill information: Package count: 8 Gross weight: 4550.0 kg Shipping date: 2024-07-01'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/653', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 73, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 483.799, 'b': 173.01701464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1158]}]}, {'self_ref': '#/texts/653', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 73, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 483.799, 'b': 173.01701464843745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1158]}]}, {'self_ref': '#/texts/656', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 74, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 520.201, 'b': 352.38601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 803]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n14:00 Customs document: MRN: 20DE9876543210ZYXW2 Seal (field 19 10): SGL2025 ... omitted fields ... EUR.1 certificate: Field 4: Deutschland Field 5: Italien Field 11 stamp: (not specified) Field 12 stamp: (not specified) Document reference: https://company....pdf Goods positions: 1. Article number: B-2047 Price: 320.40 USD Quantity: 5 Box Net mass: 120.5 kg Country of origin: USA Goods description: Electrical Components Commodity code: 85423910 File name: Position 2.pdf Shipment number: SN-20240701-002 Reference document: https://company...pdf ... more article if applicable ... Example 2 - JSON Output: {\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/656', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 74, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 520.201, 'b': 352.38601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 803]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"document_data\": { \"sendungnummer\": \"SN-20240701-002\", \"frachtbrief_packstueckanzahl\": 8, \"frachtbrief_bruttogewicht\": 4550.0, \"frachtbrief_versendungsdatum\": \"2024-07-01T14:00:00\", \"zolldokument_MRN\": \"20DE9876543210ZYXW2\", \"zolldokument_verschluss_feld_19_10\": \"SGL2025\", \"eur1_feld_4\": \"Deutschland\", \"eur1_feld_5\": \"Italien\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": None, \"referenz_zu_dokument\": \"https://company...pdf\" }, \"goods_positions\": [ {'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/656', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 74, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 520.201, 'b': 352.38601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 803]}]}, {'self_ref': '#/texts/656', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 74, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 520.201, 'b': 352.38601464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 803]}]}, {'self_ref': '#/texts/657', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 74, 'bbox': {'l': 140.564, 't': 338.5440146484375, 'r': 370.877, 'b': 328.91101464843746, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 46]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"artikelnummer\": \"B-2047\", \"preis\": 320.40, \"währung\": \"USD\", \"menge\": 5, \"menge_maßeinheit\": \"Box\", \"eigenmasse\": 120.5, \"ursprungsland\": \"USA\", \"warenbezeichnung\": \"Electrical Components\", \"warennummer\": \"85423910\", \"dateiname\": \"Position_2.pdf\", \"sendungsnummer\": \"SN-20240701-002\", \"referenz_zu_dokument\": \"https://company...pdf\" } ] }\\n```\\nExtract all relevant fields from the document.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/660', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 74, 'bbox': {'l': 140.03, 't': 242.62301464843745, 'r': 483.793, 'b': 178.79301464843752, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 297]}]}, {'self_ref': '#/texts/663', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 75, 'bbox': {'l': 140.139, 't': 754.4110146484375, 'r': 484.111, 'b': 677.0320146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 405]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents: Waybill (Frachtbrief) - T1 Transit Document (Zolldokument) - Invoice (Rechnung) - Delivery Note (Lieferschein) - Movement Certificate (ATR) - Movement Certificate (EUR1)\\nYour task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Use the one given example and generalize it to solve your task. Always provide the key \"referenz zu dokument\" : { url }.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/665', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 75, 'bbox': {'l': 140.204, 't': 640.7830146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}, {'self_ref': '#/texts/665', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 75, 'bbox': {'l': 140.204, 't': 640.7830146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n```\\nHere is the example: Example: Text: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\" JSON: { \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, ... \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\",'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/665', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 75, 'bbox': {'l': 140.204, 't': 640.7830146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}, {'self_ref': '#/texts/665', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 75, 'bbox': {'l': 140.204, 't': 640.7830146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 880]}]}, {'self_ref': '#/texts/668', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 474.383, 'b': 691.1160146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 89]}]}, {'self_ref': '#/texts/669', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 677.2730146484375, 'r': 370.877, 'b': 667.6400146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 46]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"referenz_zu_dokument\": \"https://firma.sharepoint.com/...pdf\" }, \"goods_positions\": [ { \"artikelnummer\": \"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, ... \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\",\\n```\\n```\\n\"referenz_zu_dokument\": \"https://firma...pdf\" }, \"... more article if applicable ...\" ] }\\n```\\nExtract all relevant fields from the document.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/672', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.03, 't': 604.2930146484375, 'r': 483.793, 'b': 540.4640146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 297]}]}, {'self_ref': '#/texts/673', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.139, 't': 527.1560146484375, 'r': 484.111, 'b': 449.7770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 404]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents: Waybill (Frachtbrief) - T1 Transit Document (Zolldokument) - Invoice (Rechnung) - Delivery Note (Lieferschein) - Movement Certificate (ATR) - Movement Certificate (EUR1)\\nYour task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Use the given examples and generalize them to solve your task. Always provide the key \"referenz_zu_dokument\" : { url }.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/675', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 413.52801464843753, 'r': 416.215, 'b': 403.8950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 49]}]}, {'self_ref': '#/texts/676', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.03, 't': 390.5870146484375, 'r': 483.496, 'b': 367.4050146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 106]}]}, {'self_ref': '#/texts/677', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.259, 't': 354.0970146484375, 'r': 481.981, 'b': 330.91501464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 79]}]}, {'self_ref': '#/texts/678', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 317.6070146484376, 'r': 233.52, 'b': 307.97401464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/679', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 294.66701464843754, 'r': 482.294, 'b': 271.48401464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 125]}]}, {'self_ref': '#/texts/680', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 258.17701464843753, 'r': 344.401, 'b': 248.5440146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 41]}]}, {'self_ref': '#/texts/681', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 76, 'bbox': {'l': 140.564, 't': 235.2360146484375, 'r': 483.796, 'b': 184.95501464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 248]}]}, {'self_ref': '#/texts/684', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 77, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1069]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExample 1: Text: Shipment number: SN-20240628-001\\nWaybill information: Package count: (not specified) Gross weight: 7850.5 kg Shipping date: (not specified)\\nCustoms document: MRN: 19DE1234567890ABCDE1 Seal (field 19 10): (not specified)\\n... omitted fields ...\\nEUR.1 certificate: Field 4: (not specified) Field 5: France Field 11 stamp: (not specified) Field 12 stamp: StampEUR1CustomsB\\nDocument reference: \"https://firma...pdf\"\\nGoods positions: 1. Article number: A-1023 Price: 1590.75 EUR Quantity: 10 pieces Net mass: (not specified) Country of origin: Germany Goods description: Steel tube Commodity code: 73049051 File name: Position 1.pdf Shipment number: SN-20240628-001\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/684', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 77, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1069]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n... omitted ... Example 1 - JSON Output: { \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\": \"https://firma...pdf\" }, \"goods_positions\": [ { \"artikelnummer\":'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/684', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 77, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1069]}]}, {'self_ref': '#/texts/684', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 77, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1069]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" } ] } Example 2: Text: Shipment number: SN-20240701-002 Waybill information: Package count: 8 Gross weight: 4550.0 kg Shipping date: 2024-07-01 14:00 Customs document: MRN: 20DE9876543210ZYXW2 Seal (field 19 10): SGL2025 ... omitted fields ...\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/687', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 78, 'bbox': {'l': 140.204, 't': 754.4110146484375, 'r': 483.497, 'b': 731.2290146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 120]}]}, {'self_ref': '#/texts/688', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 717.9210146484376, 'r': 355.157, 'b': 708.2880146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 42]}]}, {'self_ref': '#/texts/689', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 694.9800146484375, 'r': 483.799, 'b': 631.1500146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 285]}]}, {'self_ref': '#/texts/690', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 617.8430146484375, 'r': 290.019, 'b': 608.2100146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 34]}]}, {'self_ref': '#/texts/691', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 590.7440146484375, 'r': 520.201, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 828]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nEUR.1 certificate: Field 4: Deutschland Field 5: Italien Field 11 stamp: (not specified) Field 12 stamp: (not specified)\\nDocument reference: https://company....pdf\\nGoods positions: 1. Article number: B-2047 Price: 320.40 USD Quantity: 5 Box Net mass: 120.5 kg Country of origin: USA Goods description: Electrical Components Commodity code: 85423910 File name: Position 2.pdf Shipment number: SN-20240701-002 Reference document: https://company...pdf\\n... more article if applicable ...\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/691', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 590.7440146484375, 'r': 520.201, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 828]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExample 2 - JSON Output: { \"document_data\": { \"sendungnummer\": \"SN-20240701-002\", \"frachtbrief_packstueckanzahl\": 8, \"frachtbrief_bruttogewicht\": 4550.0, \"frachtbrief_versendungsdatum\": \"2024-07-01T14:00:00\", \"zolldokument_MRN\": \"20DE9876543210ZYXW2\", \"zolldokument_verschluss_feld_19_10\": \"SGL2025\", \"eur1_feld_4\": \"Deutschland\", \"eur1_feld_5\": \"Italien\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": None, \"referenz_zu_dokument\": \"https://company...pdf\" }, \"goods_positions\": [ {'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/691', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 590.7440146484375, 'r': 520.201, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 828]}]}, {'self_ref': '#/texts/691', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 78, 'bbox': {'l': 140.564, 't': 590.7440146484375, 'r': 520.201, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 828]}]}, {'self_ref': '#/texts/694', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 79, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 370.877, 'b': 721.8370146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 48]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"artikelnummer\": \"B-2047\", \"preis\": 320.40, \"währung\": \"USD\", \"menge\": 5, \"menge_maßeinheit\": \"Box\", \"eigenmasse\": 120.5, \"ursprungsland\": \"USA\", \"warenbezeichnung\": \"Electrical Components\", \"warennummer\": \"85423910\", \"dateiname\": \"Position_2.pdf\", \"sendungsnummer\": \"SN-20240701-002\", \"referenz_zu_dokument\": \"https://company...pdf\" } ]\\n```\\n```\\n} Extract all relevant fields from the document.\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/697', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 79, 'bbox': {'l': 140.03, 't': 635.5490146484375, 'r': 484.117, 'b': 476.8750146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 788]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents: Waybill (Frachtbrief) - T1 Transit Document (Zolldokument) - Invoice (Rechnung) - Delivery Note (Lieferschein) - Movement Certificate (ATR) - Movement Certificate (EUR1) You are an OCR-like data extraction tool specialized in customs and transport documents. Your task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making the up data if not available write None as value. Follow the given instructions step by step to solve your task. Always provide the key \"referenz zu dokument: url'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/699', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 79, 'bbox': {'l': 140.564, 't': 440.6270146484375, 'r': 483.796, 'b': 403.8950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 153]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions: 1. Extract all relevant fields of the document. 2. Keep values in original language. 3. The reference of the document is: url.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/701', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 79, 'bbox': {'l': 88.866, 't': 333.9050146484375, 'r': 507.792, 'b': 242.9770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 474]}]}], 'headings': ['A.3. Prompt Design für Schemamigration'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='A.3. Prompt Design für Schemamigration\\nDie verschiedenen Promptingstrategien wurden ebenso für die Schemamigration eingesetzt und evaluiert. Dabei dienen die in ?? beschriebenen Prompttechniken ebenso als Grundlage, um strukturierte JSON-Outputs gemäß einem vorab definierten Zieldatenschema zu generieren. Dies erlaubt eine automatische Überführung semistrukturierter Dokumenteninhalte in strukturierte Datenrepräsentationen, welche für die Weiterverarbeitung in nachgelagerten IT-Systemen genutzt werden können.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/703', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 79, 'bbox': {'l': 116.564, 't': 176.8370146484375, 'r': 206.575, 'b': 166.89901464843751, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 14]}]}, {'self_ref': '#/texts/706', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 80, 'bbox': {'l': 140.182, 't': 754.4110146484375, 'r': 484.114, 'b': 649.9340146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 489]}]}], 'headings': ['· One-Shot Prompting'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='· One-Shot Prompting\\nSystem Prompt:\\nYou are a data transformation tool that takes in JSON data and a reference JSON schema, and outputs JSON data according to the schema. Not all of the data in the input JSON will fit the schema, so you may need to omit some data or add null values to the output JSON. Translate all data into German if not already in German. Ensure values are formatted as specified in the schema (e.g. dates as YYYY-MM-DD). Here is the schema: {schema json}. Do the task by taking the example into account.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/708', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 80, 'bbox': {'l': 140.564, 't': 613.6850146484375, 'r': 244.615, 'b': 604.0520146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/709', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 80, 'bbox': {'l': 140.204, 't': 600.1360146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere is the example:\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/709', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 80, 'bbox': {'l': 140.204, 't': 600.1360146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExample: Text: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\" JSON: { \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, ... \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\":'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/709', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 80, 'bbox': {'l': 140.204, 't': 600.1360146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}, {'self_ref': '#/texts/709', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 80, 'bbox': {'l': 140.204, 't': 600.1360146484375, 'r': 566.019, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 791]}]}, {'self_ref': '#/texts/712', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 474.383, 'b': 664.0180146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 157]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"https://firma.sharepoint.com/...pdf\" }, \"goods_positions\": [ { \"artikelnummer\": \"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, ... \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\",\\n```\\n```\\n\"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" }, \"... more article if applicable ...\" ] }\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/713', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.204, 't': 650.1750146484375, 'r': 482.276, 'b': 613.4440146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 187]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nTransform the following raw JSON data according to the provided schema. Ensure all data is in English and formatted as specified by values in the schema. Here is the raw JSON: {json raw}.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/716', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.182, 't': 527.1560146484375, 'r': 484.114, 'b': 422.6780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 490]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are a data transformation tool that takes in JSON data and a reference JSON schema, and outputs JSON data according to the schema. Not all of the data in the input JSON will fit the schema, so you may need to omit some data or add null values to the output JSON. Translate all data into German if not already in German. Ensure values are formatted as specified in the schema (e.g. dates as YYYY-MM-DD). Here is the schema: {schema json}. Do the task by taking the examples into account.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/718', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 386.4300146484375, 'r': 416.215, 'b': 376.79701464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 49]}]}, {'self_ref': '#/texts/719', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.03, 't': 363.4890146484375, 'r': 483.496, 'b': 340.30701464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 106]}]}, {'self_ref': '#/texts/720', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.259, 't': 326.99901464843754, 'r': 481.981, 'b': 303.8170146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 79]}]}, {'self_ref': '#/texts/721', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 290.5090146484375, 'r': 233.52, 'b': 280.8760146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/722', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 267.5680146484375, 'r': 482.294, 'b': 244.38601464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 125]}]}, {'self_ref': '#/texts/723', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 231.0780146484375, 'r': 344.401, 'b': 221.44501464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 41]}]}, {'self_ref': '#/texts/724', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 81, 'bbox': {'l': 140.564, 't': 208.13701464843757, 'r': 483.796, 'b': 171.40601464843758, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 200]}]}, {'self_ref': '#/texts/727', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 82, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1094]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExample 1: Text: Shipment number: SN-20240628-001\\nWaybill information: Package count: (not specified) Gross weight: 7850.5 kg Shipping date: (not specified)\\nCustoms document: MRN: 19DE1234567890ABCDE1 Seal (field 19 10): (not specified)\\n```\\n... omitted fields ...\\n```\\nEUR.1 certificate: Field 4: (not specified) Field 5: France Field 11 stamp: (not specified) Field 12 stamp: StampEUR1CustomsB\\nDocument reference: \"https://firma...pdf\"\\nGoods positions: 1. Article number: A-1023 Price: 1590.75 EUR Quantity: 10 pieces Net mass: (not specified) Country of origin: Germany Goods description: Steel tube Commodity code: 73049051 File name:\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/727', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 82, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1094]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nPosition 1.pdf Shipment number: SN-20240628-001 ... omitted ... Example 1 - JSON Output: { \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\": \"https://firma...pdf\" },'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/727', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 82, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1094]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"goods_positions\": [ { \"artikelnummer\": \"A-1023\", \"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" } ] } Example 2: Text: Shipment number: SN-20240701-002 Waybill information: Package count: 8 Gross weight: 4550.0 kg Shipping date: 2024-07-01 14:00 Customs document: MRN: 20DE9876543210ZYXW2 Seal (field 19 10):'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/727', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 82, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1094]}]}, {'self_ref': '#/texts/727', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 82, 'bbox': {'l': 140.03, 't': 754.4110146484375, 'r': 483.792, 'b': 169.40101464843747, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1094]}]}, {'self_ref': '#/texts/730', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 754.4110146484375, 'r': 233.52, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/731', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 83, 'bbox': {'l': 140.204, 't': 731.4700146484375, 'r': 483.497, 'b': 708.2880146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 120]}]}, {'self_ref': '#/texts/732', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 694.9800146484375, 'r': 355.157, 'b': 685.3470146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 42]}]}, {'self_ref': '#/texts/733', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 672.0390146484375, 'r': 483.799, 'b': 608.2100146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 285]}]}, {'self_ref': '#/texts/734', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 594.9020146484376, 'r': 290.019, 'b': 585.2690146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 34]}]}, {'self_ref': '#/texts/735', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 567.8030146484375, 'r': 520.201, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 824]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nSGL2025\\n```\\n... omitted fields ...\\nEUR.1 certificate: Field 4: Deutschland Field 5: Italien Field 11 stamp: (not specified) Field 12 stamp: (not specified)\\nDocument reference: https://company....pdf\\nGoods positions: 1. Article number: B-2047 Price: 320.40 USD Quantity: 5 Box Net mass: 120.5 kg Country of origin: USA Goods description: Electrical Components Commodity code: 85423910 File name: Position 2.pdf Shipment number: SN-20240701-002 Reference document: https://company...pdf\\n... more article if applicable ...\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/735', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 567.8030146484375, 'r': 520.201, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 824]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nExample 2 - JSON Output: { \"document_data\": { \"sendungnummer\": \"SN-20240701-002\", \"frachtbrief_packstueckanzahl\": 8, \"frachtbrief_bruttogewicht\": 4550.0, \"frachtbrief_versendungsdatum\": \"2024-07-01T14:00:00\", \"zolldokument_MRN\": \"20DE9876543210ZYXW2\", \"zolldokument_verschluss_feld_19_10\": \"SGL2025\", \"eur1_feld_4\": \"Deutschland\", \"eur1_feld_5\": \"Italien\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": None, \"referenz_zu_dokument\": \"https://company...pdf\" }, \"goods_positions\": [ {'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/735', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 567.8030146484375, 'r': 520.201, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 824]}]}, {'self_ref': '#/texts/735', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 83, 'bbox': {'l': 140.564, 't': 567.8030146484375, 'r': 520.201, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 824]}]}, {'self_ref': '#/texts/738', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 173.291, 'b': 718.2150146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/739', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 84, 'bbox': {'l': 140.204, 't': 704.3720146484375, 'r': 482.284, 'b': 667.6400146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 186]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"artikelnummer\": \"B-2047\", \"preis\": 320.40, \"währung\": \"USD\", \"menge\": 5, \"menge_maßeinheit\": \"Box\", \"eigenmasse\": 120.5, \"ursprungsland\": \"USA\", \"warenbezeichnung\": \"Electrical Components\", \"warennummer\": \"85423910\", \"dateiname\": \"Position_2.pdf\", \"sendungsnummer\": \"SN-20240701-002\", \"referenz_zu_dokument\": \"https://company...pdf\"\\n```\\n```\\n} ] }\\n```\\nTransform the following raw JSON data according to the provided schema. Ensure all data is in German and formatted as specified by values in the schema. Here is the raw JSON: {json raw}.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/742', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 84, 'bbox': {'l': 140.182, 't': 581.3530146484375, 'r': 484.114, 'b': 476.8750146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 490]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are a data transformation tool that takes in JSON data and a reference JSON schema, and outputs JSON data according to the schema. Not all of the data in the input JSON will fit the schema, so you may need to omit some data or add null values to the output JSON. Translate all data into German if not already in German. Ensure values are formatted as specified in the schema (e.g. dates as YYYY-MM-DD). Here is the schema: {schema json}. Do the task by following the given instructions.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/744', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 440.6270146484375, 'r': 270.862, 'b': 430.99401464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/745', 'parent': {'$ref': '#/groups/13'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 84, 'bbox': {'l': 140.259, 't': 427.0770146484375, 'r': 481.982, 'b': 403.8950146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 74]}]}, {'self_ref': '#/texts/746', 'parent': {'$ref': '#/groups/13'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 399.9790146484375, 'r': 482.895, 'b': 376.79701464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 105]}]}, {'self_ref': '#/texts/747', 'parent': {'$ref': '#/groups/13'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 372.8810146484375, 'r': 481.984, 'b': 349.6980146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 83]}]}, {'self_ref': '#/texts/748', 'parent': {'$ref': '#/groups/13'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 84, 'bbox': {'l': 140.259, 't': 345.7820146484375, 'r': 481.984, 'b': 322.60001464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 73]}]}, {'self_ref': '#/texts/749', 'parent': {'$ref': '#/groups/13'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 318.6840146484376, 'r': 323.204, 'b': 309.05101464843756, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions:\\n1. Transform the following raw JSON data according to the provided schema.\\n2. Assign the values to the corresponding new key if applicable; otherwise assign null values to the key.\\n3. Ensure all data is in German and formatted as specified by values in the schema.\\n4. Rather include empty fields as null, than interpolate or make them up.\\n5. Here is the raw JSON: {json raw}.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/752', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 84, 'bbox': {'l': 140.564, 't': 222.76301464843755, 'r': 483.496, 'b': 172.48201464843748, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 260]}]}, {'self_ref': '#/texts/755', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 85, 'bbox': {'l': 140.259, 't': 754.4110146484375, 'r': 484.114, 'b': 690.5810146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 268]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are a data transformation tool that takes in JSON data and a reference JSON schema, and outputs JSON data according to the schema. Not all of the data in the input JSON will fit the schema, so you may need to omit some data or add null values to the output\\nJSON. Translate all data into German if not already in German. Ensure values are formatted as specified in the schema (e.g. dates as YYYY-MM-DD). Here is the schema: {schema json}. Do the task by following the given instructions and by taking the example into account.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/757', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 85, 'bbox': {'l': 140.564, 't': 654.3330146484375, 'r': 270.862, 'b': 644.7000146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/758', 'parent': {'$ref': '#/groups/14'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 85, 'bbox': {'l': 140.259, 't': 640.7830146484375, 'r': 481.982, 'b': 617.6010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 74]}]}, {'self_ref': '#/texts/759', 'parent': {'$ref': '#/groups/14'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 85, 'bbox': {'l': 140.139, 't': 613.6850146484375, 'r': 483.796, 'b': 590.5030146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 105]}]}, {'self_ref': '#/texts/760', 'parent': {'$ref': '#/groups/14'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 85, 'bbox': {'l': 140.564, 't': 586.5870146484375, 'r': 481.984, 'b': 563.4040146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 83]}]}, {'self_ref': '#/texts/761', 'parent': {'$ref': '#/groups/14'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 85, 'bbox': {'l': 140.259, 't': 559.4880146484376, 'r': 481.984, 'b': 536.3060146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 73]}]}, {'self_ref': '#/texts/762', 'parent': {'$ref': '#/groups/14'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 85, 'bbox': {'l': 140.564, 't': 532.3900146484375, 'r': 323.204, 'b': 522.7570146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/763', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 85, 'bbox': {'l': 140.564, 't': 505.2910146484375, 'r': 244.615, 'b': 495.65801464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/764', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 85, 'bbox': {'l': 140.204, 't': 468.8010146484375, 'r': 566.019, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 588]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions:\\n1. Transform the following raw JSON data according to the provided schema.\\n2. Assign the values to the corresponding new key if applicable; otherwise assign null values to the key.\\n3. Ensure all data is in German and formatted as specified by values in the schema.\\n4. Rather include empty fields as null, than interpolate or make them up.\\n5. Here is the raw JSON: {json raw}.\\nHere is the example:\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/764', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 85, 'bbox': {'l': 140.204, 't': 468.8010146484375, 'r': 566.019, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 588]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nText: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\" JSON: { \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, ... \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\":'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/764', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 85, 'bbox': {'l': 140.204, 't': 468.8010146484375, 'r': 566.019, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 588]}]}, {'self_ref': '#/texts/764', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 85, 'bbox': {'l': 140.204, 't': 468.8010146484375, 'r': 566.019, 'b': 169.93601464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 588]}]}, {'self_ref': '#/texts/767', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 86, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 474.383, 'b': 542.0750146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 351]}]}, {'self_ref': '#/texts/768', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 86, 'bbox': {'l': 140.564, 't': 528.2320146484375, 'r': 299.095, 'b': 518.5990146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 32]}]}, {'self_ref': '#/texts/769', 'parent': {'$ref': '#/groups/15'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 104.499, 't': 505.48701464843754, 'r': 501.895, 'b': 495.5490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 66]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\n\"https://firma.sharepoint.com/...pdf\" }, \"goods_positions\": [ { \"artikelnummer\": \"A-1023\",\\n```\\n```\\n\"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, ... \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\", \"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" }, \"... more article if applicable ...\" ] }\\n```\\nNow extract the relevant fields.\\n- Few-Shot- mit instuktionsbasiertem Prompting für Datenextraktion'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/771', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 86, 'bbox': {'l': 140.182, 't': 432.3110146484375, 'r': 481.982, 'b': 409.12901464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 127]}]}, {'self_ref': '#/texts/772', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 395.82101464843754, 'r': 250.975, 'b': 386.1880146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 23]}]}, {'self_ref': '#/texts/773', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 382.2720146484375, 'r': 334.124, 'b': 372.6390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 36]}]}, {'self_ref': '#/texts/774', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 368.7230146484375, 'r': 242.488, 'b': 359.0900146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/775', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 355.1740146484375, 'r': 287.76, 'b': 345.5410146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 30]}]}, {'self_ref': '#/texts/776', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 341.6250146484375, 'r': 287.837, 'b': 331.99201464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 28]}]}, {'self_ref': '#/texts/777', 'parent': {'$ref': '#/groups/16'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 86, 'bbox': {'l': 138.753, 't': 328.07501464843745, 'r': 295.713, 'b': 318.4420146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 29]}]}, {'self_ref': '#/texts/778', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 86, 'bbox': {'l': 140.182, 't': 314.52601464843747, 'r': 483.799, 'b': 210.0490146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 538]}]}, {'self_ref': '#/texts/779', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 86, 'bbox': {'l': 140.564, 't': 206.13301464843755, 'r': 247.844, 'b': 196.5000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}], 'headings': ['System Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='System Prompt:\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. There are six main types of documents:\\n- Waybill (Frachtbrief)\\n- T1 Transit Document (Zolldokument)\\n- Invoice (Rechnung)\\n- Delivery Note (Lieferschein)\\n- Movement Certificate (ATR)\\n- Movement Certificate (EUR1)\\nYou are an OCR-like data extraction tool specialized in customs and transport documents. Your task is to identify the type and extract structured data in JSON format from invoices, delivery notes, customs documents, and freight forms. Follow the structure and precision expected in official customs workflows. Instead of making up data if not available write None as value. Use the one given example and generalize it to solve your task, also follow the given instructions step by step to solve your task. Always provide the key \"referenz\\n```\\nzu dokument\" : url .\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/783', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 754.4110146484375, 'r': 270.862, 'b': 744.7780146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/784', 'parent': {'$ref': '#/groups/17'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 87, 'bbox': {'l': 140.259, 't': 740.8620146484375, 'r': 481.982, 'b': 717.6800146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 74]}]}, {'self_ref': '#/texts/785', 'parent': {'$ref': '#/groups/17'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 87, 'bbox': {'l': 140.139, 't': 713.7630146484375, 'r': 483.796, 'b': 690.5810146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 105]}]}, {'self_ref': '#/texts/786', 'parent': {'$ref': '#/groups/17'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 686.6650146484375, 'r': 481.984, 'b': 663.4830146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 83]}]}, {'self_ref': '#/texts/787', 'parent': {'$ref': '#/groups/17'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 87, 'bbox': {'l': 140.259, 't': 659.5670146484375, 'r': 481.984, 'b': 636.3840146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 73]}]}, {'self_ref': '#/texts/788', 'parent': {'$ref': '#/groups/17'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 632.4680146484375, 'r': 318.361, 'b': 622.8350146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 34]}]}], 'headings': ['User Prompt:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='User Prompt:\\nHere are the instructions:\\n1. Transform the following raw JSON data according to the provided schema.\\n2. Assign the values to the corresponding new key if applicable; otherwise assign null values to the key.\\n3. Ensure all data is in German and formatted as specified by values in the schema.\\n4. Rather include empty fields as null, than interpolate or make them up.\\n5. Here is the raw JSON: json_raw.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/790', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 87, 'bbox': {'l': 140.204, 't': 545.9390146484375, 'r': 483.497, 'b': 522.7570146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}], 'headings': ['Here is the example:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Here is the example:\\nText: Ïnvoice No: INV-0098, Date: 2024-05-12, Sender: ABC GmbH, Country: Germany\"'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/792', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 484.91501464843753, 'r': 461.292, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 643]}]}, {'self_ref': '#/texts/792', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 484.91501464843753, 'r': 461.292, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 643]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n```\\n{ \"document_data\": { \"sendungnummer\": \"SN-20240628-001\", \"frachtbrief_packstueckanzahl\": None, \"frachtbrief_bruttogewicht\": 7850.5, \"frachtbrief_versendungsdatum\": None, \"zolldokument_MRN\": \"19DE1234567890ABCDE1\", \"zolldokument_verschluss_feld_19_10\": None, \"eur1_feld_4\": None, \"eur1_feld_5\": \"Frankreich\", \"eur1_feld_11_stempel\": None, \"eur1_feld_12_stempel\": \"StempelEUR1ZollB\", \"referenz_zu_dokument\": \"https://firma...pdf\" }, \"goods_positions\": [ { \"artikelnummer\": \"A-1023\",'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/792', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 484.91501464843753, 'r': 461.292, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 643]}]}, {'self_ref': '#/texts/792', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 87, 'bbox': {'l': 140.564, 't': 484.91501464843753, 'r': 461.292, 'b': 165.7790146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 643]}]}, {'self_ref': '#/texts/795', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 88, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 520.201, 'b': 173.01801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1334]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"preis\": 1590.75, \"währung\": \"EUR\", \"menge\": 10, \"menge_maßeinheit\": \"Stück\", \"eigenmasse\": None, \"ursprungsland\": \"Deutschland\", \"warenbezeichnung\": \"Stahlrohr\",\\n```\\n```'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/795', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 88, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 520.201, 'b': 173.01801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1334]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"warennummer\": \"73049051\", \"dateiname\": \"Position_1.pdf\", \"sendungsnummer\": \"SN-20240628-001\", \"referenz_zu_dokument\": \"https://firma...pdf\" } ] } Example 2: Text: Shipment number: SN-20240701-002 Waybill information: Package count: 8 Gross weight: 4550.0 kg Shipping date: 2024-07-01 14:00 Customs document: MRN: 20DE9876543210ZYXW2 Seal (field 19 10): SGL2025 ... omitted fields ... EUR.1 certificate: Field 4: Deutschland Field 5: Italien Field 11 stamp: (not specified) Field 12 stamp: (not specified) Document reference: https://company....pdf Goods positions: 1. Article number: B-2047 Price: 320.40 USD Quantity: 5 Box Net mass: 120.5 kg Country of origin: USA Goods description: Electrical Components Commodity code:'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/795', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 88, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 520.201, 'b': 173.01801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1334]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n85423910 File name: Position 2.pdf Shipment number: SN-20240701-002 Reference document: https://company...pdf ... more article if applicable ... Example 2 - JSON Output: { \"document_data\": { \"sendungnummer\": \"SN-20240701-002\", \"frachtbrief_packstueckanzahl\": 8, \"frachtbrief_bruttogewicht\": 4550.0, \"frachtbrief_versendungsdatum\": \"2024-07-01T14:00:00\", \"zolldokument_MRN\": \"20DE9876543210ZYXW2\", \"zolldokument_verschluss_feld_19_10\": \"SGL2025\", \"eur1_feld_4\": \"Deutschland\", \"eur1_feld_5\": \"Italien\", \"eur1_feld_11_stempel\": None,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/795', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 88, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 520.201, 'b': 173.01801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1334]}]}, {'self_ref': '#/texts/795', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 88, 'bbox': {'l': 140.03, 't': 752.8180146484375, 'r': 520.201, 'b': 173.01801464843754, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1334]}]}, {'self_ref': '#/texts/798', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 89, 'bbox': {'l': 140.564, 't': 752.8180146484375, 'r': 487.474, 'b': 514.9770146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 365]}]}, {'self_ref': '#/texts/799', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 89, 'bbox': {'l': 140.564, 't': 501.1340146484375, 'r': 299.095, 'b': 491.5010146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 32]}]}], 'headings': ['Example 1 - JSON Output:'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='Example 1 - JSON Output:\\n\"eur1_feld_12_stempel\": None, \"referenz_zu_dokument\": \"https://company...pdf\"\\n```\\n```\\n}, \"goods_positions\": [ { \"artikelnummer\": \"B-2047\", \"preis\": 320.40, \"währung\": \"USD\", \"menge\": 5, \"menge_maßeinheit\": \"Box\", \"eigenmasse\": 120.5, \"ursprungsland\": \"USA\", \"warenbezeichnung\": \"Electrical Components\", \"warennummer\": \"85423910\", \"dateiname\": \"Position_2.pdf\", \"sendungsnummer\": \"SN-20240701-002\", \"referenz_zu_dokument\": \"https://company...pdf\" } ] }\\n```\\nNow extract the relevant fields.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/801', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 90, 'bbox': {'l': 89.291, 't': 642.6360146484375, 'r': 383.269, 'b': 633.0030146484376, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 55]}]}, {'self_ref': '#/texts/803', 'parent': {'$ref': '#/tables/19'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 91, 'bbox': {'l': 163.767, 't': 195.1442761019498, 'r': 757.703, 'b': 171.96227610194978, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 134]}]}, {'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nErgänzend zu Kapitel 5 die Ergebnisse auf Klassenebene.\\n\\nTabelle B.1.: Klassenspezifische Extraktionsmetriken der Kopfdaten für 30 Sendungen mit der Methode Zero-Shot Prompting (erster Teil).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Klasse = rechnung_rechnungsnummer. Zero-Shot, TP = 11. Zero-Shot, FP = 5. Zero-Shot, FN = 12. Zero-Shot, Accuracy = 0,39. Zero-Shot, Precision = 0,69. Zero-Shot, Recall = 0,48. Zero-Shot, F1 = 0,56. Zero-Shot, Support = 23. Zero-Shot, Gpt-4o = 16. Zero-Shot, Klasse = lieferschein_lieferantennamen. Zero-Shot, TP = 4. Zero-Shot, FP = 8. Zero-Shot, FN = 5. Zero-Shot, Accuracy = 0,24. Zero-Shot, Precision = 0,33. Zero-Shot, Recall = 0,44. Zero-Shot, F1 = 0,38. Zero-Shot, Support = 9. Zero-Shot, Gpt-4o = 12. Zero-Shot, Klasse = lieferschein_versenderland. Zero-Shot, TP = 4. Zero-Shot, FP = 8. Zero-Shot,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nFN = 5. Zero-Shot, Accuracy = 0,24. Zero-Shot, Precision = 0,33. Zero-Shot, Recall = 0,44. Zero-Shot, F1 = 0,38. Zero-Shot, Support = 9. Zero-Shot, Gpt-4o = 12. Zero-Shot, Klasse = incoterm. Zero-Shot, TP = 4. Zero-Shot, FP = 8. Zero-Shot, FN = 9. Zero-Shot, Accuracy = 0,19. Zero-Shot, Precision = 0,33. Zero-Shot, Recall = 0,31. Zero-Shot, F1 = 0,32. Zero-Shot, Support = 13. Zero-Shot, Gpt-4o = 12. Zero-Shot, Klasse = frachtbrief_bruttogewicht. Zero-Shot, TP = 4. Zero-Shot, FP = 4. Zero-Shot, FN = 11. Zero-Shot, Accuracy = 0,21. Zero-Shot, Precision = 0,5. Zero-Shot, Recall = 0,27. Zero-Shot, F1 = 0,35.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Support = 15. Zero-Shot, Gpt-4o = 8. Zero-Shot, Klasse = lieferschein_lieferscheinnummern. Zero-Shot, TP = 6. Zero-Shot, FP = 23. Zero-Shot, FN = 23. Zero-Shot, Accuracy = 0,12. Zero-Shot, Precision = 0,21. Zero-Shot, Recall = 0,21. Zero-Shot, F1 = 0,21. Zero-Shot, Support = 29. Zero-Shot, Gpt-4o = 29. Zero-Shot, Klasse = rechnung_bestellnummern. Zero-Shot, TP = 4. Zero-Shot, FP = 25. Zero-Shot, FN = 25. Zero-Shot, Accuracy = 0,07. Zero-Shot, Precision = 0,14. Zero-Shot, Recall = 0,14. Zero-Shot, F1 = 0,14. Zero-Shot, Support = 29. Zero-Shot, Gpt-4o = 29. Zero-Shot, Klasse ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nfrachtbrief_packstueckanzahl. Zero-Shot, TP = 2. Zero-Shot, FP = 1. Zero-Shot, FN = 13. Zero-Shot, Accuracy = 0,13. Zero-Shot, Precision = 0,67. Zero-Shot, Recall = 0,13. Zero-Shot, F1 = 0,22. Zero-Shot, Support = 15. Zero-Shot, Gpt-4o = 3. Zero-Shot, Klasse = T1_MRN. Zero-Shot, TP = 3. Zero-Shot, FP = 1. Zero-Shot, FN = 21. Zero-Shot, Accuracy = 0,12. Zero-Shot, Precision = 0,75. Zero-Shot, Recall = 0,13. Zero-Shot, F1 = 0,21. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 4. Zero-Shot, Klasse = rechnung_einzelpositionen_gesamtanzahl. Zero-Shot, TP = 3. Zero-Shot, FP = 4. Zero-Shot, FN = 21.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Accuracy = 0,11. Zero-Shot, Precision = 0,43. Zero-Shot, Recall = 0,13. Zero-Shot, F1 = 0,19. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 7. Zero-Shot, Klasse = lieferschein_einzelpositionen_anzahl. Zero-Shot, TP = 1. Zero-Shot, FP = 5. Zero-Shot, FN = 8. Zero-Shot, Accuracy = 0,07. Zero-Shot, Precision = 0,17. Zero-Shot, Recall = 0,11. Zero-Shot, F1 = 0,13. Zero-Shot, Support = 9. Zero-Shot, Gpt-4o = 6. Zero-Shot, Klasse = rechnung_ursprungserklaerung_text. Zero-Shot, TP = 1. Zero-Shot, FP = 1. Zero-Shot, FN = 9. Zero-Shot, Accuracy = 0,09. Zero-Shot, Precision = 0,5. Zero-Shot, Recall = 0,1.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, F1 = 0,17. Zero-Shot, Support = 10. Zero-Shot, Gpt-4o = 2. Zero-Shot, Klasse = T1_positionen_insgesamt. Zero-Shot, TP = 2. Zero-Shot, FP = 2. Zero-Shot, FN = 22. Zero-Shot, Accuracy = 0,08. Zero-Shot, Precision = 0,5. Zero-Shot, Recall = 0,08. Zero-Shot, F1 = 0,14. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 4. Zero-Shot, Klasse = T1_packstücke_insgesamt. Zero-Shot, TP = 1. Zero-Shot, FP = 1. Zero-Shot, FN = 23. Zero-Shot, Accuracy = 0,04. Zero-Shot, Precision = 0,5. Zero-Shot, Recall = 0,04. Zero-Shot, F1 = 0,08. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 2. Zero-Shot, Klasse ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nT1_gesamtrohmasse. Zero-Shot, TP = 1. Zero-Shot, FP = 2. Zero-Shot, FN = 23. Zero-Shot, Accuracy = 0,04. Zero-Shot, Precision = 0,33. Zero-Shot, Recall = 0,04. Zero-Shot, F1 = 0,07. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 3. Zero-Shot, Klasse = frachtbrief_versendungsdatum. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 14. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 14. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = T1_verschluss_feld_19_10. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 5. Zero-Shot, Accuracy'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/19', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/803'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 91, 'bbox': {'l': 66.77274322509766, 't': 507.0099105834961, 'r': 720.05029296875, 'b': 206.93136596679688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/806', 'parent': {'$ref': '#/tables/20'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 92, 'bbox': {'l': 163.767, 't': 246.8602761019498, 'r': 757.703, 'b': 223.6782761019498, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 135]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n= 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 5. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = T1_wareneingangsnummer_stempel. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = T1_frist. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 24. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 24. Zero-Shot, Gpt-4o = 0\\n'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nTabelle B.2.: Klassenspezifische Extraktionsmetriken der Kopfdaten für 30 Sendungen mit der Methode Zero-Shot Prompting (zweiter Teil).'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Klasse = rechnung_rechnungsdatum. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 23. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 23. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = rechnung_lieferplan. Zero-Shot, TP = 0. Zero-Shot, FP = 1. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 1. Zero-Shot, Klasse = lieferschein_lieferplan. Zero-Shot, TP = 0. Zero-Shot, FP = 1. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nPrecision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 1. Zero-Shot, Klasse = lieferschein_ursprungserklaerung_text. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eori_gb_ukraine_registrierungsnummer. Zero-Shot, TP = 0. Zero-Shot, FP = 4. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 4. Zero-Shot,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nKlasse = atr_feld_4. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 1. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = atr_feld_5. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 1. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = atr_feld_6. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n0. Zero-Shot, F1 = 0. Zero-Shot, Support = 1. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = atr_feld_12_stempel. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 1. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = atr_feld_13_stempel. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 1. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eur1_feld_2. Zero-Shot, TP ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n0. Zero-Shot, FP = 0. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 2. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eur1_feld_4. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 2. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eur1_feld_5. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/20', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/806'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 92, 'bbox': {'l': 73.69804382324219, 't': 506.67726135253906, 'r': 712.20361328125, 'b': 264.5639343261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/809', 'parent': {'$ref': '#/tables/21'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 93, 'bbox': {'l': 163.767, 't': 195.1442761019498, 'r': 757.702, 'b': 171.96227610194978, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 127]}]}, {'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n2. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eur1_feld_11_stempel. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 2. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = eur1_feld_12_stempel. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 2. Zero-Shot, Gpt-4o = 0\\n\\nTabelle B.3.: Klassenspezifische Extraktionsmetriken der Einzelpositionen für 30 Sendungen mit der Methode Zero-Shot Prompting.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Klasse = währung. Zero-Shot, TP = 37. Zero-Shot, FP = 0. Zero-Shot, FN = 5. Zero-Shot, Accuracy = 0,88. Zero-Shot, Precision = 1. Zero-Shot, Recall = 0,88. Zero-Shot, F1 = 0,94. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 37. Zero-Shot, Klasse = menge. Zero-Shot, TP = 35. Zero-Shot, FP = 4. Zero-Shot, FN = 7. Zero-Shot, Accuracy = 0,76. Zero-Shot, Precision = 0,9. Zero-Shot, Recall = 0,83. Zero-Shot, F1 = 0,86. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 39. Zero-Shot, Klasse = ursprungsland. Zero-Shot, TP = 9. Zero-Shot, FP = 6. Zero-Shot, FN = 2. Zero-Shot, Accuracy = 0,53. Zero-Shot, Precision'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n= 0,6. Zero-Shot, Recall = 0,82. Zero-Shot, F1 = 0,69. Zero-Shot, Support = 11. Zero-Shot, Gpt-4o = 15. Zero-Shot, Klasse = preis. Zero-Shot, TP = 33. Zero-Shot, FP = 5. Zero-Shot, FN = 9. Zero-Shot, Accuracy = 0,7. Zero-Shot, Precision = 0,87. Zero-Shot, Recall = 0,79. Zero-Shot, F1 = 0,83. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 38. Zero-Shot, Klasse = menge_maßeinheit. Zero-Shot, TP = 27. Zero-Shot, FP = 9. Zero-Shot, FN = 15. Zero-Shot, Accuracy = 0,53. Zero-Shot, Precision = 0,75. Zero-Shot, Recall = 0,64. Zero-Shot, F1 = 0,69. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 36. Zero-Shot,'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nKlasse = warenbezeichnung. Zero-Shot, TP = 22. Zero-Shot, FP = 15. Zero-Shot, FN = 20. Zero-Shot, Accuracy = 0,39. Zero-Shot, Precision = 0,59. Zero-Shot, Recall = 0,52. Zero-Shot, F1 = 0,56. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 37. Zero-Shot, Klasse = packstueckart. Zero-Shot, TP = 1. Zero-Shot, FP = 4. Zero-Shot, FN = 1. Zero-Shot, Accuracy = 0,17. Zero-Shot, Precision = 0,2. Zero-Shot, Recall = 0,5. Zero-Shot, F1 = 0,29. Zero-Shot, Support = 2. Zero-Shot, Gpt-4o = 5. Zero-Shot, Klasse = artikelnummer. Zero-Shot, TP = 19. Zero-Shot, FP = 17. Zero-Shot, FN = 23. Zero-Shot, Accuracy = 0,32.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Precision = 0,53. Zero-Shot, Recall = 0,45. Zero-Shot, F1 = 0,49. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 36. Zero-Shot, Klasse = rohmasse_maßeinheit. Zero-Shot, TP = 13. Zero-Shot, FP = 0. Zero-Shot, FN = 27. Zero-Shot, Accuracy = 0,33. Zero-Shot, Precision = 1. Zero-Shot, Recall = 0,33. Zero-Shot, F1 = 0,49. Zero-Shot, Support = 40. Zero-Shot, Gpt-4o = 13. Zero-Shot, Klasse = packstueckanzahl. Zero-Shot, TP = 8. Zero-Shot, FP = 4. Zero-Shot, FN = 31. Zero-Shot, Accuracy = 0,19. Zero-Shot, Precision = 0,67. Zero-Shot, Recall = 0,21. Zero-Shot, F1 = 0,31. Zero-Shot, Support = 39. Zero-Shot, Gpt-4o'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n= 12. Zero-Shot, Klasse = rohmasse. Zero-Shot, TP = 9. Zero-Shot, FP = 7. Zero-Shot, FN = 33. Zero-Shot, Accuracy = 0,18. Zero-Shot, Precision = 0,56. Zero-Shot, Recall = 0,21. Zero-Shot, F1 = 0,31. Zero-Shot, Support = 42. Zero-Shot, Gpt-4o = 16. Zero-Shot, Klasse = eigenmasse_maßeinheit. Zero-Shot, TP = 1. Zero-Shot, FP = 4. Zero-Shot, FN = 4. Zero-Shot, Accuracy = 0,11. Zero-Shot, Precision = 0,2. Zero-Shot, Recall = 0,2. Zero-Shot, F1 = 0,2. Zero-Shot, Support = 5. Zero-Shot, Gpt-4o = 5. Zero-Shot, Klasse = eigenmasse. Zero-Shot, TP = 0. Zero-Shot, FP = 5. Zero-Shot, FN = 5.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 5. Zero-Shot, Gpt-4o = 5. Zero-Shot, Klasse = anmelde_und_handelsstatistische_menge. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = beantragte_beguenstigung. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o ='),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\n0. Zero-Shot, Klasse = betriebliche_identifikationsnummer. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = container_nummer. Zero-Shot, TP = 0. Zero-Shot, FP = 0. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 0. Zero-Shot, Klasse = packstueckzeichen_und_nummer. Zero-Shot, TP = 0. Zero-Shot, FP = 2. Zero-Shot, FN = 0. Zero-Shot, Accuracy = 0.'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/21', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/809'}], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 93, 'bbox': {'l': 67.26716613769531, 't': 506.9678192138672, 'r': 719.37744140625, 'b': 206.8397216796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}, {'self_ref': '#/texts/811', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 18.666669639999935, 't': 823.9078012563228, 'r': 316.0000029733332, 'b': 812.5856668689711, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 62]}]}, {'self_ref': '#/texts/812', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 57.32630187494152, 't': 748.6781849875392, 'r': 76.67369872552746, 'b': 743.957575381049, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}], 'headings': ['B. Anhang B'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='B. Anhang B\\nZero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 0. Zero-Shot, Gpt-4o = 2. Zero-Shot, Klasse = warennummer. Zero-Shot, TP = 0. Zero-Shot, FP = 15. Zero-Shot, FN = 6. Zero-Shot, Accuracy = 0. Zero-Shot, Precision = 0. Zero-Shot, Recall = 0. Zero-Shot, F1 = 0. Zero-Shot, Support = 6. Zero-Shot, Gpt-4o = 15\\nLarge Language Model (Gpt40) Document Extraction (MAIN SYSTEM)\\nSchema'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/814', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 39.999999333333356, 't': 676.720054157479, 'r': 93.33333266666669, 'b': 670.0599751060956, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 18]}]}, {'self_ref': '#/texts/815', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 53.2827921095576, 't': 608.9738616588768, 'r': 77.38387395770212, 'b': 601.9405549471296, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 8]}]}, {'self_ref': '#/texts/816', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 242.6666672416667, 't': 682.0481174485362, 'r': 288.66666724166663, 'b': 675.388038397153, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 15]}]}, {'self_ref': '#/texts/817', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 341.3333337166667, 't': 747.3168921520936, 'r': 387.3333337166667, 'b': 740.6568131007102, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 16]}]}, {'self_ref': '#/texts/818', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 335.3333339266667, 't': 676.0540463022912, 'r': 394.66666726, 'b': 670.0599751560462, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/819', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 89.291, 't': 642.9900146484375, 'r': 507.797, 'b': 602.100568232947, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 210]}]}, {'self_ref': '#/texts/820', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 52.66666702499999, 't': 602.1271688319355, 'r': 81.33333369166665, 'b': 596.7991055908288, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 10]}]}, {'self_ref': '#/texts/821', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 94, 'bbox': {'l': 40.00000053333331, 't': 542.1864573894652, 'r': 93.33333386666665, 'b': 535.5263783380817, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 18]}, {'page_no': 94, 'bbox': {'l': 346.0000004583333, 't': 602.1271687903101, 'r': 382.666667125, 'b': 596.133097644065, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [19, 30]}]}, {'self_ref': '#/texts/822', 'parent': {'$ref': '#/pictures/11'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 94, 'bbox': {'l': 88.899, 't': 261.8000146484376, 'r': 507.792, 'b': 238.61801464843757, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/823', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'footnote', 'prov': [{'page_no': 94, 'bbox': {'l': 94.436, 't': 172.14201464843745, 'r': 221.994, 'b': 162.95601464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 25]}]}, {'self_ref': '#/texts/826', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 16.666664888888892, 't': 825.8900146188079, 'r': 336.6666648888889, 'b': 816.5566812854745, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/827', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 38.00000026666665, 't': 767.8900147234375, 'r': 72.66666693333332, 'b': 761.8900147234375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 15]}]}, {'self_ref': '#/texts/828', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 31.999999211111135, 't': 707.2233479706597, 'r': 79.33333254444447, 'b': 702.5566813039931, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 22]}]}, {'self_ref': '#/texts/829', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 120.6489492478024, 't': 767.9982330628604, 'r': 156.68438524226855, 'b': 761.7817960409691, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 14]}]}, {'self_ref': '#/texts/830', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 127.30843389899435, 't': 762.677037594314, 'r': 149.35823350023134, 'b': 757.7696584439234, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/831', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 203.92810011882094, 't': 768.297689747172, 'r': 232.07189894694594, 'b': 762.1490061991983, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}]}, {'self_ref': '#/texts/832', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 207.99260038129455, 't': 762.5952730521816, 'r': 228.6740668017861, 'b': 758.5180896466233, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 9]}]}, {'self_ref': '#/texts/833', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 276.00000044666666, 't': 763.8900146884375, 'r': 320.6666671133333, 'b': 758.5566813551042, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 21]}]}, {'self_ref': '#/texts/834', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 359.3333338083333, 't': 765.2233479817709, 'r': 397.3333338083333, 'b': 759.8900146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 19]}]}, {'self_ref': '#/texts/835', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 371.33333344444446, 't': 759.223348003993, 'r': 384.66666677777783, 'b': 753.8900146706598, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/836', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 358.66666859378796, 't': 707.8900144894918, 'r': 397.99999938398975, 'b': 702.5566814740499, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 19]}]}, {'self_ref': '#/texts/837', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 95, 'bbox': {'l': 358.00000050833336, 't': 702.5566813484375, 'r': 398.666667175, 'b': 697.2233480151042, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 19]}]}], 'headings': ['C. Anhang C'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='C. Anhang C\\nPrompt_Task_2_prod\\nSendung.\\nJson_mit_Schema\\nKopfdaten_Gpt_40\\nEinzelpositionen_Gpt4o\\nIm Folgenden sind Screenshots der beiden Systeme auf Dataiku 8 dargestellt. Die Plattform bietet unter anderem das Umsetzen komplexer Anwendungen mit visualisierter Darstellung. Kopfdaten_und_ Einzelpositionen_\\nSharePoint\\nPrompt_Task_1_prod pro_Sendung\\nAbbildung C.1.: Screenshot des LLM basierten Systems zur Zolldokumentenextraktion\\n8 https://www.dataiku.com\\nNatural Language Processing Document Extraction OCR x SpaCyNER (SECONDARY SYSTEM)\\nZolldokumente 1\\nAll_entities_spaCy_NER\\nDocuments_OCR_\\nto_images\\nImages_OCR_\\nProcessed\\nExtract_Tesseract_OCR\\nExtracted_Entities_\\nSpacy\\nAll_Entities_spaCy_\\nincluding_filenames'),\n",
       " Document(metadata={'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/838', 'parent': {'$ref': '#/pictures/12'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 95, 'bbox': {'l': 88.899, 't': 394.0490146484375, 'r': 507.795, 'b': 370.86701464843753, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 88]}]}], 'headings': ['C. Anhang C'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}, page_content='C. Anhang C\\nAbbildung C.2.: Screenshot des hybriden klassischen Systems zur Zolldokumentenextraktion')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1afdf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    splits = docs\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ],\n",
    "    )\n",
    "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed4d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='STUTTGART\\nPORSCHe\\nBachelorarbeit Studiengang : Data Science'\n",
      "- d.page_content='Einsatz von Large Language Models (LLM) zur Extraktion und Strukturierung von Zolldokumenten: Ein KI-gestützter Ansatz zur automatisierten Datenverarbeitung\\nbei Porsche AG von Kevin Garrison\\n85826\\nBetreuender Professor: Prof. Dr. Winfried Bantel Zweitprüfer : Prof. Dr. Tim Dahmen\\nEinreichungsdatum : 14. August 2025'\n",
      "- d.page_content='Angaben zur Firma\\nUnternehmen :\\nPorsche AG\\nBranche :\\nAutomobilbranche Finanzstrategie & Data Science Porscheplatz 1 D - 70435 Stuttgart\\nAbteilung :\\nAdresse :\\nBetreuerin :\\nMaike Klepsch (FOD) (+49) 0 152 3 911 0075 maike.klepsch@porsche.de\\nTelefon :\\nE-Mail :'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf56e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 327 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split blog post into {len(splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fffa06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 12:22:23,630 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['79119573-876e-427a-97cd-3d143e9a715c', 'd8938eac-196a-46bd-9fdc-c6cf44a9e35d', 'a852a9eb-d966-4ae9-8db4-a08b6fcdab2c']\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45daf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=TOP_K)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ff8847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n",
    "\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a6e00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the key findings of the paper?\n",
      "\n",
      "Once you get the answer, retrive the .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-11-24 12:22:25,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_u8KlSG3SIRt3IjXynA8zKspj)\n",
      " Call ID: call_u8KlSG3SIRt3IjXynA8zKspj\n",
      "  Args:\n",
      "    query: key findings of the paper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 12:22:25,400 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/27', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.931, 't': 642.6360146484375, 'r': 507.798, 'b': 511.0610146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}\n",
      "Content: Kurzfassung\n",
      "Ergebnisse hinzunehmen.\n",
      "\n",
      "Source: {'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/28', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 88.899, 't': 507.1440146484375, 'r': 508.114, 'b': 199.4290146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1764]}]}], 'headings': ['Kurzfassung'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}\n",
      "Content: Kurzfassung\n",
      "klassischen Systems erheblich beeinträchtigen, während der LLM-basierte Ansatz diese Schwächen durch kontextuelle Interpretation teilweise kompensieren kann. Die besten Resultate hinsichtlich der Micro-Metriken lagen bei einem Recall von 0,53 und einem F1-Score von 0,60. Diese Ergebnisse wurden bei exakter Übereinstimmung numerischer Werte und einem Levenshtein-Schwellenwert von über 90% im Zeichenkettenvergleich zu den Testdaten erzielt. Insgesamt zeigen die Ergebnisse, dass der LLM-Ansatz robuster gegenüber fehlerhaften Eingangsdaten ist und ein höheres Maß an Generalisierungsfähigkeit aufweist, zugleich jedoch auch eigene Limitationen in Bezug auf Reproduzierbarkeit und Extraktionsgenauigkeit mit sich bringt, sodass eine\n",
      "\n",
      "Source: {'source': '/Users/kevingarrison/Code Projects/Private Projects/Agents/Langchain_LECL/langchain-lecl/notebooks/Bachelorarbeit_Kevin_Garrison_85826.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/517', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.931, 't': 454.64801464843754, 'r': 507.799, 'b': 323.0730146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 733]}]}, {'self_ref': '#/texts/518', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 55, 'bbox': {'l': 88.866, 't': 319.15701464843755, 'r': 507.797, 'b': 255.3270146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 348]}]}], 'headings': ['6.1. Erreichte Ergebnisse'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 18027861618462669308, 'filename': 'Bachelorarbeit_Kevin_Garrison_85826.pdf'}}}\n",
      "Content: 6.1. Erreichte Ergebnisse\n",
      "Schwellenwerten größer 90% erzielt.\n",
      "Die Ergebnisse verdeutlichen zudem, dass die Leistungsfähigkeit des Systems maßgeblich von der Qualität und Struktur der zugrunde liegenden Daten beeinflusst wird. Insgesamt zeigen die empirischen Analysen, dass die Extraktionspipeline derzeit noch nicht ausreichend robust ist, um zollkritische Prozesse vollumfänglich und automatisiert abzulösen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 12:22:29,159 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are the key findings of the paper:\n",
      "\n",
      "- The LLM-based (Large Language Model-based) approach is more robust to faulty input data compared to classical systems, thanks to its ability for contextual interpretation.\n",
      "- The best results in micro-metrics were a recall of 0.53 and an F1-score of 0.60, achieved with exact numerical matches and a Levenshtein threshold above 90% for string comparison with test data.\n",
      "- The LLM approach shows a higher generalization capability but also has limitations regarding reproducibility and extraction precision.\n",
      "- The performance of the system is strongly influenced by the quality and structure of underlying data.\n",
      "- The extraction pipeline, in its current state, is not robust enough to fully and automatically replace processes critical for customs operations.\n",
      "\n",
      "If you need more detailed findings or another section, please specify!\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What are the key findings of the paper?\\n\\n\"\n",
    "    \"Once you get the answer, retrive the .\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-lecl (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
